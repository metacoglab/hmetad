[{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using alternative signal distributions with the meta-d' model","text":"standard meta-d’ model assumes evidence making type 1 decisions follows equal-variance normal distribution evidence making type 2 decisions follows truncated equal-variance normal distribution. However, recent interest using distributions signal detection theory. distributions identifiable meta-d’ model (e.g., one simultaneously estimate unequal variances \\textrm{meta-}d'), hmetad package allows one specify distribution takes single parameter defining location (.e., mean, median, mode) distribution. demonstrate functionality, implement meta-d’ model Gumbel-min distribution, shown provide parsimonious explanation recognition memory data (Meyer-Grant et al., 2026). begin loading necessary packages R:","code":"library(tidyverse) library(brms) library(tidybayes) library(hmetad)"},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"implementing-a-distribution-function-for-use-with-hmetad","dir":"Articles","previous_headings":"","what":"Implementing a distribution function for use with hmetad","title":"Using alternative signal distributions with the meta-d' model","text":"order distribution used hmetad package, one needs implement cumulative distribution functions R Stan. Specifically, since hmetad package computes model likelihood logarithmic scale, one must define: <distribution>_lcdf(x, mu): log cumulative distribution function defining \\textrm{log } P(X \\le x) random variable X \\sim \\textrm{distribution}(\\mu). <distribution>_lccdf(x, mu): log complementary cumulative distribution function defining \\textrm{log } P(X \\ge x) random variable X \\sim \\textrm{distribution}(\\mu). Please note use hmetad package, two functions must use naming scheme (.e., must named <distribution>_l(c)cdf). example, can write gumbel min distribution functions R follows: One also needs implement two functions Stan using brms::stanvar available brms model fitting. Fortunately, functions usually look almost identical definitions R, minor syntactic changes /use efficient helper functions. code implements two functions Stan: , note name functions Stan must match corresponding names R. lcdf lccdf functions implemented R Stan, new distribution ready use hmetad package!","code":"gumbel_min_lcdf <- function(x, g) {   log1p(-exp(-exp(x - g))) } gumbel_min_lccdf <- function(x, g) {   -exp(x - g) } gumbel_min <- stanvar(   scode = \" real gumbel_min_lcdf(real x, real g) {   return log1m_exp(-exp(x - g)); } real gumbel_min_lccdf(real x, real g) {   return -exp(x - g); }\",   block = \"functions\" )"},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"data-simulation","dir":"Articles","previous_headings":"","what":"Data simulation","title":"Using alternative signal distributions with the meta-d' model","text":"continuing model fitting, section describes simulate data meta-d’ model custom distribution. necessary step parameter recovery ensure meta-d’ model well-defined respect distribution. simulate data, can call sim_metad function supplying optional arguments lcdf lccdf:","code":"d <- sim_metad(   N_trials = 10000, dprime = 1.5, c = .1, log_M = -.5,   c2_0_diff = c(.25, .5, .25), c2_1_diff = c(.1, .5, .25),   lcdf = gumbel_min_lcdf, lccdf = gumbel_min_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Using alternative signal distributions with the meta-d' model","text":"data, fitting model exactly equal-variance normal distribution, now also need specify two additional arguments fit_metad. distribution argument name distribution string. part function names preceding \"_lcdf\" \"_lccdf\" R Stan. stanvars argument stanvar object created containing Stan code cumulative distribution functions. Otherwise, one can call fit_metad just equal-variance normal distribution! Please note, however, scale parameters vary distribution distribution, set priors accordingly. code shows fit meta-d’ model new gumbel_min distribution: model summary can interpreted just model, however can see model family metad__4__gumbel_min__absolute__multinomial, indicating model indeed uses gumbel_min distribution four confidence levels \\textrm{meta-}c = c.","code":"m <- fit_metad(N ~ 1,   data = d,   prior = prior(normal(0, 1), class = Intercept) +     prior(normal(0, 1), class = dprime) +     prior(normal(0, 1), class = c) +     prior(lognormal(-1, 1), class = metac2zero1diff) +     prior(lognormal(-1, 1), class = metac2zero2diff) +     prior(lognormal(-1, 1), class = metac2zero3diff) +     prior(lognormal(-1, 1), class = metac2one1diff) +     prior(lognormal(-1, 1), class = metac2one2diff) +     prior(lognormal(-1, 1), class = metac2one3diff),   distribution = \"gumbel_min\", stanvars = gumbel_min, file = \"models/gumbel.rds\" ) #>  Family: metad__4__gumbel_min__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -0.61      0.06    -0.73    -0.49 1.00     3591     3343 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              1.55      0.03     1.49     1.61 1.00     5722     3474 #> c                   0.11      0.01     0.08     0.14 1.00     3812     2821 #> metac2zero1diff     0.24      0.01     0.22     0.26 1.00     5298     3297 #> metac2zero2diff     0.49      0.01     0.46     0.51 1.00     5293     3210 #> metac2zero3diff     0.25      0.01     0.23     0.27 1.00     6152     2811 #> metac2one1diff      0.10      0.01     0.09     0.11 1.00     4581     2940 #> metac2one2diff      0.48      0.01     0.45     0.50 1.00     4205     3027 #> metac2one3diff      0.25      0.01     0.23     0.27 1.00     4670     2731 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"model-estimates","dir":"Articles","previous_headings":"","what":"Model estimates","title":"Using alternative signal distributions with the meta-d' model","text":"model fit, can post-processed like model hmetad package. alternative distributions often understood terms effects ROC, focus plotting . Looking pseudo-type 1 ROC, can see gumbel_min distribution exhibits asymmetry:  Likewise, gumbel_min distribution also asymmetric type 2 ROCs:","code":"# psuedo type-1 ROC tibble(.row = 1) |>   add_roc1_draws(m, bounds = TRUE) |>   median_qi(p_fa, p_hit) |>   ggplot(aes(     x = p_fa, xmin = p_fa.lower, xmax = p_fa.upper,     y = p_hit, ymin = p_hit.lower, ymax = p_hit.upper   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_point() +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(False Alarm)\") +   ylab(\"P(Hit)\") +   theme_bw(18) # type 2 ROC roc2_draws(m, tibble(.row = 1), bounds = TRUE) |>   median_qi(p_hit2, p_fa2) |>   mutate(response = factor(response)) |>   ggplot(aes(     x = p_fa2, xmin = p_fa2.lower, xmax = p_fa2.upper,     y = p_hit2, ymin = p_hit2.lower, ymax = p_hit2.upper,     color = response   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_point() +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(Type 2 False Alarm)\") +   ylab(\"P(Type 2 Hit)\") +   theme_bw(18)"},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating trial-level effects","text":"default, hmetad package uses aggregated data (.e., counts number trials stimulus, type 1 response, type 2 response.) data aggregation makes model fitting simulation much efficient. sometimes researchers interested trial-level effects. One common example often called “crossed random effects”. example, design participants make responses set items, researcher might want estimate participant-level item-level effects model parameters. can simulate data design like : Don’t worry details simulation code- matters data set repeated measures participants: repeated measures items:","code":"library(tidyverse) #> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.2.0     ✔ readr     2.2.0 #> ✔ forcats   1.0.1     ✔ stringr   1.6.0 #> ✔ ggplot2   4.0.2     ✔ tibble    3.3.1 #> ✔ lubridate 1.9.5     ✔ tidyr     1.3.2 #> ✔ purrr     1.2.1      #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(tidybayes) library(hmetad) #> Loading required package: brms #> Loading required package: Rcpp #> Loading 'brms' package (version 2.23.0). Useful instructions #> can be found by typing help('brms'). A more detailed introduction #> to the package is available through vignette('brms_overview'). #>  #> Attaching package: 'brms' #>  #> The following objects are masked from 'package:tidybayes': #>  #>     dstudent_t, pstudent_t, qstudent_t, rstudent_t #>  #> The following object is masked from 'package:stats': #>  #>     ar  ## average model parameters K <- 3   ## number of confidence levels mu_log_M <- -0.5 mu_dprime <- 1.5 mu_c <- 0 mu_c2_0 <- rep(-1, K-1) mu_c2_1 <- rep(-1, K-1)  ## participant-level standard deviations sd_log_M_participant <- 0.25 sd_dprime_participant <- 0.5 sd_c_participant <- 0.33 sd_c2_0_participant <- cov_matrix(rep(0.25, K-1), diag(K-1)) sd_c2_1_participant <- cov_matrix(rep(0.25, K-1), diag(K-1))  ## item-level standard deviations sd_log_M_item <- 0.1 sd_dprime_item <- 0.5 sd_c_item <- 0.75 sd_c2_0_item <- cov_matrix(rep(0.1, K-1), diag(K-1)) sd_c2_1_item <- cov_matrix(rep(0.1, K-1), diag(K-1))    ## simulate data d <- expand_grid(participant=1:50,             item=1:10) |>   ## simulate participant-level differences   group_by(participant) |>   mutate(z_log_M_participant=rnorm(1, sd=sd_log_M_participant),          z_dprime_participant=rnorm(1, sd=sd_dprime_participant),          z_c_participant=rnorm(1, sd=sd_c_participant),          z_c2_0_participant=list(rmulti_normal(1, mu=rep(0,K-1), Sigma=sd_c2_0_participant)),          z_c2_1_participant=list(rmulti_normal(1, mu=rep(0,K-1), Sigma=sd_c2_1_participant)))|>   ## simulate item-level differences   group_by(item) |>   mutate(z_log_M_item=rnorm(1, sd=sd_log_M_item),          z_dprime_item=rnorm(1, sd=sd_dprime_item),          z_c_item=rnorm(1, sd=sd_c_item),          z_c2_0_item=list(rmulti_normal(1, mu=rep(0,K-1), Sigma=sd_c2_0_item)),          z_c2_1_item=list(rmulti_normal(1, mu=rep(0,K-1), Sigma=sd_c2_1_item))) |>   ungroup() |>   ## compute model parameters   mutate(log_M = mu_log_M + z_log_M_participant + z_log_M_item,          dprime = mu_dprime + z_dprime_participant + z_dprime_item,          c = mu_c + z_c_participant + z_c_item,          c2_0_diff = map2(z_c2_0_participant, z_c2_0_item,                            ~ exp(mu_c2_0 + .x + .y)),          c2_1_diff = map2(z_c2_1_participant, z_c2_1_item,                           ~ exp(mu_c2_1 + .x + .y))) |>   ## simulate two trials per participant/item (stimulus = 0 and stimulus = 1)   mutate(trial=pmap(list(dprime, c, log_M, c2_0_diff, c2_1_diff), sim_metad, N_trials=2)) |>   select(participant, item, trial) |>    unnest(trial) d #> # A tibble: 1,000 × 16 #>    participant  item trial stimulus response correct confidence dprime        c #>          <int> <int> <int>    <int>    <int>   <int>      <int>  <dbl>    <dbl> #>  1           1     1     1        0        0       1          3   1.76  0.00633 #>  2           1     1     1        1        0       0          3   1.76  0.00633 #>  3           1     2     1        0        0       1          1   2.46 -0.652   #>  4           1     2     1        1        1       1          3   2.46 -0.652   #>  5           1     3     1        0        0       1          2   2.34 -0.848   #>  6           1     3     1        1        1       1          3   2.34 -0.848   #>  7           1     4     1        0        0       1          2   2.83 -0.859   #>  8           1     4     1        1        1       1          3   2.83 -0.859   #>  9           1     5     1        0        0       1          3   1.88 -0.382   #> 10           1     5     1        1        1       1          3   1.88 -0.382   #> # ℹ 990 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl> count(d, participant) #> # A tibble: 50 × 2 #>    participant     n #>          <int> <int> #>  1           1    20 #>  2           2    20 #>  3           3    20 #>  4           4    20 #>  5           5    20 #>  6           6    20 #>  7           7    20 #>  8           8    20 #>  9           9    20 #> 10          10    20 #> # ℹ 40 more rows count(d, item) #> # A tibble: 10 × 2 #>     item     n #>    <int> <int> #>  1     1   100 #>  2     2   100 #>  3     3   100 #>  4     4   100 #>  5     5   100 #>  6     6   100 #>  7     7   100 #>  8     8   100 #>  9     9   100 #> 10    10   100"},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"standard-model-with-data-aggregation","dir":"Articles","previous_headings":"","what":"Standard model with data aggregation","title":"Estimating trial-level effects","text":"like, can use fit_metad function data participant-level item-level effects. However, aggregate data , can see aggregation doesn’t really help us : can see, aggregated data set 500 rows (two observations per row), much smaller trial-level data started ! , case, probably easier aggregate data. Nevertheless, nothing stopping us fitting model like normal:","code":"aggregate_metad(d, participant, item) #> # A tibble: 500 × 5 #>    participant item    N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] #>    <fct>       <fct> <int> <int>       <int>      <int>      <int>      <int> #>  1 1           1         1     1           1          0          0          0 #>  2 1           2         1     1           0          0          1          0 #>  3 1           3         1     1           0          1          0          0 #>  4 1           4         1     1           0          1          0          0 #>  5 1           5         1     1           1          0          0          0 #>  6 1           6         1     1           1          0          0          0 #>  7 1           7         1     1           0          1          0          0 #>  8 1           8         1     1           0          0          0          0 #>  9 1           9         1     1           1          0          0          0 #> 10 1           10        1     1           1          0          0          0 #> # ℹ 490 more rows #> # ℹ 1 more variable: N[5:12] <int> m.multinomial <- fit_metad(   bf(     N ~ 1 + (1 | participant) + (1 | item),     dprime + c +       metac2zero1diff + metac2zero2diff +       metac2one1diff + metac2one2diff ~       1 + (1 | participant) + (1 | item)   ),   data = d, init = 0,   file = \"models/multinomial.rds\" ) #> Compiling Stan program... #> Trying to compile a simple C file #> Running /opt/R/4.5.2/lib/R/bin/R CMD SHLIB foo.c #> using C compiler: ‘gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’ #> gcc -std=gnu2x -I\"/opt/R/4.5.2/lib/R/include\" -DNDEBUG   -I\"/home/runner/work/_temp/Library/Rcpp/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/unsupported\"  -I\"/home/runner/work/_temp/Library/BH/include\" -I\"/home/runner/work/_temp/Library/StanHeaders/include/src/\"  -I\"/home/runner/work/_temp/Library/StanHeaders/include/\"  -I\"/home/runner/work/_temp/Library/RcppParallel/include/\"  -I\"/home/runner/work/_temp/Library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o #> In file included from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Core:19, #>                  from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Dense:1, #>                  from /home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22, #>                  from <command-line>: #> /home/runner/work/_temp/Library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory #>   679 | #include <cmath> #>       |          ^~~~~~~ #> compilation terminated. #> make: *** [/opt/R/4.5.2/lib/R/etc/Makeconf:202: foo.o] Error 1 #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.004686 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 46.86 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 143.857 seconds (Warm-up) #> Chain 1:                135.983 seconds (Sampling) #> Chain 1:                279.84 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 0.00252 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 25.2 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 145.331 seconds (Warm-up) #> Chain 2:                86.523 seconds (Sampling) #> Chain 2:                231.854 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 0.002539 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 25.39 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 157.805 seconds (Warm-up) #> Chain 3:                147.948 seconds (Sampling) #> Chain 3:                305.753 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 0.002528 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 25.28 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 137.654 seconds (Warm-up) #> Chain 4:                164.739 seconds (Sampling) #> Chain 4:                302.393 seconds (Total) #> Chain 4: #> Warning: There were 37 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems m.multinomial #> Warning: There were 37 divergent transitions after warmup. Increasing #> adapt_delta above 0.8 may help. See #> http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #>  Family: metad__3__normal__absolute__multinomial  #>   Links: mu = log; dprime = identity; c = identity; metac2zero1diff = log; metac2zero2diff = log; metac2one1diff = log; metac2one2diff = log  #> Formula: N ~ 1 + (1 | participant) + (1 | item)  #>          dprime ~ 1 + (1 | participant) + (1 | item) #>          c ~ 1 + (1 | participant) + (1 | item) #>          metac2zero1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2zero2diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one2diff ~ 1 + (1 | participant) + (1 | item) #>    Data: data.aggregated (Number of observations: 500)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Multilevel Hyperparameters: #> ~item (Number of levels: 10)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.21      0.17     0.01     0.65 1.00 #> sd(dprime_Intercept)              0.68      0.23     0.35     1.25 1.00 #> sd(c_Intercept)                   0.75      0.22     0.45     1.31 1.00 #> sd(metac2zero1diff_Intercept)     0.20      0.15     0.01     0.57 1.00 #> sd(metac2zero2diff_Intercept)     0.26      0.16     0.02     0.63 1.00 #> sd(metac2one1diff_Intercept)      0.15      0.12     0.01     0.44 1.00 #> sd(metac2one2diff_Intercept)      0.31      0.18     0.03     0.72 1.00 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                     1342     1942 #> sd(dprime_Intercept)              1498     2072 #> sd(c_Intercept)                   1226     1701 #> sd(metac2zero1diff_Intercept)     1530     1860 #> sd(metac2zero2diff_Intercept)     1285     1961 #> sd(metac2one1diff_Intercept)      1926     2318 #> sd(metac2one2diff_Intercept)      1258     1574 #>  #> ~participant (Number of levels: 50)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.35      0.18     0.03     0.72 1.00 #> sd(dprime_Intercept)              0.55      0.14     0.28     0.83 1.00 #> sd(c_Intercept)                   0.36      0.07     0.25     0.50 1.00 #> sd(metac2zero1diff_Intercept)     0.25      0.15     0.02     0.57 1.00 #> sd(metac2zero2diff_Intercept)     0.29      0.15     0.02     0.59 1.00 #> sd(metac2one1diff_Intercept)      0.29      0.16     0.02     0.62 1.00 #> sd(metac2one2diff_Intercept)      0.51      0.14     0.24     0.79 1.00 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                      916     1347 #> sd(dprime_Intercept)              1629     1738 #> sd(c_Intercept)                   1595     2383 #> sd(metac2zero1diff_Intercept)      967     1234 #> sd(metac2zero2diff_Intercept)      776     1176 #> sd(metac2one1diff_Intercept)      1049     1597 #> sd(metac2one2diff_Intercept)      1434     1759 #>  #> Regression Coefficients: #>                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS #> Intercept                    -0.37      0.18    -0.80    -0.05 1.00     2412 #> dprime_Intercept              1.77      0.27     1.25     2.30 1.00     1435 #> c_Intercept                  -0.10      0.27    -0.63     0.42 1.00      808 #> metac2zero1diff_Intercept    -1.05      0.14    -1.34    -0.78 1.00     3336 #> metac2zero2diff_Intercept    -0.76      0.14    -1.05    -0.50 1.00     2484 #> metac2one1diff_Intercept     -1.03      0.13    -1.31    -0.78 1.00     2901 #> metac2one2diff_Intercept     -1.09      0.18    -1.48    -0.76 1.00     2147 #>                           Tail_ESS #> Intercept                     2151 #> dprime_Intercept              1820 #> c_Intercept                   1285 #> metac2zero1diff_Intercept     2472 #> metac2zero2diff_Intercept     2510 #> metac2one1diff_Intercept      3131 #> metac2one2diff_Intercept      2244 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data preparation","title":"Estimating trial-level effects","text":"Fitting trial-level model require data aggregation, however still requires small amount data preparation. fit model, need things: * column stimulus per trial (0 1), * column containing joint type 1/type 2 responses per trial (1 2*K). data already stimulus column separate columns two responses. , can add joint response column now:","code":"d <- d |>   mutate(joint_response = joint_response(response, confidence, K)) |>   relocate(joint_response, .after=\"stimulus\") d #> # A tibble: 1,000 × 17 #>    participant  item trial stimulus joint_response response correct confidence #>          <int> <int> <int>    <int>          <dbl>    <int>   <int>      <int> #>  1           1     1     1        0              1        0       1          3 #>  2           1     1     1        1              1        0       0          3 #>  3           1     2     1        0              3        0       1          1 #>  4           1     2     1        1              6        1       1          3 #>  5           1     3     1        0              2        0       1          2 #>  6           1     3     1        1              6        1       1          3 #>  7           1     4     1        0              2        0       1          2 #>  8           1     4     1        1              6        1       1          3 #>  9           1     5     1        0              1        0       1          3 #> 10           1     5     1        1              6        1       1          3 #> # ℹ 990 more rows #> # ℹ 9 more variables: dprime <dbl>, c <dbl>, meta_dprime <dbl>, M <dbl>, #> #   meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, #> #   theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Estimating trial-level effects","text":"Now data, can fit trial-level model using joint_response response variable, stimulus extra variable passed brms, argument categorical=TRUE tell fit_metad aggregate data: can see, aside way data formatted, model exactly multinomial model .","code":"m.categorical <- fit_metad(   bf(     joint_response | vint(stimulus) ~ 1 + (1 | participant) + (1 | item),     dprime + c +       metac2zero1diff + metac2zero2diff +       metac2one1diff + metac2one2diff ~       1 + (1 | participant) + (1 | item)   ),   data = d, categorical=TRUE, init = 0,   file = \"models/categorical.rds\" ) #> Compiling Stan program... #> Trying to compile a simple C file #> Running /opt/R/4.5.2/lib/R/bin/R CMD SHLIB foo.c #> using C compiler: ‘gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’ #> gcc -std=gnu2x -I\"/opt/R/4.5.2/lib/R/include\" -DNDEBUG   -I\"/home/runner/work/_temp/Library/Rcpp/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/unsupported\"  -I\"/home/runner/work/_temp/Library/BH/include\" -I\"/home/runner/work/_temp/Library/StanHeaders/include/src/\"  -I\"/home/runner/work/_temp/Library/StanHeaders/include/\"  -I\"/home/runner/work/_temp/Library/RcppParallel/include/\"  -I\"/home/runner/work/_temp/Library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o #> In file included from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Core:19, #>                  from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Dense:1, #>                  from /home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22, #>                  from <command-line>: #> /home/runner/work/_temp/Library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory #>   679 | #include <cmath> #>       |          ^~~~~~~ #> compilation terminated. #> make: *** [/opt/R/4.5.2/lib/R/etc/Makeconf:202: foo.o] Error 1 #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.003318 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 33.18 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 163.363 seconds (Warm-up) #> Chain 1:                177.418 seconds (Sampling) #> Chain 1:                340.781 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 0.002839 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 28.39 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 168.458 seconds (Warm-up) #> Chain 2:                184.384 seconds (Sampling) #> Chain 2:                352.842 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 0.002883 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 28.83 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 160.328 seconds (Warm-up) #> Chain 3:                103.636 seconds (Sampling) #> Chain 3:                263.964 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 0.00284 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 28.4 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 182.619 seconds (Warm-up) #> Chain 4:                92.32 seconds (Sampling) #> Chain 4:                274.939 seconds (Total) #> Chain 4: #> Warning: There were 24 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems m.categorical #> Warning: There were 24 divergent transitions after warmup. Increasing #> adapt_delta above 0.8 may help. See #> http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #>  Family: metad__3__normal__absolute__categorical  #>   Links: mu = log; dprime = identity; c = identity; metac2zero1diff = log; metac2zero2diff = log; metac2one1diff = log; metac2one2diff = log  #> Formula: joint_response | vint(stimulus) ~ 1 + (1 | participant) + (1 | item)  #>          dprime ~ 1 + (1 | participant) + (1 | item) #>          c ~ 1 + (1 | participant) + (1 | item) #>          metac2zero1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2zero2diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one2diff ~ 1 + (1 | participant) + (1 | item) #>    Data: data.aggregated (Number of observations: 1000)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Multilevel Hyperparameters: #> ~item (Number of levels: 10)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.21      0.18     0.01     0.64 1.00 #> sd(dprime_Intercept)              0.67      0.23     0.35     1.22 1.00 #> sd(c_Intercept)                   0.76      0.22     0.45     1.31 1.00 #> sd(metac2zero1diff_Intercept)     0.19      0.14     0.01     0.53 1.00 #> sd(metac2zero2diff_Intercept)     0.26      0.15     0.02     0.62 1.00 #> sd(metac2one1diff_Intercept)      0.15      0.12     0.01     0.45 1.00 #> sd(metac2one2diff_Intercept)      0.32      0.18     0.03     0.72 1.01 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                     1395     2061 #> sd(dprime_Intercept)              1675     2347 #> sd(c_Intercept)                   1424     2120 #> sd(metac2zero1diff_Intercept)     1361     1735 #> sd(metac2zero2diff_Intercept)     1216     1557 #> sd(metac2one1diff_Intercept)      1752     2299 #> sd(metac2one2diff_Intercept)       976     1333 #>  #> ~participant (Number of levels: 50)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.34      0.18     0.03     0.72 1.01 #> sd(dprime_Intercept)              0.55      0.15     0.25     0.85 1.00 #> sd(c_Intercept)                   0.37      0.06     0.25     0.50 1.00 #> sd(metac2zero1diff_Intercept)     0.25      0.15     0.01     0.58 1.00 #> sd(metac2zero2diff_Intercept)     0.28      0.15     0.02     0.58 1.01 #> sd(metac2one1diff_Intercept)      0.29      0.16     0.02     0.61 1.00 #> sd(metac2one2diff_Intercept)      0.51      0.14     0.22     0.80 1.00 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                      926     1363 #> sd(dprime_Intercept)              1126     1245 #> sd(c_Intercept)                   1573     2690 #> sd(metac2zero1diff_Intercept)      952     1570 #> sd(metac2zero2diff_Intercept)      832     1419 #> sd(metac2one1diff_Intercept)       738     1047 #> sd(metac2one2diff_Intercept)      1200      887 #>  #> Regression Coefficients: #>                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS #> Intercept                    -0.37      0.19    -0.79    -0.04 1.00     2533 #> dprime_Intercept              1.76      0.26     1.27     2.26 1.00     1625 #> c_Intercept                  -0.08      0.26    -0.60     0.42 1.00      954 #> metac2zero1diff_Intercept    -1.04      0.14    -1.35    -0.80 1.00     2738 #> metac2zero2diff_Intercept    -0.76      0.14    -1.04    -0.49 1.00     2572 #> metac2one1diff_Intercept     -1.03      0.13    -1.31    -0.79 1.00     3293 #> metac2one2diff_Intercept     -1.10      0.19    -1.48    -0.76 1.00     2107 #>                           Tail_ESS #> Intercept                     1740 #> dprime_Intercept              1838 #> c_Intercept                   1633 #> metac2zero1diff_Intercept     2544 #> metac2zero2diff_Intercept     2462 #> metac2one1diff_Intercept      2871 #> metac2one2diff_Intercept      1817 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"extracting-model-estimates","dir":"Articles","previous_headings":"","what":"Extracting model estimates","title":"Estimating trial-level effects","text":"Obtaining posterior estimates model parameters, predictions, estimates similar multinomial model (details, see vignette(\"hmetad\")). , focus type 1 ROC curves, time using roc1_rvars instead roc1_draws increased efficiency. get posterior estimates, need specify data set make predictions , well random effects formula use model predictions. example, estimate ROC averaging participants items, can use empty data set re_formula=NA: process exactly categorical model: Next, get participant-level ROCs (averaging items), can use data set one row per participant participant-level random effects: can use similar process get item-level ROCs (averaging participants):","code":"roc1_rvars(m.multinomial, tibble(.row=1), re_formula=NA) #> # A tibble: 5 × 6 #> # Groups:   .row, joint_response, response, confidence [5] #>    .row joint_response response confidence           p_fa         p_hit #>   <int>          <int>    <int>      <dbl>     <rvar[1d]>    <rvar[1d]> #> 1     1              1        0          3  0.573 ± 0.107  0.95 ± 0.034 #> 2     1              2        0          2  0.372 ± 0.101  0.89 ± 0.056 #> 3     1              3        0          1  0.227 ± 0.085  0.83 ± 0.075 #> 4     1              4        1          1  0.147 ± 0.067  0.69 ± 0.097 #> 5     1              5        1          2  0.089 ± 0.049  0.55 ± 0.109 roc1_rvars(m.categorical, tibble(.row=1), re_formula=NA) #> # A tibble: 5 × 6 #> # Groups:   .row, joint_response, response, confidence [5] #>    .row joint_response response confidence           p_fa         p_hit #>   <int>          <int>    <int>      <dbl>     <rvar[1d]>    <rvar[1d]> #> 1     1              1        0          3  0.567 ± 0.105  0.95 ± 0.032 #> 2     1              2        0          2  0.365 ± 0.100  0.89 ± 0.055 #> 3     1              3        0          1  0.221 ± 0.082  0.82 ± 0.074 #> 4     1              4        1          1  0.142 ± 0.065  0.69 ± 0.094 #> 5     1              5        1          2  0.086 ± 0.048  0.55 ± 0.106 roc1_rvars(m.categorical, distinct(d, participant), re_formula=~ (1 | participant)) #> # A tibble: 250 × 7 #> # Groups:   .row, participant, joint_response, response, confidence [250] #>     .row participant joint_response response confidence         p_fa #>    <int>       <int>          <int>    <int>      <dbl>   <rvar[1d]> #>  1     1           1              1        0          3  0.50 ± 0.15 #>  2     2           2              1        0          3  0.57 ± 0.14 #>  3     3           3              1        0          3  0.78 ± 0.12 #>  4     4           4              1        0          3  0.74 ± 0.13 #>  5     5           5              1        0          3  0.76 ± 0.12 #>  6     6           6              1        0          3  0.49 ± 0.15 #>  7     7           7              1        0          3  0.81 ± 0.11 #>  8     8           8              1        0          3  0.43 ± 0.15 #>  9     9           9              1        0          3  0.54 ± 0.15 #> 10    10          10              1        0          3  0.60 ± 0.14 #> # ℹ 240 more rows #> # ℹ 1 more variable: p_hit <rvar[1d]> roc1_rvars(m.categorical, distinct(d, item), re_formula=~ (1 | item)) #> # A tibble: 50 × 7 #> # Groups:   .row, item, joint_response, response, confidence [50] #>     .row  item joint_response response confidence          p_fa          p_hit #>    <int> <int>          <int>    <int>      <dbl>    <rvar[1d]>     <rvar[1d]> #>  1     1     1              1        0          3  0.44 ± 0.065  0.86 ± 0.0403 #>  2     2     2              1        0          3  0.63 ± 0.068  0.99 ± 0.0056 #>  3     3     3              1        0          3  0.82 ± 0.048  0.99 ± 0.0075 #>  4     4     4              1        0          3  0.75 ± 0.063  1.00 ± 0.0022 #>  5     5     5              1        0          3  0.66 ± 0.064  0.98 ± 0.0108 #>  6     6     6              1        0          3  0.21 ± 0.057  0.77 ± 0.0549 #>  7     7     7              1        0          3  0.67 ± 0.063  0.83 ± 0.0463 #>  8     8     8              1        0          3  0.77 ± 0.058  0.99 ± 0.0071 #>  9     9     9              1        0          3  0.55 ± 0.068  0.96 ± 0.0195 #> 10    10    10              1        0          3  0.20 ± 0.054  0.68 ± 0.0633 #> # ℹ 40 more rows"},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"other-benefits","dir":"Articles","previous_headings":"","what":"Other benefits","title":"Estimating trial-level effects","text":"Aside representing data convenient format, trial-level model useful things like model comparison using loo package, multivariate models, mediation models. features mostly work box still active development, stay tuned!","code":""},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Fitting the meta-d' model","text":"vignette demonstrates use hmetad package fit meta-d’ model (Maniscalco Lau 2012) dataset including binary decision confidence ratings.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data preparation","title":"Fitting the meta-d' model","text":"get better idea kind datasets hmetad package designed , can start simulating one (see help('sim_metad') description data simulation function): can see, dataset column trial number, presented stimulus trial (0 1), participant’s type 1 response (0 1), corresponding type 2 response (confidence; 1:K). trials dataset sorted stimulus, response, confidence data set simulated, otherwise look similar kind data immediately get running experiment.","code":"library(tidyverse) library(tidybayes) library(hmetad)  d <- sim_metad(   N_trials = 1000, dprime = .75, c = -.5, log_M = -1,   c2_0 = c(.25, .75, 1), c2_1 = c(.5, 1, 1.25) ) #> # A tibble: 1,000 × 4 #> # Groups:   stimulus, response, confidence [16] #>    trial stimulus response confidence #>    <int>    <int>    <int>      <int> #>  1     1        0        0          1 #>  2     2        0        0          1 #>  3     3        0        0          1 #>  4     4        0        0          1 #>  5     5        0        0          1 #>  6     6        0        0          1 #>  7     7        0        0          1 #>  8     8        0        0          1 #>  9     9        0        0          1 #> 10    10        0        0          1 #> # ℹ 990 more rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"type-1-type-2-and-joint-responses","dir":"Articles","previous_headings":"Data preparation","what":"Type 1, type 2, and joint responses","title":"Fitting the meta-d' model","text":"One hiccup paradigms collect separate decision (.e., type 1 response) confidence rating (.e., type 2 response)—rather, collect single rating reflecting primary decision confidence. example, instead binary type 1 response type 2 response ranging 1 K (K maximum confidence level), sometimes participants asked make rating scale 1 2*K, 1 represents confidence \"0\" response, K represents uncertain \"0\" response, K+1 represents uncertain \"1\" response, 2*K represents confident \"1\" response. refer joint response, combination type 1 response type 2 response. like convert joint response separate type 1 type 2 responses, can use corresponding functions type1_response type2_response. example, instead dataset looked like : convert joint response like : Similarly, can also convert separate responses joint response: Note cases need specify confidence scale K=4 levels (meaning joint type 1/type 2 scale 8 levels).","code":"#> # A tibble: 1,000 × 2 #>    trial joint_response #>    <int>          <dbl> #>  1     1              4 #>  2     2              4 #>  3     3              4 #>  4     4              4 #>  5     5              4 #>  6     6              4 #>  7     7              4 #>  8     8              4 #>  9     9              4 #> 10    10              4 #> # ℹ 990 more rows d.joint_response |>   mutate(     response = type1_response(joint_response, K = 4),     confidence = type2_response(joint_response, K = 4)   ) #> # A tibble: 1,000 × 4 #>    trial joint_response response confidence #>    <int>          <dbl>    <int>      <dbl> #>  1     1              4        0          1 #>  2     2              4        0          1 #>  3     3              4        0          1 #>  4     4              4        0          1 #>  5     5              4        0          1 #>  6     6              4        0          1 #>  7     7              4        0          1 #>  8     8              4        0          1 #>  9     9              4        0          1 #> 10    10              4        0          1 #> # ℹ 990 more rows d |>   mutate(joint_response = joint_response(response, confidence, K = 4)) #> # A tibble: 1,000 × 5 #> # Groups:   stimulus, response, confidence [16] #>    trial stimulus response confidence joint_response #>    <int>    <int>    <int>      <int>          <dbl> #>  1     1        0        0          1              4 #>  2     2        0        0          1              4 #>  3     3        0        0          1              4 #>  4     4        0        0          1              4 #>  5     5        0        0          1              4 #>  6     6        0        0          1              4 #>  7     7        0        0          1              4 #>  8     8        0        0          1              4 #>  9     9        0        0          1              4 #> 10    10        0        0          1              4 #> # ℹ 990 more rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"signed-and-unsigned-binary-numbers","dir":"Articles","previous_headings":"Data preparation","what":"Signed and unsigned binary numbers","title":"Fitting the meta-d' model","text":"Often datasets use -1 1 instead 0 1 represent two possible stimuli type 1 responses. hmetad package designed use unsigned (0 1) version, provides helper functions convert two:","code":"to_unsigned(c(-1, 1)) #> [1] 0 1 to_signed(c(0, 1)) #> [1] -1  1"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"data-aggregation","dir":"Articles","previous_headings":"Data preparation","what":"Data aggregation","title":"Fitting the meta-d' model","text":"Finally, ensure model runs efficiently, hmetad package currently requires data aggregated. easier, hmetad package aggregate data fit model. like manually (e.g., plotting follow-analyses), aggregate_metad function can : resulting data frame three columns: N_0 number trials stimulus==0, N_1 number trials stimulus==1, N matrix containing number joint responses two possible stimuli (column names indicating stimulus joint_response). like use variable name N counts, can change name .name argument: Finally, columns dataset (e.g., participant condition columns) like aggregated separately, can simply add function call:","code":"d.summary <- aggregate_metad(d) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   500   500           3         59        117         44         83        135 #> # ℹ 1 more variable: N[7:16] <int> aggregate_metad(d, .name = \"y\") #> # A tibble: 1 × 3 #>     y_0   y_1 y[,\"y_0_1\"] [,\"y_0_2\"] [,\"y_0_3\"] [,\"y_0_4\"] [,\"y_0_5\"] [,\"y_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   500   500           3         59        117         44         83        135 #> # ℹ 1 more variable: y[7:16] <int> aggregate_metad(d, participant, condition)"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Fitting the meta-d' model","text":"fit model, can use fit_metad function. function simply wrapper around brms::brm, users strongly encouraged become familiar brms model fitting. Since aggregate_metad place dataset trial counts column named N default, can use N response variable even data yet aggregated. fit model fixed values parameter, , can use formula N ~ 1: Note arbitrarily chosen use standard normal priors parameters. get better idea set informed priors, please refer help('set_prior', package='brms'). model, Intercept estimate \\textrm{log}(M) = \\textrm{log}\\frac{\\textrm{meta-}d'}{d'}, dprime estimate d', c estimate c, metac2zero1diff metac2zero2diff distances successive confidence thresholds \"0\" responses, metac2one1diff metac2one2diff distances successive confidence thresholds \"1\" responses. parameter, brms shows posterior means (Estimate), posterior standard deviations (Est. Error), upper- lower-95% posterior quantiles (l-95% CI u-95% CI), well convergence metrics (Rhat, Bulk_ESS, Tail_ESS).","code":"m <- fit_metad(N ~ 1,   data = d,   file = \"models/metad.rds\",   prior = prior(normal(0, 1), class = Intercept) +     prior(normal(0, 1), class = dprime) +     prior(normal(0, 1), class = c) +     prior(lognormal(0, 1), class = metac2zero1diff) +     prior(lognormal(0, 1), class = metac2zero2diff) +     prior(lognormal(0, 1), class = metac2one1diff) +     prior(lognormal(0, 1), class = metac2one2diff) ) #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -0.69      0.32    -1.43    -0.15 1.00     4865     3047 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              0.71      0.08     0.54     0.87 1.00     6299     2751 #> c                  -0.49      0.04    -0.57    -0.41 1.00     4208     2761 #> metac2zero1diff     0.21      0.02     0.17     0.26 1.00     6164     2998 #> metac2zero2diff     0.78      0.05     0.68     0.89 1.00     5144     2949 #> metac2zero3diff     1.27      0.17     0.97     1.63 1.00     5911     3002 #> metac2one1diff      0.47      0.03     0.41     0.54 1.00     5660     3143 #> metac2one2diff      1.00      0.05     0.91     1.09 1.00     5878     2975 #> metac2one3diff      1.30      0.11     1.10     1.52 1.00     8763     3453 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"extract-model-estimates","dir":"Articles","previous_headings":"","what":"Extract model estimates","title":"Fitting the meta-d' model","text":"fitted model, many estimates can extract . Although brms provides functions extracting posterior estimates, hmetad package designed interface well tidybayes package make easier work model posterior samples.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"parameter-estimates","dir":"Articles","previous_headings":"Extract model estimates","what":"Parameter estimates","title":"Fitting the meta-d' model","text":"First, often useful extract posterior draws model parameters, can linpred_draws_metad (wrapper around tidybayes::linpred_draws): tibble separate row every posterior sample separate column every model parameter. format useful purposes, often useful pivot separate row model parameter posterior sample: Now posterior samples stored single column .value, easy get posterior summaries using e.g. tidybayes::median_qi:","code":"draws.metad <- tibble(.row = 1) |>   add_linpred_draws_metad(m) #> # A tibble: 4,000 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime      c meta_dprime meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>  <dbl>       <dbl>  <dbl> #>  1     1     NA         NA     1 0.635  0.756 -0.505       0.480 -0.505 #>  2     1     NA         NA     2 0.419  0.723 -0.503       0.303 -0.505 #>  3     1     NA         NA     3 0.358  0.775 -0.499       0.277 -0.505 #>  4     1     NA         NA     4 0.571  0.687 -0.463       0.392 -0.505 #>  5     1     NA         NA     5 0.499  0.803 -0.540       0.401 -0.505 #>  6     1     NA         NA     6 0.398  0.735 -0.557       0.293 -0.505 #>  7     1     NA         NA     7 0.574  0.605 -0.475       0.347 -0.505 #>  8     1     NA         NA     8 0.456  0.716 -0.501       0.326 -0.505 #>  9     1     NA         NA     9 0.693  0.476 -0.482       0.330 -0.505 #> 10     1     NA         NA    10 0.596  0.777 -0.481       0.463 -0.505 #> # ℹ 3,990 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl> draws.metad <- tibble(.row = 1) |>   add_linpred_draws_metad(m, pivot_longer = TRUE) #> # A tibble: 44,000 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable    .value #>    <int>  <int>      <int> <int> <chr>         <dbl> #>  1     1     NA         NA     1 M            0.635  #>  2     1     NA         NA     1 dprime       0.756  #>  3     1     NA         NA     1 c           -0.505  #>  4     1     NA         NA     1 meta_dprime  0.480  #>  5     1     NA         NA     1 meta_c      -0.505  #>  6     1     NA         NA     1 meta_c2_0_1 -0.706  #>  7     1     NA         NA     1 meta_c2_0_2 -1.46   #>  8     1     NA         NA     1 meta_c2_0_3 -3.03   #>  9     1     NA         NA     1 meta_c2_1_1 -0.0206 #> 10     1     NA         NA     1 meta_c2_1_2  1.01   #> # ℹ 43,990 more rows draws.metad |>   median_qi() #> # A tibble: 11 × 8 #>     .row .variable    .value  .lower  .upper .width .point .interval #>    <int> <chr>         <dbl>   <dbl>   <dbl>  <dbl> <chr>  <chr>     #>  1     1 c           -0.493  -0.574  -0.409    0.95 median qi        #>  2     1 dprime       0.707   0.543   0.871    0.95 median qi        #>  3     1 M            0.518   0.240   0.865    0.95 median qi        #>  4     1 meta_c      -0.505  -0.505  -0.505    0.95 median qi        #>  5     1 meta_c2_0_1 -0.718  -0.769  -0.673    0.95 median qi        #>  6     1 meta_c2_0_2 -1.50   -1.62   -1.39     0.95 median qi        #>  7     1 meta_c2_0_3 -2.76   -3.14   -2.45     0.95 median qi        #>  8     1 meta_c2_1_1 -0.0339 -0.0968  0.0334   0.95 median qi        #>  9     1 meta_c2_1_2  0.965   0.862   1.07     0.95 median qi        #> 10     1 meta_c2_1_3  2.26    2.05    2.50     0.95 median qi        #> 11     1 meta_dprime  0.367   0.171   0.573    0.95 median qi"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Extract model estimates","what":"Posterior predictions","title":"Fitting the meta-d' model","text":"One way evaluate model fit perform posterior predictive check: simulate data model’s posterior compare simulated actual data. can using function predicted_draws_metad (wrapper around tidybayes::predicted_draws): data frame, columns aggregated data d.summary well stimulus, joint_response, response, confidence (indicating simulated trial type), well .prediction (indicating number simulated trials per trial type). , can plot posterior predictions (points error-bars) actual data (bars):","code":"draws.predicted <- predicted_draws_metad(m, d.summary) #> # A tibble: 64,000 × 12 #> # Groups:   .row, N_0, N_1, N, stimulus, joint_response, response, confidence #> #   [16] #>     .row   N_0   N_1 N[,\"N_0_1\"] stimulus joint_response response confidence #>    <int> <int> <int>       <int>    <int>          <int>    <int>      <dbl> #>  1     1   500   500           3        0              1        0          4 #>  2     1   500   500           3        0              1        0          4 #>  3     1   500   500           3        0              1        0          4 #>  4     1   500   500           3        0              1        0          4 #>  5     1   500   500           3        0              1        0          4 #>  6     1   500   500           3        0              1        0          4 #>  7     1   500   500           3        0              1        0          4 #>  8     1   500   500           3        0              1        0          4 #>  9     1   500   500           3        0              1        0          4 #> 10     1   500   500           3        0              1        0          4 #> # ℹ 63,990 more rows #> # ℹ 5 more variables: N[2:16] <int>, .prediction <int>, .chain <int>, #> #   .iteration <int>, .draw <int> draws.predicted |>   group_by(.row, stimulus, joint_response, response, confidence) |>   median_qi(.prediction) |>   group_by(.row) |>   mutate(N = t(d.summary$N[.row, ])) |>   ggplot(aes(x = joint_response)) +   geom_col(aes(y = N), fill = \"grey80\") +   geom_pointrange(aes(y = .prediction, ymin = .lower, ymax = .upper)) +   facet_wrap(~stimulus, labeller = label_both) +   theme_classic(18) #> Warning in `[<-.data.frame`(`*tmp*`, , y_vars, value = list(y = c(3, 59, : #> replacement element 1 has 256 rows to replace 16 rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"posterior-expectations","dir":"Articles","previous_headings":"Extract model estimates","what":"Posterior expectations","title":"Fitting the meta-d' model","text":"Usually simpler compare response probabilities rather raw response counts. , can use workflow using epred_draws_metad (wrapper around tidybayes::epred_draws):","code":"draws.epred <- epred_draws_metad(m, newdata = tibble(.row = 1)) #> # A tibble: 64,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence  .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>   <dbl>  <int>      <int> #>  1     1        0              1        0          4 0.00296     NA         NA #>  2     1        0              1        0          4 0.0100      NA         NA #>  3     1        0              1        0          4 0.00375     NA         NA #>  4     1        0              1        0          4 0.0122      NA         NA #>  5     1        0              1        0          4 0.00535     NA         NA #>  6     1        0              1        0          4 0.00504     NA         NA #>  7     1        0              1        0          4 0.00363     NA         NA #>  8     1        0              1        0          4 0.00509     NA         NA #>  9     1        0              1        0          4 0.00828     NA         NA #> 10     1        0              1        0          4 0.00637     NA         NA #> # ℹ 63,990 more rows #> # ℹ 1 more variable: .draw <int> draws.epred |>   group_by(.row, stimulus, joint_response, response, confidence) |>   median_qi(.epred) |>   group_by(.row) |>   mutate(.true = t(response_probabilities(d.summary$N[.row, ]))) |>   ggplot(aes(x = joint_response)) +   geom_col(aes(y = .true), fill = \"grey80\") +   geom_pointrange(aes(y = .epred, ymin = .lower, ymax = .upper)) +   scale_alpha_discrete(range = c(.25, 1)) +   facet_wrap(~stimulus, labeller = label_both) +   theme_classic(18) #> Warning: Using alpha for a discrete variable is not advised. #> Warning in `[<-.data.frame`(`*tmp*`, , y_vars, value = list(y = c(0.006, : #> replacement element 1 has 256 rows to replace 16 rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"mean-confidence","dir":"Articles","previous_headings":"Extract model estimates","what":"Mean confidence","title":"Fitting the meta-d' model","text":"One can also compute implied values mean confidence meta-d’ model using mean_confidence_draws: , .epred refers model-estimated mean confidence per stimulus response, .true empirical mean confidence. addition, can compute mean confidence marginalizing stimuli: responses: stimuli responses:","code":"tibble(.row = 1) |>   add_mean_confidence_draws(m) |>   median_qi(.epred) |>   left_join(d |>     group_by(stimulus, response) |>     summarize(.true = mean(confidence))) #> `summarise()` has regrouped the output. #> Joining with `by = join_by(stimulus, response)` #> ℹ Summaries were computed grouped by stimulus and response. #> ℹ Output is grouped by stimulus. #> ℹ Use `summarise(.groups = \"drop_last\")` to silence this message. #> ℹ Use `summarise(.by = c(stimulus, response))` for per-operation grouping #>   (`?dplyr::dplyr_by`) instead. #> # A tibble: 4 × 10 #>    .row stimulus response .epred .lower .upper .width .point .interval .true #>   <int>    <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0        0   2.07   1.99   2.15   0.95 median qi         2.09 #> 2     1        0        1   1.91   1.83   1.99   0.95 median qi         1.92 #> 3     1        1        0   1.95   1.86   2.04   0.95 median qi         1.90 #> 4     1        1        1   2.08   2.02   2.15   0.95 median qi         2.07 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_stimulus = FALSE) |>   median_qi(.epred) |>   left_join(d |>     group_by(response) |>     summarize(.true = mean(confidence))) #> Joining with `by = join_by(response)` #> # A tibble: 2 × 9 #>    .row response .epred .lower .upper .width .point .interval .true #>   <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0   2.03   1.95   2.11   0.95 median qi         2.03 #> 2     1        1   2.01   1.96   2.07   0.95 median qi         2.01 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_response = FALSE) |>   median_qi(.epred) |>   left_join(d |>     group_by(stimulus) |>     summarize(.true = mean(confidence))) #> Joining with `by = join_by(stimulus)` #> # A tibble: 2 × 9 #>    .row stimulus .epred .lower .upper .width .point .interval .true #>   <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0   1.98   1.93   2.03   0.95 median qi         2    #> 2     1        1   2.06   2.01   2.11   0.95 median qi         2.04 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_stimulus = FALSE, by_response = FALSE) |>   median_qi(.epred) |>   bind_cols(d |>     ungroup() |>     summarize(.true = mean(confidence))) #> # A tibble: 1 × 8 #>    .row .epred .lower .upper .width .point .interval .true #>   <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1   2.02   1.97   2.06   0.95 median qi         2.02"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"metacognitive-bias","dir":"Articles","previous_headings":"Extract model estimates","what":"Metacognitive bias","title":"Fitting the meta-d' model","text":"mean confidence often empirically informative, recommended measure metacognitive bias known confounded type 1 response characteristics (.e., d' c) metacognitive sensitivity (.e., \\textrm{meta-}d'). Instead, recommend new measure metacognitive bias, \\textrm{meta-}\\Delta, distance average confidence criteria \\textrm{meta-}c. \\textrm{meta-}\\Delta can interpreted lying two extremes: \\textrm{meta-}\\Delta = 0, observer uses highest confidence rating, \\textrm{meta-}\\Delta = \\infty, observer uses lowest confidence rating. obtain estimates \\textrm{meta-}\\Delta, one can use function metacognitive_bias_draws:","code":"tibble(.row = 1) |>   add_metacognitive_bias_draws(m) |>   median_qi() #> # A tibble: 2 × 8 #>    .row response metacognitive_bias .lower .upper .width .point .interval #>   <int>    <int>              <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     #> 1     1        0               1.16   1.03   1.30   0.95 median qi        #> 2     1        1               1.57   1.47   1.67   0.95 median qi"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"pseudo-type-1-roc","dir":"Articles","previous_headings":"Extract model estimates","what":"Pseudo Type 1 ROC","title":"Fitting the meta-d' model","text":"obtain type 1 performance pseudo-type 1 ROC, can use add_roc1_draws: , tidy tibble columns .chain, .iteration, .draw identifying individual posterior samples, joint_response, response, confidence identifying different points ROC, .row identifying different ROCs (since data frame one row, one ROC). addition, also p_hit p_fa, contain posterior estimates type 1 hit rate (.e., probability \"1\" response confidence >= c given stimulus==1) type 1 false alarm rate (.e., probability \"1\" response confidence >= c given stimulus==0). visualization, can get posterior summaries ROC using tidybayes::median_qi simply plot line:","code":"draws.roc1 <- tibble(.row = 1) |>   add_roc1_draws(m) #> # A tibble: 28,000 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.997 1.000 #>  2     1              1        0          4     NA         NA     2 0.990 0.997 #>  3     1              1        0          4     NA         NA     3 0.996 0.999 #>  4     1              1        0          4     NA         NA     4 0.988 0.997 #>  5     1              1        0          4     NA         NA     5 0.995 0.999 #>  6     1              1        0          4     NA         NA     6 0.995 0.999 #>  7     1              1        0          4     NA         NA     7 0.996 0.999 #>  8     1              1        0          4     NA         NA     8 0.995 0.999 #>  9     1              1        0          4     NA         NA     9 0.992 0.997 #> 10     1              1        0          4     NA         NA    10 0.994 0.999 #> # ℹ 27,990 more rows draws.roc1 |>   median_qi(p_fa, p_hit) |>   ggplot(aes(     x = p_fa, xmin = p_fa.lower, xmax = p_fa.upper,     y = p_hit, ymin = p_hit.lower, ymax = p_hit.upper   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(False Alarm)\") +   ylab(\"P(Hit)\") +   theme_bw(18)"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"type-2-roc","dir":"Articles","previous_headings":"Extract model estimates","what":"Type 2 ROC","title":"Fitting the meta-d' model","text":"Finally, plot type 2 performance type 2 ROC, can use add_roc2_draws: tibble looks roc1_draws, except now columns p_hit2 representing type 2 hit rate (.e., probability correct response confidence >= c given response) type 2 false alarm rate (.e., probability incorrect response confidence >= c given response). Note response-specific type 2 ROC, two separate curves two type 1 responses. can also plot type 2 ROC similarly:","code":"draws.roc2 <- tibble(.row = 1) |>   add_roc2_draws(m) #> # A tibble: 24,000 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw  p_hit2   p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>   <dbl>   <dbl> #>  1     1        0          4     NA         NA     1 0.00659 0.00233 #>  2     1        0          4     NA         NA     2 0.0226  0.0134  #>  3     1        0          4     NA         NA     3 0.00824 0.00468 #>  4     1        0          4     NA         NA     4 0.0270  0.0138  #>  5     1        0          4     NA         NA     5 0.0120  0.00552 #>  6     1        0          4     NA         NA     6 0.0119  0.00678 #>  7     1        0          4     NA         NA     7 0.00841 0.00410 #>  8     1        0          4     NA         NA     8 0.0115  0.00608 #>  9     1        0          4     NA         NA     9 0.0205  0.0114  #> 10     1        0          4     NA         NA    10 0.0138  0.00559 #> # ℹ 23,990 more rows draws.roc2 |>   median_qi(p_hit2, p_fa2) |>   mutate(response = factor(response)) |>   ggplot(aes(     x = p_fa2, xmin = p_fa2.lower, xmax = p_fa2.upper,     y = p_hit2, ymin = p_hit2.lower, ymax = p_hit2.upper,     color = response   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(Type 2 False Alarm)\") +   ylab(\"P(Type 2 Hit)\") +   theme_bw(18)"},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parameterization of the meta-d' model","text":"metacognition research, decision-making often categorized two kinds. type 1 decision primary decision hand, example judging orientation grating left right, judging word either presented (old) (new). context meta-d’ model, type 1 decision binary decision task (.e., either yes-decision task two-alternative forced choice task). contrast, type 2 decision task rating confidence type 1 decision. meta-d’ model applicable type 2 decision categorical (.e., confidence rated ordinal scale 1 K, 1 indicates low confidence K indicates high confidence). line distinction type 1 type 2 decisions, meta-d’ model conjunction two models (one decision). models based Signal Detection Theory (SDT). However, insight meta-d’ model information available type 2 decisions might differ information available type 1 decisions.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"model-for-type-1-decisions","dir":"Articles","previous_headings":"","what":"Model for type 1 decisions","title":"Parameterization of the meta-d' model","text":"SDT, observer presented noisy signal depending underlying stimulus x_1 \\sim \\mathcal{D}_S(d') following distribution \\mathcal{D} dependent stimulus S \\\\{0, 1\\} observer’s sensitivity d'. Typically, \\mathcal{D} chosen equal-variance normal distribution, \\mathcal{D}_0(d') = \\mathcal{N}\\left(-\\frac{d'}{2}, 1\\right) \\mathcal{D}_1(d') = \\mathcal{N}\\left(\\frac{d'}{2}, 1\\right) However, decision arbitrary options available. Given noisy encoding x_1, observer tasked determining true value S. , simply threshold x_1 response R = [x_1 > c] setup, observer makes correct response R = S. importantly, trials can categorized hits (S = 1 R = 1), misses (S = 1 R = 0), false alarms (FAs; S = 0 R = 1), correct rejections (CRs; S = 0 R = 0). generative model type 1 decisions implies following response probabilities: P(R=r \\;\\vert\\; S=s) = \\begin{cases} 1 - F_{\\mathcal{D}_s(d')}\\left(c\\right) & \\textrm{} r=1 \\\\ F_{\\mathcal{D}_s(d')}\\left(c\\right) & \\textrm{} r=0 \\end{cases}","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"model-for-type-2-decisions","dir":"Articles","previous_headings":"","what":"Model for type 2 decisions","title":"Parameterization of the meta-d' model","text":"classical SDT, type 2 decisions treated just like type 1 decisions stringent liberal response criteria. However, assumes observers access information making type 1 type 2 decisions. Relaxing assumption, meta-d’ model assumes type 2 decisions derived separate decision variable: x_2 \\sim \\begin{cases} \\mathcal{D}_S^{(-\\infty, \\textrm{meta-}c]}\\left(\\textrm{meta-}d'\\right) & \\textrm{} R=0 \\\\ \\mathcal{D}_S^{[\\textrm{meta-}c, \\infty)}\\left(\\textrm{meta-}d'\\right) & \\textrm{} R=1 \\end{cases} Importantly, decision variable follows distribution type 1 decision, two differences. First, distribution truncated either type 1 criterion \\textrm{meta-}c depending initial type 1 response. type 2 decision contradict type 1 decision (.e., meta-d’ model allow changes mind). Second, sensitivity type 2 decision \\textrm{meta-}d' rather d' allow task-level sensitivity metacognitive sensitivity differ. , determine confidence level C \\\\{ 1 \\ldots K\\}, observer rates confidence using one two sets K-1 ordered confidence criteria (\\textrm{meta-}c_2^0 \\textrm{meta-}c_2^1): \\begin{align*}     C &= \\begin{cases}     1+\\Sigma_{k=1}^{K-1}[x_2 < \\textrm{meta-}c_{2,k}^0] & \\textrm{} R=0 \\\\     1+\\Sigma_{k=1}^{K-1} [x_2 > \\textrm{meta-}c_{2,k}^1] & \\textrm{} R=1     \\end{cases} \\end{align*} generative model implies , conditional stimulus type 1 response, type 2 response probabilities \\begin{align*}     P(C=c \\;\\vert\\; R=r,S=s) &= \\begin{cases}     \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,1}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=0, c=1 \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k}^0\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k+1}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}       & \\textrm{} r=0, 1 \\le c \\le K \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,K}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=0, c = K \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,1}^0\\right) -     F_{\\mathcal{D}_s}\\left(\\textrm{meta-}c \\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, c=1 \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k+1}^0\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k}^0\\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, 1 \\le c \\le K \\\\          \\frac{1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,K}^0 \\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, c = K     \\end{cases} \\end{align*} formulas, numerator probability x_2 lies successive confidence thresholds denominator probability type 1 response r given type 2 parameters \\textrm{meta-}d' \\textrm{meta-}c account truncation type 2 signal distributions \\textrm{meta-}c.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"joint-model-for-type-1-and-type-2-decisions","dir":"Articles","previous_headings":"","what":"Joint model for type 1 and type 2 decisions","title":"Parameterization of the meta-d' model","text":"Ultimately, interested joint type 1 type 2 response probabilities stimulus. can conveniently decomposed type 1 response probability conditional type 2 response probability follows: P(R=r, C=c \\;\\vert\\; S=s) = P(R=r \\;\\vert\\; S=s) \\; P(C=c \\;\\vert\\; R=r, S=s) Given joint response probabilities stimulus, can formulate log likelihood meta-d’ one two ways. trial-level effects interest, one can model individual trials using categorical likelihood: LL \\;=\\; \\sum_n \\textrm{categorical}\\_\\textrm{lpmf}\\left(\\textrm{joint}\\_\\textrm{response}(r_n,c_n) \\;\\vert\\; P(R=r_n, C=c_n \\;\\vert\\; S=s_n)\\right) However, formulation requires likelihood evaluated per trial, well-powered experiments can take long time. , default hmetad package uses multinomial likelihood aggregated data. N_{s,r,c} number trials S=s, R=r, C=c: \\begin{align*} LL \\;&=\\; \\textrm{multinomial}\\_\\textrm{lpmf}\\left(N_{0,r,c} \\;\\vert\\; P(R=r, C=c \\;\\vert\\; S=0)\\right) \\\\ &\\;\\quad+\\; \\textrm{multinomial}\\_\\textrm{lpmf}\\left(N_{1,r,c} \\;\\vert\\; P(R=r, C=c \\;\\vert\\; S=1)\\right) \\end{align*} formulation requires model likelihood evaluated twice (per stimulus), dramatically increasing efficiency model fitting. increase efficiency, multinomial likelihood default hmetad package. categorical likelihood desired (e.g., trial-level effects crossed random effects), can used argument categorical=TRUE.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"fixing-the-type-1-threshold-for-type-2-responses","dir":"Articles","previous_headings":"","what":"Fixing the type 1 threshold for type 2 responses","title":"Parameterization of the meta-d' model","text":"meta-d’ model requires parameter \\textrm{meta-}c fixed equal respect type 1 criterion c. discussed (Maniscalco & Lau, 2014), multiple ways fixing \\textrm{meta-}c. hmetad package implements two: fixed parameterization, \\textrm{meta-}c = c. parameterization used default, since also used Hmeta-d toolbox (see also Fleming (2017)). Alternatively, relative parameterization, \\frac{\\textrm{meta-}c}{\\textrm{meta-}d'} = \\frac{c}{d'}, achieved setting \\textrm{meta-}c = M c. parameterization used (Maniscalco & Lau, 2012, 2014). switch two parameterizations, fit_metad sim_metad functions argument metac_absolute TRUE default. use relative parameterization, simply set metac_absolute=FALSE call function.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"model-parameterization","dir":"Articles","previous_headings":"","what":"Model parameterization","title":"Parameterization of the meta-d' model","text":"increase efficiency model fitting help convergence, hmetad parameterizes meta-d’ model parameters unconstrained variables (.e., fall range (-\\infty, \\infty)). parameters type 1 responses (d' c) already unconstrained, estimated normally. However, parameters type 2 parameters bounded. First, instead fitting \\textrm{meta-}d' directly, hmetad package models M-ratio M = \\frac{\\textrm{meta-}d'}{d'}. parameterization helps regularize strong differences \\textrm{meta-}d' d', M-ratio still bounded zero. , hmetad package models M-ratio logarithmic scale, .e., \\textrm{log }M = \\textrm{log}\\frac{\\textrm{meta-}d'}{d'}. parameterization, one can compute \\textrm{meta-}d' \\textrm{meta-}d' = e^{\\textrm{log }M}d'. Second, confidence criteria \\textrm{meta-}c_{2,1:K}^0 \\textrm{meta-}c_{2,1:K}^1 two constraints. Namely, \\textrm{meta-}c_{2,1:K}^0 must strictly decreasing less \\textrm{meta-}c, whereas \\textrm{meta-}c_{2,1:K}^1 must strictly increasing greater \\textrm{meta-}c. deal constraints, hmetad package estimates differences successive confidence criteria: \\textrm{dmeta-}c_{2,k}^0 = \\begin{cases}   \\textrm{meta-}c - \\textrm{meta-}c_{2,1}^0 & \\textrm{} k = 1 \\\\   \\textrm{meta-}c_{2,k-1}^0  - \\textrm{meta-}c_{2,k}^0 & \\textrm{} 2 \\le k \\le K \\end{cases}   \\textrm{dmeta-}c_{2,k}^1 = \\begin{cases}   \\textrm{meta-}c_{2,1}^0 - \\textrm{meta-}c & \\textrm{} k = 1 \\\\   \\textrm{meta-}c_{2,k}^1  - \\textrm{meta-}c_{2,k-1}^1 & \\textrm{} 2 \\le k \\le K \\end{cases} Like M-ratio, differences successive confidence criteria also modeled logarithmic scale (parameters named metac2zero<k>diff metac2one<k>diff). parameterization, confidence criteria can computed follows: \\begin{align*} \\textrm{meta-}c_2^0 &= \\textrm{meta-}c - \\textrm{cumulative}\\_\\textrm{sum}\\left(e^{\\textrm{dmeta-}c_2^0}\\right) \\\\ \\textrm{meta-}c_2^1 &= \\textrm{meta-}c + \\textrm{cumulative}\\_\\textrm{sum}\\left(e^{\\textrm{dmeta-}c_2^1}\\right) \\end{align*}","code":""},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kevin O'Neill. Author, maintainer, copyright holder.","code":""},{"path":"https://metacoglab.github.io/hmetad/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"O'Neill K (2026). hmetad: Fit Meta-D' Model Confidence Ratings Using 'brms'. R package version 0.0.1, https://metacoglab.github.io/hmetad/.","code":"@Manual{,   title = {hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms'},   author = {Kevin O'Neill},   year = {2026},   note = {R package version 0.0.1},   url = {https://metacoglab.github.io/hmetad/}, }"},{"path":"https://metacoglab.github.io/hmetad/index.html","id":"hmetad","dir":"","previous_headings":"","what":"Fit the Meta-D Model of Confidence Ratings Using brms'","title":"Fit the Meta-D Model of Confidence Ratings Using brms'","text":"hmetad package designed fit meta-d’ model confidence ratings (Maniscalco & Lau, 2012, 2014). Like Hmeta-d toolbox (Fleming, 2017), hmetad package uses Bayesian modeling approach. hmetad package builds Hmeta-d toolbox implementation custom family brms package, provides friendly interface probabilistic programming language Stan. provides major benefits: Model designs can specified simple R formulas Support complex model designs (e.g., multilevel models, distributional models, multivariate models) Interfaces packages surrounding brms (e.g., tidybayes, ggdist, bayesplot, loo, posterior, bridgesampling, bayestestR) Computation model-implied quantities (e.g., mean confidence, type 1 type 2 receiver operating characteristic curves, metacognitive bias) Increased sampling efficiency better convergence diagnostics","code":""},{"path":"https://metacoglab.github.io/hmetad/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fit the Meta-D Model of Confidence Ratings Using brms'","text":"hmetad currently submission CRAN, means soon able install using: now, can install development version hmetad GitHub :","code":"install.packages(\"hmetad\") # install.packages(\"pak\") pak::pak(\"metacoglab/hmetad\")"},{"path":"https://metacoglab.github.io/hmetad/index.html","id":"quick-setup","dir":"","previous_headings":"","what":"Quick setup","title":"Fit the Meta-D Model of Confidence Ratings Using brms'","text":"Let’s say data binary decision task ordinal confidence ratings: can fit intercepts-meta-d’ model using fit_metad: Now let’s say complicated design, within-participant manipulation: account repeated measures design, can simply adjust formula include participant-level effects:","code":"#> # A tibble: 1,000 × 5 #>    trial stimulus response correct confidence #>    <int>    <int>    <int>   <int>      <int> #>  1     1        1        1       1          2 #>  2     2        1        0       0          1 #>  3     3        0        0       1          2 #>  4     4        0        0       1          4 #>  5     5        1        1       1          2 #>  6     6        1        1       1          3 #>  7     7        1        1       1          2 #>  8     8        1        1       1          2 #>  9     9        1        1       1          2 #> 10    10        1        0       0          2 #> # ℹ 990 more rows library(hmetad)  m <- fit_metad(N ~ 1, data = d, file = \"vignettes/models/readme1.rds\") #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -0.18      0.16    -0.52     0.11 1.00     3142     3260 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              1.08      0.08     0.92     1.25 1.00     4527     3273 #> c                   0.02      0.04    -0.06     0.10 1.00     3675     3067 #> metac2zero1diff     0.48      0.03     0.41     0.55 1.00     4490     3209 #> metac2zero2diff     0.52      0.04     0.44     0.60 1.00     5076     3242 #> metac2zero3diff     0.55      0.05     0.46     0.65 1.00     5655     2716 #> metac2one1diff      0.46      0.03     0.39     0.52 1.00     4627     2976 #> metac2one2diff      0.43      0.04     0.36     0.50 1.00     4979     2987 #> metac2one3diff      0.52      0.05     0.43     0.61 1.00     5653     2723 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1). #> # A tibble: 5,000 × 7 #> # Groups:   participant, condition [50] #>    participant condition trial stimulus response correct confidence #>          <int>     <int> <int>    <int>    <int>   <int>      <int> #>  1           1         1     1        0        0       1          4 #>  2           1         1     2        1        0       0          3 #>  3           1         1     3        1        0       0          4 #>  4           1         1     4        1        1       1          3 #>  5           1         1     5        0        0       1          4 #>  6           1         1     6        0        0       1          1 #>  7           1         1     7        0        1       0          2 #>  8           1         1     8        0        0       1          3 #>  9           1         1     9        1        1       1          3 #> 10           1         1    10        1        0       0          1 #> # ℹ 4,990 more rows m <- fit_metad(   bf(     N ~ condition + (condition | participant),     dprime + c +       metac2zero1diff + metac2zero2diff + metac2zero3diff +       metac2one1diff + metac2one2diff + metac2one3diff ~       condition + (condition | participant)   ),   data = d, init = \"0\", file = \"vignettes/models/readme2.rds\",   prior = prior(normal(0, 1)) +     prior(normal(0, 1), dpar = dprime) +     prior(normal(0, 1), dpar = c) +     prior(normal(0, 1), dpar = metac2zero1diff) +     prior(normal(0, 1), dpar = metac2zero2diff) +     prior(normal(0, 1), dpar = metac2zero3diff) +     prior(normal(0, 1), dpar = metac2one1diff) +     prior(normal(0, 1), dpar = metac2one2diff) +     prior(normal(0, 1), dpar = metac2one3diff) ) #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log; dprime = identity; c = identity; metac2zero1diff = log; metac2zero2diff = log; metac2zero3diff = log; metac2one1diff = log; metac2one2diff = log; metac2one3diff = log  #> Formula: N ~ condition + (condition | participant)  #>          dprime ~ condition + (condition | participant) #>          c ~ condition + (condition | participant) #>          metac2zero1diff ~ condition + (condition | participant) #>          metac2zero2diff ~ condition + (condition | participant) #>          metac2zero3diff ~ condition + (condition | participant) #>          metac2one1diff ~ condition + (condition | participant) #>          metac2one2diff ~ condition + (condition | participant) #>          metac2one3diff ~ condition + (condition | participant) #>    Data: data.aggregated (Number of observations: 50)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Multilevel Hyperparameters: #> ~participant (Number of levels: 25)  #>                                                           Estimate Est.Error #> sd(Intercept)                                                 0.53      0.16 #> sd(condition2)                                                0.85      0.25 #> sd(dprime_Intercept)                                          0.48      0.09 #> sd(dprime_condition2)                                         0.67      0.14 #> sd(c_Intercept)                                               0.64      0.10 #> sd(c_condition2)                                              0.75      0.12 #> sd(metac2zero1diff_Intercept)                                 0.09      0.06 #> sd(metac2zero1diff_condition2)                                0.09      0.07 #> sd(metac2zero2diff_Intercept)                                 0.15      0.09 #> sd(metac2zero2diff_condition2)                                0.17      0.11 #> sd(metac2zero3diff_Intercept)                                 0.07      0.06 #> sd(metac2zero3diff_condition2)                                0.14      0.10 #> sd(metac2one1diff_Intercept)                                  0.08      0.05 #> sd(metac2one1diff_condition2)                                 0.12      0.08 #> sd(metac2one2diff_Intercept)                                  0.12      0.07 #> sd(metac2one2diff_condition2)                                 0.10      0.07 #> sd(metac2one3diff_Intercept)                                  0.21      0.12 #> sd(metac2one3diff_condition2)                                 0.19      0.13 #> cor(Intercept,condition2)                                    -0.84      0.15 #> cor(dprime_Intercept,dprime_condition2)                      -0.61      0.16 #> cor(c_Intercept,c_condition2)                                -0.79      0.08 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)    -0.10      0.57 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)    -0.20      0.56 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)    -0.23      0.58 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)      -0.07      0.59 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)       0.05      0.56 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)      -0.63      0.46 #>                                                           l-95% CI u-95% CI #> sd(Intercept)                                                 0.28     0.89 #> sd(condition2)                                                0.40     1.39 #> sd(dprime_Intercept)                                          0.33     0.68 #> sd(dprime_condition2)                                         0.45     0.98 #> sd(c_Intercept)                                               0.48     0.86 #> sd(c_condition2)                                              0.55     1.02 #> sd(metac2zero1diff_Intercept)                                 0.00     0.22 #> sd(metac2zero1diff_condition2)                                0.00     0.25 #> sd(metac2zero2diff_Intercept)                                 0.01     0.34 #> sd(metac2zero2diff_condition2)                                0.01     0.42 #> sd(metac2zero3diff_Intercept)                                 0.00     0.21 #> sd(metac2zero3diff_condition2)                                0.01     0.37 #> sd(metac2one1diff_Intercept)                                  0.00     0.20 #> sd(metac2one1diff_condition2)                                 0.01     0.31 #> sd(metac2one2diff_Intercept)                                  0.01     0.26 #> sd(metac2one2diff_condition2)                                 0.00     0.27 #> sd(metac2one3diff_Intercept)                                  0.02     0.46 #> sd(metac2one3diff_condition2)                                 0.01     0.47 #> cor(Intercept,condition2)                                    -0.99    -0.44 #> cor(dprime_Intercept,dprime_condition2)                      -0.85    -0.25 #> cor(c_Intercept,c_condition2)                                -0.91    -0.59 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)    -0.96     0.93 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)    -0.97     0.93 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)    -0.98     0.91 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)      -0.96     0.95 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)      -0.92     0.95 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)      -1.00     0.70 #>                                                           Rhat Bulk_ESS #> sd(Intercept)                                             1.00     1976 #> sd(condition2)                                            1.00     1316 #> sd(dprime_Intercept)                                      1.00     1744 #> sd(dprime_condition2)                                     1.00     1306 #> sd(c_Intercept)                                           1.00      940 #> sd(c_condition2)                                          1.00      908 #> sd(metac2zero1diff_Intercept)                             1.00     1721 #> sd(metac2zero1diff_condition2)                            1.00     1858 #> sd(metac2zero2diff_Intercept)                             1.00     1372 #> sd(metac2zero2diff_condition2)                            1.00     1294 #> sd(metac2zero3diff_Intercept)                             1.00     1676 #> sd(metac2zero3diff_condition2)                            1.00     1669 #> sd(metac2one1diff_Intercept)                              1.00     2318 #> sd(metac2one1diff_condition2)                             1.00     1592 #> sd(metac2one2diff_Intercept)                              1.00     1303 #> sd(metac2one2diff_condition2)                             1.00     1848 #> sd(metac2one3diff_Intercept)                              1.00      863 #> sd(metac2one3diff_condition2)                             1.00     1038 #> cor(Intercept,condition2)                                 1.00     1379 #> cor(dprime_Intercept,dprime_condition2)                   1.00     1635 #> cor(c_Intercept,c_condition2)                             1.00     1090 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2) 1.00     4554 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2) 1.00     2823 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2) 1.00     2675 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)   1.00     2354 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)   1.00     4178 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)   1.00     1520 #>                                                           Tail_ESS #> sd(Intercept)                                                 2725 #> sd(condition2)                                                1774 #> sd(dprime_Intercept)                                          2325 #> sd(dprime_condition2)                                         2546 #> sd(c_Intercept)                                               1722 #> sd(c_condition2)                                              1190 #> sd(metac2zero1diff_Intercept)                                 2037 #> sd(metac2zero1diff_condition2)                                1691 #> sd(metac2zero2diff_Intercept)                                 1808 #> sd(metac2zero2diff_condition2)                                1908 #> sd(metac2zero3diff_Intercept)                                 2164 #> sd(metac2zero3diff_condition2)                                2429 #> sd(metac2one1diff_Intercept)                                  2459 #> sd(metac2one1diff_condition2)                                 1920 #> sd(metac2one2diff_Intercept)                                  1510 #> sd(metac2one2diff_condition2)                                 2032 #> sd(metac2one3diff_Intercept)                                  1528 #> sd(metac2one3diff_condition2)                                 1590 #> cor(Intercept,condition2)                                     2113 #> cor(dprime_Intercept,dprime_condition2)                       2358 #> cor(c_Intercept,c_condition2)                                 1538 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)     2956 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)     2275 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)     2654 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)       2669 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)       3249 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)       2395 #>  #> Regression Coefficients: #>                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS #> Intercept                     -0.10      0.16    -0.44     0.19 1.00     3095 #> dprime_Intercept               0.90      0.11     0.67     1.12 1.00     1523 #> c_Intercept                   -0.02      0.13    -0.27     0.24 1.01      474 #> metac2zero1diff_Intercept     -0.95      0.06    -1.07    -0.84 1.00     5998 #> metac2zero2diff_Intercept     -1.02      0.07    -1.16    -0.89 1.00     4764 #> metac2zero3diff_Intercept     -1.05      0.07    -1.18    -0.92 1.00     6306 #> metac2one1diff_Intercept      -0.96      0.06    -1.09    -0.85 1.00     5967 #> metac2one2diff_Intercept      -0.97      0.06    -1.10    -0.84 1.00     5015 #> metac2one3diff_Intercept      -1.09      0.08    -1.26    -0.93 1.00     4329 #> condition2                    -0.05      0.24    -0.53     0.43 1.00     2754 #> dprime_condition2              0.03      0.15    -0.27     0.33 1.00     2083 #> c_condition2                  -0.19      0.15    -0.48     0.11 1.00      809 #> metac2zero1diff_condition2    -0.09      0.08    -0.25     0.07 1.00     5915 #> metac2zero2diff_condition2    -0.14      0.10    -0.32     0.05 1.00     4944 #> metac2zero3diff_condition2     0.01      0.10    -0.17     0.20 1.00     5620 #> metac2one1diff_condition2     -0.12      0.08    -0.28     0.04 1.00     5205 #> metac2one2diff_condition2     -0.01      0.08    -0.17     0.15 1.00     5177 #> metac2one3diff_condition2      0.10      0.10    -0.09     0.31 1.00     5508 #>                            Tail_ESS #> Intercept                      2616 #> dprime_Intercept               2172 #> c_Intercept                    1239 #> metac2zero1diff_Intercept      2829 #> metac2zero2diff_Intercept      3016 #> metac2zero3diff_Intercept      3005 #> metac2one1diff_Intercept       2897 #> metac2one2diff_Intercept       2952 #> metac2one3diff_Intercept       2879 #> condition2                     2771 #> dprime_condition2              2679 #> c_condition2                   1446 #> metac2zero1diff_condition2     2905 #> metac2zero2diff_condition2     3129 #> metac2zero3diff_condition2     2461 #> metac2one1diff_condition2      2420 #> metac2one2diff_condition2      2707 #> metac2one3diff_condition2      3413 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate data by response, confidence, and other columns — aggregate_metad","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"Counts number rows data unique combinations values columns response, confidence, columns ....","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"","code":"aggregate_metad(   data,   ...,   .stimulus = \"stimulus\",   .response = \"response\",   .confidence = \"confidence\",   .joint_response = \"joint_response\",   .name = \"N\",   K = NULL )"},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"data data frame aggregate ... Grouping columns data. columns converted factors. .stimulus name \"stimulus\" column .response name \"response\" column .confidence name \"confidence\" column .joint_response name \"joint_response\" column .name name resulting column containing trial counts K number confidence levels data. NULL, estimated data.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"tibble one row per combination variables ..., another column named value .response containing trial counts. \\(K\\) confidence levels, \\(N \\times K*4\\) matrix, columns represent (stimulus \\(S\\), type 1 response \\(R\\), type 2 response \\(C\\)): $$  [N_{S=0, R=0, C=K}, \\ldots, N_{S=0, R=0, C=1}, \\\\  N_{S=0, R=1, C=1}, \\ldots, N_{S=0, R=1, C=K}, \\\\  N_{S=1, R=0, C=K}, \\ldots, N_{S=1, R=0, C=1}, \\\\  N_{S=1, R=1, C=1}, \\ldots, N_{S=1, R=1, C=K}] \\\\ $$","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"data frame data must one column name given .stimulus. Additionally, must either: Two columns names given .response .confidence One column name given .joint_response Finally, must also columns additional variables ....","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"","code":"# aggregate a dataset without grouping factors d <- sim_metad() aggregate_metad(d) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1    50    50           8          5          4         12         10          7 #> # ℹ 1 more variable: N[7:16] <int>  # aggregate a dataset with grouping factors d2 <- sim_metad_condition() aggregate_metad(d2, condition) #> # A tibble: 2 × 4 #>   condition   N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] #>   <fct>     <int> <int>       <int>      <int>      <int>      <int>      <int> #> 1 1            50    50           7          4         10         16          5 #> 2 2            50    50           3          6         10         13          9 #> # ℹ 1 more variable: N[6:16] <int>  # can also aggregate ignoring grouping factors aggregate_metad(d2) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   100   100          10         10         20         29         14          9 #> # ℹ 1 more variable: N[7:16] <int>  # aggregate data with only `joint_response` column library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union d |>   ungroup() |>   mutate(joint_response = joint_response(     response, confidence,     n_distinct(confidence)   )) |>   select(-response, -confidence) |>   aggregate_metad() #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1    50    50           8          5          4         12         10          7 #> # ℹ 1 more variable: N[7:16] <int>"},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"Computes \\(\\textrm{meta-}\\Delta\\), index metacognitive bias. \\(\\textrm{meta-}\\Delta\\) distance meta_c average confidence criteria meta_c2_0 meta_c2_1. metacognitive_bias_draws add_metacognitive_bias_draws, parameters returned tidy tibble one row per posterior draw per response. metacognitive_bias_rvars add_metacognitive_bias_rvars, parameters returned posterior::rvars, one row per row newdata per response.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"","code":"metacognitive_bias_draws(object, newdata, ..., by_response = TRUE)  add_metacognitive_bias_draws(newdata, object, ...)  metacognitive_bias_rvars(object, newdata, ..., by_response = TRUE)  add_metacognitive_bias_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws tidybayes::epred_rvars by_response TRUE, compute metacognitive bias separately two type 1 responses. FALSE, compute un-weighted average two measures.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"tibble containing posterior draws \\(\\textrm{meta-}\\Delta\\) following columns: .row: row newdata .chain, .iteration, .draw: metacognitive_bias_draws add_metacognitive_bias_draws, identifiers posterior sample response: type 1 response perceived stimulus presence metacognitive_bias: distance meta_c average confidence criteria meta_c2_{response}.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.039 seconds (Warm-up) #> Chain 1:                0.025 seconds (Sampling) #> Chain 1:                0.064 seconds (Total) #> Chain 1:  newdata <- tidyr::tibble(.row = 1)  # compute metacognitive bias metacognitive_bias_draws(m, newdata) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row response .chain .iteration .draw metacognitive_bias #>    <int>    <int>  <int>      <int> <int>              <dbl> #>  1     1        0     NA         NA     1              0.981 #>  2     1        0     NA         NA     2              1.18  #>  3     1        0     NA         NA     3              1.10  #>  4     1        0     NA         NA     4              1.00  #>  5     1        0     NA         NA     5              0.875 #>  6     1        0     NA         NA     6              1.04  #>  7     1        0     NA         NA     7              1.01  #>  8     1        0     NA         NA     8              1.14  #>  9     1        0     NA         NA     9              1.04  #> 10     1        0     NA         NA    10              1.06  #> # ℹ 490 more rows add_metacognitive_bias_draws(newdata, m) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row response .chain .iteration .draw metacognitive_bias #>    <int>    <int>  <int>      <int> <int>              <dbl> #>  1     1        0     NA         NA     1              0.981 #>  2     1        0     NA         NA     2              1.18  #>  3     1        0     NA         NA     3              1.10  #>  4     1        0     NA         NA     4              1.00  #>  5     1        0     NA         NA     5              0.875 #>  6     1        0     NA         NA     6              1.04  #>  7     1        0     NA         NA     7              1.01  #>  8     1        0     NA         NA     8              1.14  #>  9     1        0     NA         NA     9              1.04  #> 10     1        0     NA         NA    10              1.06  #> # ℹ 490 more rows  # use posterior::rvar for increased efficiency metacognitive_bias_rvars(m, newdata) #> # A tibble: 2 × 3 #> # Groups:   .row, response [2] #>    .row response metacognitive_bias #>   <dbl>    <int>         <rvar[1d]> #> 1     1        0        1.02 ± 0.13 #> 2     1        1        0.97 ± 0.14 add_metacognitive_bias_rvars(newdata, m) #> # A tibble: 2 × 3 #> # Groups:   .row, response [2] #>    .row response metacognitive_bias #>   <dbl>    <int>         <rvar[1d]> #> 1     1        0        1.02 ± 0.13 #> 2     1        1        0.97 ± 0.14  # average over the two type 1 responses metacognitive_bias_draws(m, newdata, by_response = FALSE) #> # A tibble: 250 × 5 #> # Groups:   .row [1] #>     .row .chain .iteration .draw metacognitive_bias #>    <int>  <int>      <int> <int>              <dbl> #>  1     1     NA         NA     1              1.00  #>  2     1     NA         NA     2              1.04  #>  3     1     NA         NA     3              0.983 #>  4     1     NA         NA     4              0.927 #>  5     1     NA         NA     5              1.01  #>  6     1     NA         NA     6              1.07  #>  7     1     NA         NA     7              0.882 #>  8     1     NA         NA     8              1.00  #>  9     1     NA         NA     9              1.03  #> 10     1     NA         NA    10              1.14  #> # ℹ 240 more rows metacognitive_bias_rvars(m, newdata, by_response = FALSE) #> # A tibble: 1 × 2 #> # Groups:   .row [1] #>    .row metacognitive_bias #>   <dbl>         <rvar[1d]> #> 1     1       0.99 ± 0.098"},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"Generate correlation matrix -diagonal values equal r","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"","code":"cor_matrix(r, nrow = 2)"},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"r correlation fill matrix -diagonals nrow number rows (columns) resulting matrix","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"[nrow x nrow] matrix values along diagonal equal 1 values diagonal equal r","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"","code":"cor_matrix(0, nrow = 3) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1  cor_matrix(-.5, nrow = 4) #>      [,1] [,2] [,3] [,4] #> [1,]  1.0 -0.5 -0.5 -0.5 #> [2,] -0.5  1.0 -0.5 -0.5 #> [3,] -0.5 -0.5  1.0 -0.5 #> [4,] -0.5 -0.5 -0.5  1.0"},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a covariance matrix. — cov_matrix","title":"Generate a covariance matrix. — cov_matrix","text":"Generate covariance matrix.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a covariance matrix. — cov_matrix","text":"","code":"cov_matrix(S, OMEGA)"},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a covariance matrix. — cov_matrix","text":"S vector standard deviations OMEGA correlation matrix","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a covariance matrix. — cov_matrix","text":"\\(N \\times N\\) covariance matrix, N = length(S).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a covariance matrix. — cov_matrix","text":"","code":"sds <- c(1, 2) corrs <- matrix(c(1, .5, .5, 1), nrow = 2) cov_matrix(sds, corrs) #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    4"},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of joint response probabilities — epred_draws_metad","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"Given data frame meta-d' model, adds estimates joint type 1 type 2 response probabilities. epred_draws_metad add_epred_draws_metad, estimates returned tidy tibble one row per posterior draw. epred_rvars_metad add_epred_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"","code":"epred_draws_metad(object, newdata, ...)  add_epred_draws_metad(newdata, object, ...)  epred_rvars_metad(object, newdata, ...)  add_epred_rvars_metad(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_epred_draws tidybayes::add_epred_rvars","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: epred_draws_metad, identifiers posterior sample stimulus, joint_response, response, confidence: identifiers response type .epred: probability type 1 type 2 response given stimulus, \\(P(R, C \\;\\vert\\; S)\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1: Rejecting initial value: #> Chain 1:   Gradient evaluated at the initial value is not finite. #> Chain 1:   Stan can't start sampling from this initial value. #> Chain 1:  #> Chain 1: Gradient evaluation took 9e-06 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.027 seconds (Warm-up) #> Chain 1:                0.023 seconds (Sampling) #> Chain 1:                0.05 seconds (Total) #> Chain 1:  #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # obtain model predictions epred_draws_metad(m, newdata) #> # A tibble: 4,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>  <dbl>  <int>      <int> #>  1     1        0              1        0          4 0.0863     NA         NA #>  2     1        0              1        0          4 0.173      NA         NA #>  3     1        0              1        0          4 0.103      NA         NA #>  4     1        0              1        0          4 0.148      NA         NA #>  5     1        0              1        0          4 0.127      NA         NA #>  6     1        0              1        0          4 0.198      NA         NA #>  7     1        0              1        0          4 0.143      NA         NA #>  8     1        0              1        0          4 0.151      NA         NA #>  9     1        0              1        0          4 0.122      NA         NA #> 10     1        0              1        0          4 0.0978     NA         NA #> # ℹ 3,990 more rows #> # ℹ 1 more variable: .draw <int> add_epred_draws_metad(newdata, m) #> # A tibble: 4,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>  <dbl>  <int>      <int> #>  1     1        0              1        0          4 0.0863     NA         NA #>  2     1        0              1        0          4 0.173      NA         NA #>  3     1        0              1        0          4 0.103      NA         NA #>  4     1        0              1        0          4 0.148      NA         NA #>  5     1        0              1        0          4 0.127      NA         NA #>  6     1        0              1        0          4 0.198      NA         NA #>  7     1        0              1        0          4 0.143      NA         NA #>  8     1        0              1        0          4 0.151      NA         NA #>  9     1        0              1        0          4 0.122      NA         NA #> 10     1        0              1        0          4 0.0978     NA         NA #> # ℹ 3,990 more rows #> # ℹ 1 more variable: .draw <int>  # obtain model predictions (posterior::rvar) epred_rvars_metad(m, newdata) #> # A tibble: 16 × 6 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence         .epred #>    <int>    <int>          <int>    <int>      <dbl>     <rvar[1d]> #>  1     1        0              1        0          4  0.140 ± 0.045 #>  2     1        0              2        0          3  0.186 ± 0.048 #>  3     1        0              3        0          2  0.278 ± 0.049 #>  4     1        0              4        0          1  0.169 ± 0.046 #>  5     1        0              5        1          1  0.118 ± 0.047 #>  6     1        0              6        1          2  0.067 ± 0.023 #>  7     1        0              7        1          3  0.021 ± 0.011 #>  8     1        0              8        1          4  0.022 ± 0.015 #>  9     1        1              1        0          4  0.020 ± 0.013 #> 10     1        1              2        0          3  0.050 ± 0.020 #> 11     1        1              3        0          2  0.133 ± 0.035 #> 12     1        1              4        0          1  0.134 ± 0.041 #> 13     1        1              5        1          1  0.213 ± 0.048 #> 14     1        1              6        1          2  0.202 ± 0.048 #> 15     1        1              7        1          3  0.093 ± 0.035 #> 16     1        1              8        1          4  0.155 ± 0.046 add_epred_rvars_metad(newdata, m) #> # A tibble: 16 × 6 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence         .epred #>    <int>    <int>          <int>    <int>      <dbl>     <rvar[1d]> #>  1     1        0              1        0          4  0.140 ± 0.045 #>  2     1        0              2        0          3  0.186 ± 0.048 #>  3     1        0              3        0          2  0.278 ± 0.049 #>  4     1        0              4        0          1  0.169 ± 0.046 #>  5     1        0              5        1          1  0.118 ± 0.047 #>  6     1        0              6        1          2  0.067 ± 0.023 #>  7     1        0              7        1          3  0.021 ± 0.011 #>  8     1        0              8        1          4  0.022 ± 0.015 #>  9     1        1              1        0          4  0.020 ± 0.013 #> 10     1        1              2        0          3  0.050 ± 0.020 #> 11     1        1              3        0          2  0.133 ± 0.035 #> 12     1        1              4        0          1  0.134 ± 0.041 #> 13     1        1              5        1          1  0.213 ± 0.048 #> 14     1        1              6        1          2  0.202 ± 0.048 #> 15     1        1              7        1          3  0.093 ± 0.035 #> 16     1        1              8        1          4  0.155 ± 0.046"},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit the meta-d' model using brms package — fit_metad","title":"Fit the meta-d' model using brms package — fit_metad","text":"function wrapper around brms::brm() using custom family meta-d' model.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit the meta-d' model using brms package — fit_metad","text":"","code":"fit_metad(   formula,   data,   ...,   aggregate = TRUE,   .stimulus = \"stimulus\",   .response = \"response\",   .confidence = \"confidence\",   .joint_response = \"joint_response\",   K = NULL,   distribution = \"normal\",   metac_absolute = TRUE,   stanvars = NULL,   categorical = FALSE )"},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit the meta-d' model using brms package — fit_metad","text":"formula model formula parameters metad brms family. display parameter names model K confidence levels, use metad(K). data tibble containing data fit model. aggregate==TRUE, data one row per observation columns stimulus, response, confidence, variables formula aggregate==FALSE, aggregated one row per cell design matrix, joint type 1/type 2 response counts matrix column (see aggregate_metad()). ... Additional parameters passed brm function. aggregate TRUE, automatically aggregate data variables included formula using aggregate_metad(). Otherwise, data already aggregated. .stimulus name \"stimulus\" column .response name \"response\" column .confidence name \"confidence\" column .joint_response name \"joint_response\" column K number confidence levels. default, estimated data. distribution noise distribution use signal detection model. default, uses normal distribution mean parameterized dprime. metac_absolute TRUE, fix type 2 criterion equal type 1 criterion. Otherwise, equate criteria relatively metac/metadprime = c/dprime. stanvars Additional stanvars pass model code, example define alternative distribution custom model prior (see brms::stanvar()). categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit the meta-d' model using brms package — fit_metad","text":"","code":"# fit a basic model on simulated data # running few iterations so example runs quickly, use more in practice fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.03 seconds (Warm-up) #> Chain 1:                0.032 seconds (Sampling) #> Chain 1:                0.062 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 1 chains, each with iter = 500; warmup = 250; thin = 1; #>          total post-warmup draws = 250 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -1.97      2.08    -7.37     0.52 1.00      123       96 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              0.76      0.26     0.27     1.24 1.02      309      104 #> c                  -0.03      0.13    -0.26     0.22 1.02      190      153 #> metac2zero1diff     0.47      0.08     0.33     0.65 1.00      206      154 #> metac2zero2diff     0.23      0.08     0.11     0.39 1.00      327      206 #> metac2zero3diff     0.69      0.16     0.44     1.05 1.01      433      208 #> metac2one1diff      0.58      0.10     0.42     0.80 1.02      133      186 #> metac2one2diff      0.58      0.13     0.37     0.89 1.00      437      230 #> metac2one3diff      0.52      0.17     0.21     0.89 1.00      286      153 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/reference/hmetad-package.html","id":null,"dir":"Reference","previous_headings":"","what":"hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms' — hmetad-package","title":"hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms' — hmetad-package","text":"Implementation Bayesian regressions meta-d\\' model psychological data two alternative forced choice tasks ordinal confidence ratings. information, see Maniscalco & Lau (2012) doi:10.1016/j.concog.2011.09.021 . package front-end 'brms' package, facilitates wide range regression designs, well tools efficiently extracting posterior estimates, plotting, significance testing.","code":""},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/reference/hmetad-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms' — hmetad-package","text":"Maintainer: Kevin O'Neill kevin.o'neill@ucl.ac.uk (ORCID) [copyright holder]","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"Given data frame meta-d' model, adds estimates model parameters. linpred_draws_metad add_linpred_draws_metad, parameters returned tidy tibble one row per posterior draw. linpred_rvars_metad add_linpred_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"","code":"linpred_draws_metad(object, newdata, ..., pivot_longer = FALSE)  add_linpred_draws_metad(newdata, object, ..., pivot_longer = FALSE)  linpred_rvars_metad(object, newdata, ..., pivot_longer = FALSE)  add_linpred_rvars_metad(newdata, object, pivot_longer = FALSE)"},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_linpred_draws tidybayes::add_linpred_rvars pivot_longer Return draws long format? TRUE, resulting data frame one row per posterior draw per model parameter FALSE (default), resulting data frame one row per posterior draw","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: linpred_draws_metad, identifiers posterior sample .variable, .value: pivot_longer=TRUE, .variable identifies different meta-d' model parameters .value stores posterior samples M, dprime, c, meta_dprime, meta_c, meta_c2_0_<k>, meta_c2_1_<k>: pivot_longer=FALSE, posterior samples meta-d' model parameters","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.033 seconds (Warm-up) #> Chain 1:                0.021 seconds (Sampling) #> Chain 1:                0.054 seconds (Total) #> Chain 1:  newdata <- tidyr::tibble(.row = 1)  # obtain model parameters (wide format) linpred_draws_metad(m, newdata) #> # A tibble: 250 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime      c meta_dprime meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>  <dbl>       <dbl>  <dbl> #>  1     1     NA         NA     1 0.777  1.18  -0.109       0.914 -0.109 #>  2     1     NA         NA     2 0.305  1.27  -0.172       0.387 -0.109 #>  3     1     NA         NA     3 0.741  1.19  -0.230       0.883 -0.109 #>  4     1     NA         NA     4 0.337  1.25  -0.413       0.420 -0.109 #>  5     1     NA         NA     5 0.362  1.31  -0.439       0.475 -0.109 #>  6     1     NA         NA     6 0.258  1.57  -0.449       0.406 -0.109 #>  7     1     NA         NA     7 0.274  1.61  -0.250       0.440 -0.109 #>  8     1     NA         NA     8 1.09   0.721 -0.167       0.783 -0.109 #>  9     1     NA         NA     9 1.30   0.623 -0.266       0.809 -0.109 #> 10     1     NA         NA    10 0.438  1.16  -0.182       0.508 -0.109 #> # ℹ 240 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl> add_linpred_draws_metad(newdata, m) #> # A tibble: 250 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime      c meta_dprime meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>  <dbl>       <dbl>  <dbl> #>  1     1     NA         NA     1 0.777  1.18  -0.109       0.914 -0.109 #>  2     1     NA         NA     2 0.305  1.27  -0.172       0.387 -0.109 #>  3     1     NA         NA     3 0.741  1.19  -0.230       0.883 -0.109 #>  4     1     NA         NA     4 0.337  1.25  -0.413       0.420 -0.109 #>  5     1     NA         NA     5 0.362  1.31  -0.439       0.475 -0.109 #>  6     1     NA         NA     6 0.258  1.57  -0.449       0.406 -0.109 #>  7     1     NA         NA     7 0.274  1.61  -0.250       0.440 -0.109 #>  8     1     NA         NA     8 1.09   0.721 -0.167       0.783 -0.109 #>  9     1     NA         NA     9 1.30   0.623 -0.266       0.809 -0.109 #> 10     1     NA         NA    10 0.438  1.16  -0.182       0.508 -0.109 #> # ℹ 240 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl>  # obtain model parameters (long format) linpred_draws_metad(m, newdata, pivot_longer = TRUE) #> # A tibble: 2,750 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable   .value #>    <int>  <int>      <int> <int> <chr>        <dbl> #>  1     1     NA         NA     1 M            0.777 #>  2     1     NA         NA     1 dprime       1.18  #>  3     1     NA         NA     1 c           -0.109 #>  4     1     NA         NA     1 meta_dprime  0.914 #>  5     1     NA         NA     1 meta_c      -0.109 #>  6     1     NA         NA     1 meta_c2_0_1 -0.342 #>  7     1     NA         NA     1 meta_c2_0_2 -1.01  #>  8     1     NA         NA     1 meta_c2_0_3 -1.54  #>  9     1     NA         NA     1 meta_c2_1_1  0.382 #> 10     1     NA         NA     1 meta_c2_1_2  1.03  #> # ℹ 2,740 more rows add_linpred_draws_metad(newdata, m, pivot_longer = TRUE) #> # A tibble: 2,750 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable   .value #>    <int>  <int>      <int> <int> <chr>        <dbl> #>  1     1     NA         NA     1 M            0.777 #>  2     1     NA         NA     1 dprime       1.18  #>  3     1     NA         NA     1 c           -0.109 #>  4     1     NA         NA     1 meta_dprime  0.914 #>  5     1     NA         NA     1 meta_c      -0.109 #>  6     1     NA         NA     1 meta_c2_0_1 -0.342 #>  7     1     NA         NA     1 meta_c2_0_2 -1.01  #>  8     1     NA         NA     1 meta_c2_0_3 -1.54  #>  9     1     NA         NA     1 meta_c2_1_1  0.382 #> 10     1     NA         NA     1 meta_c2_1_2  1.03  #> # ℹ 2,740 more rows  # obtain model parameters (wide format, posterior::rvar) linpred_rvars_metad(m, newdata) #> # A tibble: 1 × 12 #> # Groups:   .row [1] #>    .row            M      dprime             c  meta_dprime        meta_c #>   <dbl>   <rvar[1d]>  <rvar[1d]>    <rvar[1d]>   <rvar[1d]>    <rvar[1d]> #> 1     1  0.52 ± 0.39  1.1 ± 0.24  -0.13 ± 0.13  0.52 ± 0.36  -0.13 ± 0.13 #> # ℹ 6 more variables: meta_c2_0_1 <rvar[1d]>, meta_c2_0_2 <rvar[1d]>, #> #   meta_c2_0_3 <rvar[1d]>, meta_c2_1_1 <rvar[1d]>, meta_c2_1_2 <rvar[1d]>, #> #   meta_c2_1_3 <rvar[1d]> add_linpred_rvars_metad(newdata, m) #> # A tibble: 1 × 12 #> # Groups:   .row [1] #>    .row            M      dprime             c  meta_dprime        meta_c #>   <dbl>   <rvar[1d]>  <rvar[1d]>    <rvar[1d]>   <rvar[1d]>    <rvar[1d]> #> 1     1  0.52 ± 0.39  1.1 ± 0.24  -0.13 ± 0.13  0.52 ± 0.36  -0.13 ± 0.13 #> # ℹ 6 more variables: meta_c2_0_1 <rvar[1d]>, meta_c2_0_2 <rvar[1d]>, #> #   meta_c2_0_3 <rvar[1d]>, meta_c2_1_1 <rvar[1d]>, meta_c2_1_2 <rvar[1d]>, #> #   meta_c2_1_3 <rvar[1d]>  # obtain model parameters (long format, posterior::rvar) linpred_rvars_metad(m, newdata, pivot_longer = TRUE) #> # A tibble: 11 × 3 #> # Groups:   .row, .variable [11] #>     .row .variable          .value #>    <dbl> <chr>          <rvar[1d]> #>  1     1 M             0.52 ± 0.39 #>  2     1 dprime        1.05 ± 0.24 #>  3     1 c            -0.13 ± 0.13 #>  4     1 meta_dprime   0.52 ± 0.36 #>  5     1 meta_c       -0.13 ± 0.13 #>  6     1 meta_c2_0_1  -0.43 ± 0.13 #>  7     1 meta_c2_0_2  -1.04 ± 0.15 #>  8     1 meta_c2_0_3  -1.61 ± 0.17 #>  9     1 meta_c2_1_1   0.32 ± 0.13 #> 10     1 meta_c2_1_2   0.79 ± 0.15 #> 11     1 meta_c2_1_3   1.40 ± 0.18 add_linpred_rvars_metad(newdata, m, pivot_longer = TRUE) #> # A tibble: 11 × 3 #> # Groups:   .row, .variable [11] #>     .row .variable          .value #>    <dbl> <chr>          <rvar[1d]> #>  1     1 M             0.52 ± 0.39 #>  2     1 dprime        1.05 ± 0.24 #>  3     1 c            -0.13 ± 0.13 #>  4     1 meta_dprime   0.52 ± 0.36 #>  5     1 meta_c       -0.13 ± 0.13 #>  6     1 meta_c2_0_1  -0.43 ± 0.13 #>  7     1 meta_c2_0_2  -1.04 ± 0.15 #>  8     1 meta_c2_0_3  -1.61 ± 0.17 #>  9     1 meta_c2_1_1   0.32 ± 0.13 #> 10     1 meta_c2_1_2   0.79 ± 0.15 #> 11     1 meta_c2_1_3   1.40 ± 0.18"},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of mean confidence — mean_confidence_draws","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"Computes posterior mean confidence conditional stimulus response (\\(\\mathbb{E}[C \\;\\vert\\; S=s,R=r]\\)), stimulus (averaging responses, \\(\\mathbb{E}[C \\;\\vert\\; S=s]\\)), response (averaging stimuli, \\(\\mathbb{E}[C \\;\\vert\\; R=r]\\)), neither (averaging stimuli responses, \\(\\mathbb{E}[C]\\)). mean_confidence_draws add_mean_confidence_draws, estimates returned tidy tibble one row per posterior draw, stimulus, response. mean_confidence_rvars add_mean_confidence_rvars, estimates returned posterior::rvars, one row per row newdata. add_mean_confidence_draws alias mean_confidence_draws argument order swapped.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"","code":"mean_confidence_draws(   object,   newdata,   ...,   by_stimulus = TRUE,   by_response = TRUE )  add_mean_confidence_draws(newdata, object, ...)  mean_confidence_rvars(   object,   newdata,   ...,   by_stimulus = TRUE,   by_response = TRUE )  add_mean_confidence_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments tidybayes::epred_draws tidybayes::epred_rvars by_stimulus TRUE, predict mean confidence separately stimulus. Otherwise, predict mean confidence averaging stimuli. by_response TRUE, predict mean confidence separately response Otherwise, predict mean confidence averaging responses.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"tibble containing posterior draws mean confidence following columns: .row: row newdata .chain, .iteration, .draw: mean_confidence_draws add_mean_confidence_draws, identifiers posterior sample stimulus: indicator stimulus presence (by_stimulus==TRUE) response: indicator type 1 response (by_response==TRUE) .epred: predicted mean confidence","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.034 seconds (Warm-up) #> Chain 1:                0.029 seconds (Sampling) #> Chain 1:                0.063 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # compute mean confidence by stimulus and response mean_confidence_draws(m, newdata) #> # A tibble: 1,000 × 7 #> # Groups:   .row, stimulus, response [4] #>     .row .chain .iteration .draw stimulus response .epred #>    <int>  <int>      <int> <int>    <int>    <int>  <dbl> #>  1     1     NA         NA     1        0        0   2.21 #>  2     1     NA         NA     1        0        1   1.98 #>  3     1     NA         NA     1        1        0   1.78 #>  4     1     NA         NA     1        1        1   2.42 #>  5     1     NA         NA     2        0        0   2.23 #>  6     1     NA         NA     2        0        1   1.76 #>  7     1     NA         NA     2        1        0   1.43 #>  8     1     NA         NA     2        1        1   2.48 #>  9     1     NA         NA     3        0        0   2.26 #> 10     1     NA         NA     3        0        1   2.01 #> # ℹ 990 more rows add_mean_confidence_draws(newdata, m) #> # A tibble: 1,000 × 7 #> # Groups:   .row, stimulus, response [4] #>     .row .chain .iteration .draw stimulus response .epred #>    <int>  <int>      <int> <int>    <int>    <int>  <dbl> #>  1     1     NA         NA     1        0        0   2.21 #>  2     1     NA         NA     1        0        1   1.98 #>  3     1     NA         NA     1        1        0   1.78 #>  4     1     NA         NA     1        1        1   2.42 #>  5     1     NA         NA     2        0        0   2.23 #>  6     1     NA         NA     2        0        1   1.76 #>  7     1     NA         NA     2        1        0   1.43 #>  8     1     NA         NA     2        1        1   2.48 #>  9     1     NA         NA     3        0        0   2.26 #> 10     1     NA         NA     3        0        1   2.01 #> # ℹ 990 more rows  # compute mean confidence by stimulus mean_confidence_draws(m, newdata, by_response = FALSE) #> # A tibble: 500 × 6 #> # Groups:   .row, stimulus [2] #>     .row .chain .iteration .draw stimulus .epred #>    <int>  <int>      <int> <int>    <int>  <dbl> #>  1     1     NA         NA     1        0   2.14 #>  2     1     NA         NA     1        1   2.25 #>  3     1     NA         NA     2        0   2.14 #>  4     1     NA         NA     2        1   2.06 #>  5     1     NA         NA     3        0   2.20 #>  6     1     NA         NA     3        1   2.13 #>  7     1     NA         NA     4        0   2.15 #>  8     1     NA         NA     4        1   2.06 #>  9     1     NA         NA     5        0   2.09 #> 10     1     NA         NA     5        1   2.08 #> # ℹ 490 more rows  # compute mean confidence by response mean_confidence_draws(m, newdata, by_stimulus = FALSE) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row .chain .iteration .draw response .epred #>    <int>  <int>      <int> <int>    <int>  <dbl> #>  1     1     NA         NA     1        0   2.09 #>  2     1     NA         NA     1        1   2.29 #>  3     1     NA         NA     2        0   1.96 #>  4     1     NA         NA     2        1   2.31 #>  5     1     NA         NA     3        0   2.14 #>  6     1     NA         NA     3        1   2.20 #>  7     1     NA         NA     4        0   2.11 #>  8     1     NA         NA     4        1   2.09 #>  9     1     NA         NA     5        0   1.94 #> 10     1     NA         NA     5        1   2.30 #> # ℹ 490 more rows  # compute mean confidence averaging over stimuli and responses mean_confidence_draws(m, newdata, by_stimulus = FALSE, by_response = FALSE) #> # A tibble: 250 × 5 #> # Groups:   .row [1] #>     .row .chain .iteration .draw .epred #>    <int>  <int>      <int> <int>  <dbl> #>  1     1     NA         NA     1   2.20 #>  2     1     NA         NA     2   2.10 #>  3     1     NA         NA     3   2.16 #>  4     1     NA         NA     4   2.10 #>  5     1     NA         NA     5   2.08 #>  6     1     NA         NA     6   2.12 #>  7     1     NA         NA     7   2.28 #>  8     1     NA         NA     8   2.21 #>  9     1     NA         NA     9   2.14 #> 10     1     NA         NA    10   2.21 #> # ℹ 240 more rows  # use posterior::rvar for increased efficiency mean_confidence_rvars(m, newdata) #> # A tibble: 4 × 4 #> # Groups:   .row, stimulus, response [4] #>    .row stimulus response      .epred #>   <int>    <int>    <int>  <rvar[1d]> #> 1     1        0        0  2.3 ± 0.17 #> 2     1        0        1  1.8 ± 0.22 #> 3     1        1        0  1.7 ± 0.20 #> 4     1        1        1  2.3 ± 0.18"},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":null,"dir":"Reference","previous_headings":"","what":"brms family for the metad' model — metad","title":"brms family for the metad' model — metad","text":"brms family metad' model","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"brms family for the metad' model — metad","text":"","code":"metad(K, distribution = \"normal\", metac_absolute = TRUE, categorical = FALSE)"},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"brms family for the metad' model — metad","text":"K number confidence levels distribution noise distribution use signal detection model metac_absolute TRUE, fix type 2 criterion equal type 1 criterion. Otherwise, equate criteria relatively $$\\frac{\\textrm{meta-}c}{\\textrm{meta-}d'} = \\frac{c}{d'}$$ categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"brms family for the metad' model — metad","text":"brms family metad' model \\(K\\) confidence levels","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"brms family for the metad' model — metad","text":"","code":"# create a family using the normal distribution and 3 levels of confidence metad(3) #>  #> Custom family: metad__3__normal__absolute__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2one1diff, metac2one2diff  #>   # create a family with meta_c = M * c metad(3, metac_absolute = FALSE) #>  #> Custom family: metad__3__normal__relative__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2one1diff, metac2one2diff  #>   # create a family with an alternative distribution # note: cumulative distribution functions must be defined # in R and in Stan using [brms::stanvar()] metad(4, distribution = \"gumbel_min\") #>  #> Custom family: metad__4__gumbel_min__absolute__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2zero3diff, metac2one1diff, metac2one2diff, metac2one3diff  #>"},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"Generate (log) probability simplex joint type 1/type 2 responses","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"","code":"metad_pmf(   stimulus,   dprime,   c,   meta_dprime,   meta_c,   meta_c2_0,   meta_c2_1,   lcdf = normal_lcdf,   lccdf = normal_lccdf,   log = FALSE )"},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"stimulus stimulus (0 1) dprime type 1 sensitivity c type 1 response criterion meta_dprime type 2 sensitivity meta_c type 1 criteriom generating confidence ratings meta_c2_0 type 2 response criteria \"0\" responses, indexed increasing confidence levels meta_c2_1 type 2 response criteria \"1\" responses, indexed increasing confidence levels lcdf log cumulative distribution function underlying distribution metad' model. default, uses normal distribution standard deviation 1. lccdf log complement cumulative distribution function underlying distribution metad' model. default, uses normal distribution standard deviation 1. log TRUE, return log probabilities instead probabilities","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"probability simplex $$\\begin{bmatrix} P(R=0, C=K \\vert S=0), \\ldots, P(R=0, C=1 \\vert S=0), P(R=0, C=1 \\vert S=1), \\ldots, P(R=1, C=1 \\vert S=1)\\end{bmatrix}$$ response \\(R\\) confidence \\(C\\) given stimulus \\(S\\), defined meta-d' model.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"","code":"metad_pmf(   stimulus = 0, dprime = 2, c = .5, meta_dprime = 1, meta_c = .5,   meta_c2_0 = c(0, -.5), meta_c2_1 = c(1, 1.5) ) #> [1] 0.554584077 0.212364065 0.166244657 0.038675753 0.018551730 0.009579718"},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal cumulative distribution functions — normal_lcdf","title":"Normal cumulative distribution functions — normal_lcdf","text":"Normal cumulative distribution functions","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal cumulative distribution functions — normal_lcdf","text":"","code":"normal_lcdf(x, mu)  normal_lccdf(x, mu)"},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal cumulative distribution functions — normal_lcdf","text":"x quantile evaluate l(c)cdf mu mean normal distribution","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal cumulative distribution functions — normal_lcdf","text":"\\(log(P(X < x))\\) (normal_lcdf) \\(log(P(X > x))\\) (normal_lccdf) \\(X\\) sampled normal distribution mean mu standard deviation \\(1\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal cumulative distribution functions — normal_lcdf","text":"","code":"normal_lcdf(0, mu = 1) #> [1] -1.841022 normal_lccdf(0, mu = 1) #> [1] -0.1727538"},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior predictions of joint responses — predicted_draws_metad","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"Given data frame meta-d' model, adds predictions joint type 1 type 2 responses predicted_draws_metad add_predicted_draws_metad, predictions returned tidy tibble one row per posterior draw. predicted_rvars_metad add_predicted_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"","code":"predicted_draws_metad(object, newdata, ...)  add_predicted_draws_metad(newdata, object, ...)  predicted_rvars_metad(object, newdata, ...)  add_predicted_rvars_metad(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_predicted_draws tidybayes::add_predicted_rvars","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: predicted_draws_metad, identifiers posterior sample stimulus, joint_response, response, confidence: identifiers response type .prediction: predicted type 1 type 2 responses given stimulus","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.7e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.032 seconds (Warm-up) #> Chain 1:                0.026 seconds (Sampling) #> Chain 1:                0.058 seconds (Total) #> Chain 1:  #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess  # obtain model predictions predicted_draws_metad(m, m$data) add_predicted_draws_metad(m$data, m)  # obtain model predictions (posterior::rvar) predicted_rvars_metad(m, m$data) #> # A tibble: 16 × 7 #> # Groups:   .row, N, stimulus, joint_response, response, confidence [16] #>     .row N[,\"N_0_1\"] stimulus joint_response response confidence  .prediction #>    <int>       <int>    <int>          <int>    <int>      <dbl>   <rvar[1d]> #>  1     1          11        0              1        0          4   9.87 ± 4.0 #>  2     1          11        0              2        0          3   8.94 ± 3.6 #>  3     1          11        0              3        0          2   8.37 ± 3.2 #>  4     1          11        0              4        0          1  12.25 ± 4.2 #>  5     1          11        0              5        1          1   4.24 ± 2.5 #>  6     1          11        0              6        1          2   3.62 ± 2.4 #>  7     1          11        0              7        1          3   1.74 ± 1.6 #>  8     1          11        0              8        1          4   0.98 ± 1.1 #>  9     1          11        1              1        0          4   2.76 ± 2.1 #> 10     1          11        1              2        0          3   3.52 ± 2.1 #> 11     1          11        1              3        0          2   4.47 ± 2.3 #> 12     1          11        1              4        0          1   8.98 ± 3.7 #> 13     1          11        1              5        1          1   8.75 ± 3.7 #> 14     1          11        1              6        1          2   9.77 ± 3.7 #> 15     1          11        1              7        1          3   6.17 ± 3.1 #> 16     1          11        1              8        1          4   5.57 ± 2.9 #> # ℹ 1 more variable: N[2:16] <int> add_predicted_rvars_metad(m$data, m) #> # A tibble: 16 × 7 #> # Groups:   .row, N, stimulus, joint_response, response, confidence [16] #>     .row N[,\"N_0_1\"] stimulus joint_response response confidence .prediction #>    <int>       <int>    <int>          <int>    <int>      <dbl>  <rvar[1d]> #>  1     1          11        0              1        0          4   9.9 ± 3.8 #>  2     1          11        0              2        0          3   9.2 ± 3.4 #>  3     1          11        0              3        0          2   8.1 ± 3.3 #>  4     1          11        0              4        0          1  11.7 ± 4.1 #>  5     1          11        0              5        1          1   4.4 ± 2.5 #>  6     1          11        0              6        1          2   3.7 ± 2.3 #>  7     1          11        0              7        1          3   1.7 ± 1.5 #>  8     1          11        0              8        1          4   1.1 ± 1.2 #>  9     1          11        1              1        0          4   2.6 ± 2.1 #> 10     1          11        1              2        0          3   3.6 ± 2.1 #> 11     1          11        1              3        0          2   4.5 ± 2.6 #> 12     1          11        1              4        0          1   8.9 ± 3.7 #> 13     1          11        1              5        1          1   9.0 ± 3.6 #> 14     1          11        1              6        1          2   9.8 ± 3.5 #> 15     1          11        1              7        1          3   6.1 ± 3.0 #> 16     1          11        1              8        1          4   5.6 ± 2.9 #> # ℹ 1 more variable: N[2:16] <int>"},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute joint response probabilities from aggregated counts — response_probabilities","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"Compute joint response probabilities aggregated counts","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"","code":"response_probabilities(counts)"},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"counts vector (matrix) counts joint type 1/type 2 responses provided aggregate_metad","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"vector (matrix) response probabilities \\(P(R, C \\;\\vert\\; S)\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"response \\(R\\), confidence \\(C\\), stimulus \\(S\\), number confidence levels \\(K\\), counts vector (matrix rows) form: $$  [N_{S=0, R=0, C=K}, \\ldots, N_{S=0, R=0, C=1}, \\\\  N_{S=0, R=1, C=1}, \\ldots, N_{S=0, R=1, C=K}, \\\\  N_{S=1, R=0, C=K}, \\ldots, N_{S=1, R=0, C=1}, \\\\  N_{S=1, R=1, C=1}, \\ldots, N_{S=1, R=1, C=K}] \\\\ $$ Returns vector (matrix rows) form: $$ [P(R=0, C=K \\;\\vert\\; S=0), ..., P(R=0, C=1 \\;\\vert\\; S=0), \\\\  P(R=1, C=1 \\;\\vert\\; S=0), ..., P(R=1, C=K \\;\\vert\\; S=0), \\\\  P(R=0, C=K \\;\\vert\\; S=1), ..., P(R=0, C=1 \\;\\vert\\; S=1), \\\\  P(R=1, C=1 \\;\\vert\\; S=1), ..., P(R=1, C=K \\;\\vert\\; S=1)] $$","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"","code":"# Aggregate responses from simulated data d <- sim_metad() |> aggregate_metad()  # Compute conditional response probabilities response_probabilities(d$N) #>      N_0_1 N_0_2 N_0_3 N_0_4 N_0_5 N_0_6 N_0_7 N_0_8 N_1_1 N_1_2 N_1_3 N_1_4 #> [1,]  0.12  0.12   0.1   0.2  0.24  0.16  0.06     0  0.02  0.02   0.1  0.26 #>      N_1_5 N_1_6 N_1_7 N_1_8 #> [1,]  0.12  0.18  0.16  0.14  # Also works on matrices matrix(rep(1, 16), nrow = 2) |> response_probabilities() #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #> [1,] 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 #> [2,] 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25"},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between separate and joint type 1/type 2 responses — joint_response","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"Confidence ratings decisions collected one two ways. separate ratings, type 1 response (\\(R \\\\{0, 1\\}\\)) type 2 response (\\(C \\[1, K]\\)). joint ratings, instead combined type 1/type 2 response (\\(J \\[1, 2K]\\)), values \\([1, K]\\) indicating type 1 response \\(0\\) values \\([K+1, 2K]\\) indicating type 1 response \\(1\\), confident responses ends scale. joint_response converts separate type 1 type 2 responses joint format type1_response type2_response convert joint response separate responses.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"","code":"joint_response(response, confidence, K)  type1_response(joint_response, K)  type2_response(joint_response, K)"},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"response type 1 response (0 1) confidence type 2 response/confidence rating (1:K) K number confidence levels joint_response joint type 1/type 2 response","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"","code":"# convert joint_response to separate responses joint <- 1:8 K <- 4 type1_response(joint, K) #> [1] 0 0 0 0 1 1 1 1 type2_response(joint, K) #> [1] 4 3 2 1 1 2 3 4  # convert separate responses to a joint response t1 <- rep(c(0, 1), each = 4) t2 <- c(4:1, 1:4) joint_response(t1, t2, K) #> [1] 1 2 3 4 5 6 7 8"},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a matrix-normal distribution — rmatrixnorm","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"Sample matrix-normal distribution","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"","code":"rmatrixnorm(mu, L_sigma_rows, L_sigma_cols)"},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"mu matrix means L_sigma_rows Cholesky-decomposed covariance matrix rows L_sigma_cols Cholesky-decomposed covariance matrix columns","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"single sample matrix-normal distribution mean mu (matrix), row-wise covariances sigma_rows, column-wise covariances sigma_cols, L_sigma_rows L_sigma_cols Cholesky-decomposed covariance matrices","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"","code":"mu <- matrix(rep(0, 8), nrow = 4) sd_rows <- rep(1, 4) sd_cols <- rep(1, 2) r_rows <- cor_matrix(.25, 4) r_cols <- cor_matrix(.75, 2) L_sigma_rows <- chol(cov_matrix(sd_rows, r_rows)) L_sigma_cols <- chol(cov_matrix(sd_cols, r_cols)) rmatrixnorm(mu, L_sigma_rows, L_sigma_cols) #>            [,1]       [,2] #> [1,]  2.8136991  2.0018524 #> [2,]  0.9433234  1.7617484 #> [3,]  0.7674802  0.3909412 #> [4,] -0.1663155 -0.7883861"},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"Given data frame meta-d' model, adds estimates cumulative probability joint_responses. roc1_draws add_roc1_draws, estimates returned tidy tibble one row per posterior draw per joint response. roc1_rvars add_roc1_rvars, parameters returned posterior::rvars, one row per row newdata per joint response.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"","code":"roc1_draws(object, newdata, ..., bounds = FALSE)  add_roc1_draws(newdata, object, ...)  roc1_rvars(object, newdata, ..., bounds = FALSE)  add_roc1_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws tidybayes::epred_rvars bounds TRUE, include endpoints ROC \\((0, 0)\\) \\((1, 1)\\). Otherwise, endpoints excluded.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"tibble containing posterior draws pseudo type 1 ROC following columns: .row: row newdata .chain, .iteration, .draw: roc1_draws add_roc1_draws, identifiers posterior sample joint_response: combined type 1 / type 2 response (\\(J \\[1, 2K]\\)) \\(K\\) confidence levels) response: type 1 response perceived stimulus presence (\\(R \\\\{0, 1\\}\\)) confidence: type 2 confidence response (\\(C \\[1, K]\\)) p_fa: cumulative probability 'present'/'old' response stimulus==0 (\\(P(J \\ge j \\;\\vert\\; S=0)\\)) p_hit: cumulative probability 'present'/'old' response stimulus==1 (\\(P(J \\ge j \\;\\vert\\; S=1)\\))","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.7e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.039 seconds (Warm-up) #> Chain 1:                0.049 seconds (Sampling) #> Chain 1:                0.088 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.07, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # compute pseudo-type 1 ROC curve roc1_draws(m, newdata) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.784 0.976 #>  2     1              1        0          4     NA         NA     2 0.767 0.956 #>  3     1              1        0          4     NA         NA     3 0.765 0.957 #>  4     1              1        0          4     NA         NA     4 0.865 0.985 #>  5     1              1        0          4     NA         NA     5 0.770 0.915 #>  6     1              1        0          4     NA         NA     6 0.798 0.964 #>  7     1              1        0          4     NA         NA     7 0.888 0.971 #>  8     1              1        0          4     NA         NA     8 0.730 0.947 #>  9     1              1        0          4     NA         NA     9 0.851 0.962 #> 10     1              1        0          4     NA         NA    10 0.728 0.981 #> # ℹ 1,740 more rows add_roc1_draws(newdata, m) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.784 0.976 #>  2     1              1        0          4     NA         NA     2 0.767 0.956 #>  3     1              1        0          4     NA         NA     3 0.765 0.957 #>  4     1              1        0          4     NA         NA     4 0.865 0.985 #>  5     1              1        0          4     NA         NA     5 0.770 0.915 #>  6     1              1        0          4     NA         NA     6 0.798 0.964 #>  7     1              1        0          4     NA         NA     7 0.888 0.971 #>  8     1              1        0          4     NA         NA     8 0.730 0.947 #>  9     1              1        0          4     NA         NA     9 0.851 0.962 #> 10     1              1        0          4     NA         NA    10 0.728 0.981 #> # ℹ 1,740 more rows  # use posterior::rvar for additional efficiency roc1_rvars(m, newdata) #> # A tibble: 7 × 6 #> # Groups:   .row, joint_response, response, confidence [7] #>    .row joint_response response confidence           p_fa         p_hit #>   <int>          <int>    <int>      <dbl>     <rvar[1d]>    <rvar[1d]> #> 1     1              1        0          4  0.804 ± 0.051  0.96 ± 0.016 #> 2     1              2        0          3  0.657 ± 0.064  0.93 ± 0.025 #> 3     1              3        0          2  0.447 ± 0.059  0.87 ± 0.042 #> 4     1              4        0          1  0.237 ± 0.056  0.81 ± 0.057 #> 5     1              5        1          1  0.135 ± 0.037  0.52 ± 0.067 #> 6     1              6        1          2  0.066 ± 0.026  0.29 ± 0.063 #> 7     1              7        1          3  0.025 ± 0.013  0.12 ± 0.041 add_roc1_draws(newdata, m) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.784 0.976 #>  2     1              1        0          4     NA         NA     2 0.767 0.956 #>  3     1              1        0          4     NA         NA     3 0.765 0.957 #>  4     1              1        0          4     NA         NA     4 0.865 0.985 #>  5     1              1        0          4     NA         NA     5 0.770 0.915 #>  6     1              1        0          4     NA         NA     6 0.798 0.964 #>  7     1              1        0          4     NA         NA     7 0.888 0.971 #>  8     1              1        0          4     NA         NA     8 0.730 0.947 #>  9     1              1        0          4     NA         NA     9 0.851 0.962 #> 10     1              1        0          4     NA         NA    10 0.728 0.981 #> # ℹ 1,740 more rows  # include the ROC bounds roc1_draws(m, newdata, bounds = TRUE) #> # A tibble: 2,250 × 9 #> # Groups:   .row, joint_response, response, confidence [9] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <dbl>    <dbl>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              0        0          5     NA         NA     1     1     1 #>  2     1              0        0          5     NA         NA     2     1     1 #>  3     1              0        0          5     NA         NA     3     1     1 #>  4     1              0        0          5     NA         NA     4     1     1 #>  5     1              0        0          5     NA         NA     5     1     1 #>  6     1              0        0          5     NA         NA     6     1     1 #>  7     1              0        0          5     NA         NA     7     1     1 #>  8     1              0        0          5     NA         NA     8     1     1 #>  9     1              0        0          5     NA         NA     9     1     1 #> 10     1              0        0          5     NA         NA    10     1     1 #> # ℹ 2,240 more rows"},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"Given data frame meta-d' model, adds estimates cumulative probability confidence type 1 response. roc2_draws add_roc2_draws, estimates returned tidy tibble one row per posterior draw per joint response. roc2_rvars add_roc2_rvars, parameters returned posterior::rvars, one row per row newdata per joint response.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"","code":"roc2_draws(object, newdata, ..., bounds = FALSE)  add_roc2_draws(newdata, object, ...)  roc2_rvars(object, newdata, ..., bounds = FALSE)  add_roc2_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws bounds TRUE, include endpoints ROC \\((0, 0)\\) \\((1, 1)\\). Otherwise, endpoints excluded.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"tibble containing posterior draws pseudo type 1 ROC following columns: .row: row newdata .chain, .iteration, .draw: roc2_draws add_roc2_draws, identifiers posterior sample response: type 1 response perceived stimulus presence (\\(R \\\\{0, 1\\}\\)) confidence: type 2 confidence response (\\(C \\[1, K]\\)) p_fa2: cumulative probability incorrect response (\\(P(C\\ge c \\;\\vert\\; R\\ne S)\\)) p_hit2: cumulative probability correct response (\\(P(C\\ge c \\;\\vert\\; R = S)\\))","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.032 seconds (Warm-up) #> Chain 1:                0.023 seconds (Sampling) #> Chain 1:                0.055 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.06, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # compute type 2 ROC curve roc2_draws(m, newdata) #> # A tibble: 1,500 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.120 0.0304 #>  2     1        0          4     NA         NA     2  0.183 0.0186 #>  3     1        0          4     NA         NA     3  0.191 0.0911 #>  4     1        0          4     NA         NA     4  0.151 0.0597 #>  5     1        0          4     NA         NA     5  0.132 0.0363 #>  6     1        0          4     NA         NA     6  0.163 0.0860 #>  7     1        0          4     NA         NA     7  0.369 0.199  #>  8     1        0          4     NA         NA     8  0.282 0.0504 #>  9     1        0          4     NA         NA     9  0.209 0.0710 #> 10     1        0          4     NA         NA    10  0.223 0.0773 #> # ℹ 1,490 more rows add_roc2_draws(newdata, m) #> # A tibble: 1,500 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.120 0.0304 #>  2     1        0          4     NA         NA     2  0.183 0.0186 #>  3     1        0          4     NA         NA     3  0.191 0.0911 #>  4     1        0          4     NA         NA     4  0.151 0.0597 #>  5     1        0          4     NA         NA     5  0.132 0.0363 #>  6     1        0          4     NA         NA     6  0.163 0.0860 #>  7     1        0          4     NA         NA     7  0.369 0.199  #>  8     1        0          4     NA         NA     8  0.282 0.0504 #>  9     1        0          4     NA         NA     9  0.209 0.0710 #> 10     1        0          4     NA         NA    10  0.223 0.0773 #> # ℹ 1,490 more rows  # use posterior::rvar for additional efficiency roc2_rvars(m, newdata) #> # A tibble: 6 × 5 #> # Groups:   .row, response, confidence [6] #>    .row response confidence        p_hit2          p_fa2 #>   <int>    <int>      <dbl>    <rvar[1d]>     <rvar[1d]> #> 1     1        0          2  0.74 ± 0.064  0.525 ± 0.096 #> 2     1        0          3  0.48 ± 0.078  0.243 ± 0.089 #> 3     1        0          4  0.21 ± 0.067  0.068 ± 0.045 #> 4     1        1          1  0.71 ± 0.065  0.488 ± 0.100 #> 5     1        1          2  0.42 ± 0.075  0.190 ± 0.075 #> 6     1        1          3  0.19 ± 0.063  0.055 ± 0.036 add_roc2_rvars(newdata, m) #> # A tibble: 6 × 5 #> # Groups:   .row, response, confidence [6] #>    .row response confidence        p_hit2          p_fa2 #>   <int>    <int>      <dbl>    <rvar[1d]>     <rvar[1d]> #> 1     1        0          2  0.74 ± 0.064  0.525 ± 0.096 #> 2     1        0          3  0.48 ± 0.078  0.243 ± 0.089 #> 3     1        0          4  0.21 ± 0.067  0.068 ± 0.045 #> 4     1        1          1  0.71 ± 0.065  0.488 ± 0.100 #> 5     1        1          2  0.42 ± 0.075  0.190 ± 0.075 #> 6     1        1          3  0.19 ± 0.063  0.055 ± 0.036  # include the ROC bounds roc2_draws(m, newdata, bounds = TRUE) #> # A tibble: 2,500 × 8 #> # Groups:   .row, response, confidence [10] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <dbl>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.120 0.0304 #>  2     1        0          4     NA         NA     2  0.183 0.0186 #>  3     1        0          4     NA         NA     3  0.191 0.0911 #>  4     1        0          4     NA         NA     4  0.151 0.0597 #>  5     1        0          4     NA         NA     5  0.132 0.0363 #>  6     1        0          4     NA         NA     6  0.163 0.0860 #>  7     1        0          4     NA         NA     7  0.369 0.199  #>  8     1        0          4     NA         NA     8  0.282 0.0504 #>  9     1        0          4     NA         NA     9  0.209 0.0710 #> 10     1        0          4     NA         NA    10  0.223 0.0773 #> # ℹ 2,490 more rows"},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"to_signed(x) converts \\(x \\\\{0, 1\\}\\) \\(x' \\\\{-1, 1\\}\\) to_unsigned(x) converts \\(x \\\\{-1, 1\\}\\) \\(x' \\\\{0, 1\\}\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"","code":"to_signed(x)  to_unsigned(x)"},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"x binary variable","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"signed (to_signed) unsigned (to_unsigned) version x","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"","code":"# should return `1` to_signed(0) #> [1] -1  # should return `1` to_signed(1) #> [1] 1  # should return `0` to_unsigned(-1) #> [1] 0  # should return `1` to_unsigned(1) #> [1] 1  # `to_signed` also works with objects `R` interprets as `0` or `1` to_signed(10) #> [1] 1  # `to_unsigned` also works with any signed integer to_unsigned(-10) #> [1] 0  # neither function works with factors to_unsigned(factor(1)) #> Warning: ‘>’ not meaningful for factors #> [1] NA"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the meta-d' model — sim_metad","title":"Simulate from the meta-d' model — sim_metad","text":"Generate simulated dataset meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the meta-d' model — sim_metad","text":"","code":"sim_metad(   N_trials = 100,   dprime = 1,   c = 0,   log_M = 0,   c2_0_diff = rep(0.5, 3),   c2_1_diff = rep(0.5, 3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the meta-d' model — sim_metad","text":"N_trials Total number trials simulate. Half trials stimulus=0 half stimulus=1. dprime sensitivity signal detection agent simulate c response bias signal detection agent simulate log_M metacognitive efficiency agent logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. c2_0_diff, c2_1_diff Distances confidence thresholds \"0\" \"1\" responses, meta_c2_0 = meta_c - cumsum(c2_0_diff) meta_c2_1 = meta_c + cumsum(c2_1_diff). metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf, lccdf log (complement) cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the meta-d' model — sim_metad","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the meta-d' model — sim_metad","text":"","code":"sim_metad(N_trials = 10) #> # A tibble: 10 × 14 #> # Groups:   stimulus, response, confidence [8] #>    trial stimulus response correct confidence dprime     c meta_dprime     M #>    <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> <dbl> #>  1     1        0        0       1          1      1     0           1     1 #>  2     2        0        0       1          2      1     0           1     1 #>  3     3        0        0       1          2      1     0           1     1 #>  4     4        0        0       1          4      1     0           1     1 #>  5     5        0        1       0          1      1     0           1     1 #>  6     1        1        1       1          1      1     0           1     1 #>  7     2        1        1       1          2      1     0           1     1 #>  8     3        1        1       1          2      1     0           1     1 #>  9     4        1        1       1          3      1     0           1     1 #> 10     5        1        1       1          4      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad(N_trials = 10000, summarize = TRUE) #> # A tibble: 16 × 14 #> # Groups:   stimulus [2] #>    stimulus response correct confidence     n dprime     c meta_dprime     M #>       <int>    <int>   <int>      <int> <int>  <dbl> <dbl>       <dbl> <dbl> #>  1        0        0       1          1   954      1     0           1     1 #>  2        0        0       1          2   983      1     0           1     1 #>  3        0        0       1          3   725      1     0           1     1 #>  4        0        0       1          4   809      1     0           1     1 #>  5        0        1       0          1   757      1     0           1     1 #>  6        0        1       0          2   439      1     0           1     1 #>  7        0        1       0          3   231      1     0           1     1 #>  8        0        1       0          4   102      1     0           1     1 #>  9        1        0       0          1   741      1     0           1     1 #> 10        1        0       0          2   445      1     0           1     1 #> 11        1        0       0          3   211      1     0           1     1 #> 12        1        0       0          4   125      1     0           1     1 #> 13        1        1       1          1   952      1     0           1     1 #> 14        1        1       1          2   948      1     0           1     1 #> 15        1        1       1          3   736      1     0           1     1 #> 16        1        1       1          4   842      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad(N_trials = 10, c2_0_diff = 1, c2_1_diff = 1) #> # A tibble: 10 × 14 #> # Groups:   stimulus, response, confidence [6] #>    trial stimulus response correct confidence dprime     c meta_dprime     M #>    <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> <dbl> #>  1     1        0        0       1          1      1     0           1     1 #>  2     2        0        0       1          2      1     0           1     1 #>  3     3        0        0       1          2      1     0           1     1 #>  4     4        0        1       0          1      1     0           1     1 #>  5     5        0        1       0          1      1     0           1     1 #>  6     1        1        0       0          1      1     0           1     1 #>  7     2        1        0       0          1      1     0           1     1 #>  8     3        1        1       1          1      1     0           1     1 #>  9     4        1        1       1          2      1     0           1     1 #> 10     5        1        1       1          2      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"Generate simulated dataset across separate conditions meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"","code":"sim_metad_condition(   N_trials = 100,   dprime = rep(1, 2),   c = rep(0, 2),   log_M = rep(0, 2),   c2_0_diff = list(rep(0.5, 3), rep(0.5, 3)),   c2_1_diff = list(rep(0.5, 3), rep(0.5, 3)),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"N_trials Total number trials simulate. Half trials stimulus=0 half stimulus=1. dprime sensitivity signal detection agent simulate c response bias signal detection agent simulate log_M metacognitive efficiency agent logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. c2_0_diff, c2_1_diff Distances confidence thresholds \"0\" \"1\" responses, meta_c2_0 = meta_c - cumsum(c2_0_diff) meta_c2_1 = meta_c + cumsum(c2_1_diff). metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf, lccdf log (complement) cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number condition: simulated condition number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"","code":"sim_metad_condition(N_trials = 10) #> # A tibble: 20 × 15 #>    condition trial stimulus response correct confidence dprime     c meta_dprime #>        <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> #>  1         1     1        0        0       1          1      1     0           1 #>  2         1     2        0        0       1          2      1     0           1 #>  3         1     3        0        0       1          4      1     0           1 #>  4         1     4        0        1       0          1      1     0           1 #>  5         1     5        0        1       0          1      1     0           1 #>  6         1     1        1        0       0          3      1     0           1 #>  7         1     2        1        1       1          1      1     0           1 #>  8         1     3        1        1       1          2      1     0           1 #>  9         1     4        1        1       1          3      1     0           1 #> 10         1     5        1        1       1          4      1     0           1 #> 11         2     1        0        0       1          2      1     0           1 #> 12         2     2        0        0       1          2      1     0           1 #> 13         2     3        0        0       1          3      1     0           1 #> 14         2     4        0        1       0          1      1     0           1 #> 15         2     5        0        1       0          2      1     0           1 #> 16         2     1        1        1       1          2      1     0           1 #> 17         2     2        1        1       1          2      1     0           1 #> 18         2     3        1        1       1          3      1     0           1 #> 19         2     4        1        1       1          3      1     0           1 #> 20         2     5        1        1       1          4      1     0           1 #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad_condition(N_trials = 10000, summarize = TRUE) #> # A tibble: 32 × 15 #>    condition stimulus response correct confidence     n dprime     c meta_dprime #>        <int>    <int>    <int>   <int>      <int> <int>  <dbl> <dbl>       <dbl> #>  1         1        0        0       1          1  1008      1     0           1 #>  2         1        0        0       1          2   927      1     0           1 #>  3         1        0        0       1          3   740      1     0           1 #>  4         1        0        0       1          4   826      1     0           1 #>  5         1        0        1       0          1   750      1     0           1 #>  6         1        0        1       0          2   420      1     0           1 #>  7         1        0        1       0          3   215      1     0           1 #>  8         1        0        1       0          4   114      1     0           1 #>  9         1        1        0       0          1   779      1     0           1 #> 10         1        1        0       0          2   468      1     0           1 #> # ℹ 22 more rows #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad_condition(N_trials = 10, c2_0_diff = list(1, .5), c2_1_diff = list(1, .5)) #> # A tibble: 20 × 15 #>    condition trial stimulus response correct confidence dprime     c meta_dprime #>        <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> #>  1         1     1        0        0       1          1      1     0           1 #>  2         1     2        0        0       1          1      1     0           1 #>  3         1     3        0        0       1          1      1     0           1 #>  4         1     4        0        0       1          2      1     0           1 #>  5         1     5        0        0       1          2      1     0           1 #>  6         1     1        1        0       0          1      1     0           1 #>  7         1     2        1        1       1          1      1     0           1 #>  8         1     3        1        1       1          1      1     0           1 #>  9         1     4        1        1       1          1      1     0           1 #> 10         1     5        1        1       1          2      1     0           1 #> 11         2     1        0        0       1          2      1     0           1 #> 12         2     2        0        0       1          2      1     0           1 #> 13         2     3        0        0       1          2      1     0           1 #> 14         2     4        0        0       1          2      1     0           1 #> 15         2     5        0        1       0          1      1     0           1 #> 16         2     1        1        0       0          1      1     0           1 #> 17         2     2        1        0       0          1      1     0           1 #> 18         2     3        1        0       0          2      1     0           1 #> 19         2     4        1        0       0          2      1     0           1 #> 20         2     5        1        1       1          2      1     0           1 #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the hierarchical meta-d' model — sim_metad_participant","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"Generate simulated dataset across participants meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"","code":"sim_metad_participant(   N_participants = 100,   N_trials = 100,   mu_dprime = 1,   sd_dprime = 0.5,   mu_c = 0,   sd_c = 0.5,   mu_log_M = 0,   sd_log_M = 0.5,   mu_z_c2_0 = rep(-1, 3),   sd_z_c2_0 = rep(0.1, 3),   r_z_c2_0 = diag(3),   mu_z_c2_1 = rep(-1, 3),   sd_z_c2_1 = rep(0.1, 3),   r_z_c2_1 = diag(3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"N_trials, N_participants Total number participants trials simulate per participant. Half trials stimulus=0 half stimulus=1. mu_dprime, sd_dprime mean standard deviation sensitivities signal detection agents simulate mu_c, sd_c mean standard deviation response bias signal detection agents simulate mu_log_M, sd_log_M mean standard deviation metacognitive efficiency agents logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. mu_z_c2_0, mu_z_c2_1 Mean distance confidence thresholds \"0\" \"1\" responses log_scale, meta_c2_0 = meta_c - cumulative_sum(exp(z_c2_0)) meta_c2_1 = meta_c + cumulative_sum(exp(z_c2_1)). sd_z_c2_0, sd_z_c2_1 SD log distances confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0, r_z_c2_1 Correlation log distances confidence thresholds \"0\" \"1\" responses log_scale. metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf log cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution. lccdf log complement cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number participant: simulated participant number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"","code":"sim_metad_participant(N_participants = 10, N_trials = 10) #> # A tibble: 100 × 15 #>    participant trial stimulus response correct confidence dprime     c #>          <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl> #>  1           1     1        0        0       1          4   1.02 0.579 #>  2           1     2        0        0       1          4   1.02 0.579 #>  3           1     3        0        0       1          4   1.02 0.579 #>  4           1     4        0        0       1          4   1.02 0.579 #>  5           1     5        0        0       1          4   1.02 0.579 #>  6           1     1        1        0       0          1   1.02 0.579 #>  7           1     2        1        1       1          1   1.02 0.579 #>  8           1     3        1        1       1          1   1.02 0.579 #>  9           1     4        1        1       1          3   1.02 0.579 #> 10           1     5        1        1       1          3   1.02 0.579 #> # ℹ 90 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl> sim_metad_participant(mu_dprime = 2, mu_log_M = -1) #> # A tibble: 10,000 × 15 #>    participant trial stimulus response correct confidence dprime      c #>          <int> <int>    <int>    <int>   <int>      <int>  <dbl>  <dbl> #>  1           1     1        0        0       1          1   1.61 -0.324 #>  2           1     2        0        0       1          1   1.61 -0.324 #>  3           1     3        0        0       1          1   1.61 -0.324 #>  4           1     4        0        0       1          1   1.61 -0.324 #>  5           1     5        0        0       1          1   1.61 -0.324 #>  6           1     6        0        0       1          1   1.61 -0.324 #>  7           1     7        0        0       1          1   1.61 -0.324 #>  8           1     8        0        0       1          1   1.61 -0.324 #>  9           1     9        0        0       1          2   1.61 -0.324 #> 10           1    10        0        0       1          2   1.61 -0.324 #> # ℹ 9,990 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"Generate simulated dataset across participants conditions meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"","code":"sim_metad_participant_condition(   N_participants = 100,   N_trials = 100,   mu_dprime = rep(1, 2),   sd_dprime = rep(0.5, 2),   r_dprime = diag(2),   mu_c = rep(0, 2),   sd_c = rep(0.5, 2),   r_c = diag(2),   mu_log_M = rep(0, 2),   sd_log_M = rep(0.5, 2),   r_log_M = diag(2),   mu_z_c2_0 = matrix(rep(-1, 6), nrow = 3, ncol = 2),   sd_z_c2_0_condition = rep(0.1, 2),   r_z_c2_0_condition = diag(2),   sd_z_c2_0_confidence = rep(0.1, 3),   r_z_c2_0_confidence = diag(3),   mu_z_c2_1 = matrix(rep(-1, 6), nrow = 3, ncol = 2),   sd_z_c2_1_condition = rep(0.1, 2),   r_z_c2_1_condition = diag(2),   sd_z_c2_1_confidence = rep(0.1, 3),   r_z_c2_1_confidence = diag(3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"N_trials, N_participants Total number participants trials simulate per participant. Half trials stimulus=0 half stimulus=1. mu_dprime, sd_dprime, r_dprime mean, standard deviation, within-participant correlations sensitivities signal detection agents simulate mu_c, sd_c, r_c mean, standard deviation, within-participant correlations response bias signal detection agents simulate mu_log_M, sd_log_M, r_log_M mean, standard deviation, within-participant correlations metacognitive efficiency agents logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. mu_z_c2_0, mu_z_c2_1 Mean distance confidence thresholds \"0\" \"1\" responses log_scale, meta_c2_0 = meta_c - cumulative_sum(exp(z_c2_0)) meta_c2_1 = meta_c + cumulative_sum(exp(z_c2_1)). sd_z_c2_0_condition, sd_z_c2_1_condition SD log distances across conditions confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0_condition, r_z_c2_1_condition Correlation across conditions log distances confidence thresholds \"0\" \"1\" responses log_scale. sd_z_c2_0_confidence, sd_z_c2_1_confidence SD log distances across confidence levels confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0_confidence, r_z_c2_1_confidence Correlation across confidence levels log distances confidence thresholds \"0\" \"1\" responses log_scale. metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf log cumulative distribution function underlying signal distribution. default, uses normal(+/- dprime/2, 1) distribution. lccdf log complement cumulative distribution function underlying signal distribution. default, uses normal(+/- dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"","code":"sim_metad_participant_condition(10, 10) #> # A tibble: 200 × 16 #>    participant condition trial stimulus response correct confidence dprime #>          <int>     <int> <int>    <int>    <int>   <int>      <int>  <dbl> #>  1           1         1     1        0        0       1          1  0.675 #>  2           1         1     2        0        0       1          1  0.675 #>  3           1         1     3        0        1       0          3  0.675 #>  4           1         1     4        0        1       0          3  0.675 #>  5           1         1     5        0        1       0          4  0.675 #>  6           1         1     1        1        0       0          1  0.675 #>  7           1         1     2        1        0       0          4  0.675 #>  8           1         1     3        1        1       1          1  0.675 #>  9           1         1     4        1        1       1          3  0.675 #> 10           1         1     5        1        1       1          4  0.675 #> # ℹ 190 more rows #> # ℹ 8 more variables: c <dbl>, meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Stan code for the meta-d' model — stanvars_metad","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"Generate Stan code meta-d' model","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"","code":"stanvars_metad(   K,   distribution = \"normal\",   metac_absolute = TRUE,   categorical = FALSE )"},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"K number confidence levels distribution noise distribution use. parameter-free distribution, .e., one mean-centered without additional variance/shape parameters. distribution already available stan, must additionally provide two functions Stan (one <distribution>_lcdf one <distribution>_lccdf). metac_absolute type 2 criterion (metac) fixed absolute type 1 criterion (c)? TRUE, model set metac = c. Otherwise, set metac = M * c, type 2 criterion relatively equal type 1 criterion (.e., meta_c/meta_dprime = c/dprime) categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"brms::stanvar object containing Stan code defining likelihood metad' model K confidence levels, signal distributed according distribution distribution, metac = c metac_absolute==TRUE, metac = M*c otherwise.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"","code":"# create stancode for the meta-d' model # using the normal distribution and 3 levels of confidence stanvars_metad(3) #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_normal_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = std_normal_lccdf(c - to_signed(stimulus)*dprime/2);\\n    real lp_0 = std_normal_lcdf(c - to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = std_normal_lccdf(meta_c - meta_mu);\\n    lp2_0[1] = std_normal_lcdf(meta_c - meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = std_normal_lccdf(meta_c2_1[k-1] - meta_mu);\\n      lp2_0[k] = std_normal_lcdf(meta_c2_0[k-1] - meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__3__normal__absolute__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_1_1, real z_meta_c2_1_2) {\\n  int K = 3; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_normal_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_normal_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\"  # create stancode for the meta-d' model with meta_c = M * c stanvars_metad(3, metac_absolute = FALSE) #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_normal_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = std_normal_lccdf(c - to_signed(stimulus)*dprime/2);\\n    real lp_0 = std_normal_lcdf(c - to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = std_normal_lccdf(meta_c - meta_mu);\\n    lp2_0[1] = std_normal_lcdf(meta_c - meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = std_normal_lccdf(meta_c2_1[k-1] - meta_mu);\\n      lp2_0[k] = std_normal_lcdf(meta_c2_0[k-1] - meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__3__normal__relative__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_1_1, real z_meta_c2_1_2) {\\n  int K = 3; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = M * c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_normal_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_normal_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\"  # create stancode for the meta-d' model with # an alternative distribution # note: cumulative distribution functions must be defined # in R and in Stan using [brms::stanvar()] stanvars_metad(4, distribution = \"gumbel_min\") #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_gumbel_min_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = gumbel_min_lccdf(c | to_signed(stimulus)*dprime/2);\\n    real lp_0 = gumbel_min_lcdf(c | to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = gumbel_min_lccdf(meta_c | meta_mu);\\n    lp2_0[1] = gumbel_min_lcdf(meta_c | meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = gumbel_min_lccdf(meta_c2_1[k-1] | meta_mu);\\n      lp2_0[k] = gumbel_min_lcdf(meta_c2_0[k-1] | meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__4__gumbel_min__absolute__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_0_3, real z_meta_c2_1_1, real z_meta_c2_1_2, real z_meta_c2_1_3) {\\n  int K = 4; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2, z_meta_c2_0_3]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2, z_meta_c2_1_3]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_gumbel_min_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_gumbel_min_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\""},{"path":"https://metacoglab.github.io/hmetad/news/index.html","id":"hmetad-001","dir":"Changelog","previous_headings":"","what":"hmetad 0.0.1","title":"hmetad 0.0.1","text":"Initial CRAN submission.","code":""}]
