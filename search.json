[{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using alternative signal distributions with the meta-d' model","text":"standard meta-d’ model assumes evidence making type 1 decisions follows equal-variance normal distribution evidence making type 2 decisions follows truncated equal-variance normal distribution. However, recent interest using distributions signal detection theory. distributions identifiable meta-d’ model (e.g., one simultaneously estimate unequal variances \\textrm{meta-}d'), hmetad package allows one specify distribution takes single parameter defining location (.e., mean, median, mode) distribution. demonstrate functionality, implement meta-d’ model Gumbel-min distribution, shown provide parsimonious explanation recognition memory data (Meyer-Grant et al., 2026). begin loading necessary packages R:","code":"library(tidyverse) library(brms) library(tidybayes) library(hmetad)"},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"implementing-a-distribution-function-for-use-with-hmetad","dir":"Articles","previous_headings":"","what":"Implementing a distribution function for use with hmetad","title":"Using alternative signal distributions with the meta-d' model","text":"order distribution used hmetad package, one needs implement cumulative distribution functions R Stan. Specifically, since hmetad package computes model likelihood logarithmic scale, one must define: <distribution>_lcdf(x, mu): log cumulative distribution function defining \\textrm{log } P(X \\le x) random variable X \\sim \\textrm{distribution}(\\mu). <distribution>_lccdf(x, mu): log complementary cumulative distribution function defining \\textrm{log } P(X \\ge x) random variable X \\sim \\textrm{distribution}(\\mu). Please note use hmetad package, two functions must use naming scheme (.e., must named <distribution>_l(c)cdf). example, can write gumbel min distribution functions R follows: One also needs implement two functions Stan using brms::stanvar available brms model fitting. Fortunately, functions usually look almost identical definitions R, minor syntactic changes /use efficient helper functions. code implements two functions Stan: , note name functions Stan must match corresponding names R. lcdf lccdf functions implemented R Stan, new distribution ready use hmetad package!","code":"gumbel_min_lcdf <- function(x, g) {   log1p(-exp(-exp(x - g))) } gumbel_min_lccdf <- function(x, g) {   -exp(x - g) } gumbel_min <- stanvar(   scode = \" real gumbel_min_lcdf(real x, real g) {   return log1m_exp(-exp(x - g)); } real gumbel_min_lccdf(real x, real g) {   return -exp(x - g); }\",   block = \"functions\" )"},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"data-simulation","dir":"Articles","previous_headings":"","what":"Data simulation","title":"Using alternative signal distributions with the meta-d' model","text":"continuing model fitting, section describes simulate data meta-d’ model custom distribution. necessary step parameter recovery ensure meta-d’ model well-defined respect distribution. simulate data, can call sim_metad function supplying optional arguments lcdf lccdf:","code":"d <- sim_metad(   N_trials = 10000, dprime = 1.5, c = .1, log_M = -.5,   c2_0_diff = c(.25, .5, .25), c2_1_diff = c(.1, .5, .25),   lcdf = gumbel_min_lcdf, lccdf = gumbel_min_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Using alternative signal distributions with the meta-d' model","text":"data, fitting model exactly equal-variance normal distribution, now also need specify two additional arguments fit_metad. distribution argument name distribution string. part function names preceding \"_lcdf\" \"_lccdf\" R Stan. stanvars argument stanvar object created containing Stan code cumulative distribution functions. Otherwise, one can call fit_metad just equal-variance normal distribution! Please note, however, scale parameters vary distribution distribution, set priors accordingly. code shows fit meta-d’ model new gumbel_min distribution: model summary can interpreted just model, however can see model family metad__4__gumbel_min__absolute__multinomial, indicating model indeed uses gumbel_min distribution four confidence levels \\textrm{meta-}c = c.","code":"m <- fit_metad(N ~ 1,   data = d,   prior = prior(normal(0, 1), class = Intercept) +     prior(normal(0, 1), class = dprime) +     prior(normal(0, 1), class = c) +     prior(lognormal(-1, 1), class = metac2zero1diff) +     prior(lognormal(-1, 1), class = metac2zero2diff) +     prior(lognormal(-1, 1), class = metac2zero3diff) +     prior(lognormal(-1, 1), class = metac2one1diff) +     prior(lognormal(-1, 1), class = metac2one2diff) +     prior(lognormal(-1, 1), class = metac2one3diff),   distribution = \"gumbel_min\", stanvars = gumbel_min, file = \"models/gumbel.rds\" ) #>  Family: metad__4__gumbel_min__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -0.61      0.06    -0.73    -0.49 1.00     3591     3343 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              1.55      0.03     1.49     1.61 1.00     5722     3474 #> c                   0.11      0.01     0.08     0.14 1.00     3812     2821 #> metac2zero1diff     0.24      0.01     0.22     0.26 1.00     5298     3297 #> metac2zero2diff     0.49      0.01     0.46     0.51 1.00     5293     3210 #> metac2zero3diff     0.25      0.01     0.23     0.27 1.00     6152     2811 #> metac2one1diff      0.10      0.01     0.09     0.11 1.00     4581     2940 #> metac2one2diff      0.48      0.01     0.45     0.50 1.00     4205     3027 #> metac2one3diff      0.25      0.01     0.23     0.27 1.00     4670     2731 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/alternative_distributions.html","id":"model-estimates","dir":"Articles","previous_headings":"","what":"Model estimates","title":"Using alternative signal distributions with the meta-d' model","text":"model fit, can post-processed like model hmetad package. alternative distributions often understood terms effects ROC, focus plotting . Looking pseudo-type 1 ROC, can see gumbel_min distribution exhibits asymmetry:  Likewise, gumbel_min distribution also asymmetric type 2 ROCs:","code":"# psuedo type-1 ROC tibble(.row = 1) |>   add_roc1_draws(m, bounds = TRUE) |>   median_qi(p_fa, p_hit) |>   ggplot(aes(     x = p_fa, xmin = p_fa.lower, xmax = p_fa.upper,     y = p_hit, ymin = p_hit.lower, ymax = p_hit.upper   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_point() +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(False Alarm)\") +   ylab(\"P(Hit)\") +   theme_bw(18) # type 2 ROC roc2_draws(m, tibble(.row = 1), bounds = TRUE) |>   median_qi(p_hit2, p_fa2) |>   mutate(response = factor(response)) |>   ggplot(aes(     x = p_fa2, xmin = p_fa2.lower, xmax = p_fa2.upper,     y = p_hit2, ymin = p_hit2.lower, ymax = p_hit2.upper,     color = response   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_point() +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(Type 2 False Alarm)\") +   ylab(\"P(Type 2 Hit)\") +   theme_bw(18)"},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating trial-level effects","text":"default, hmetad package uses aggregated data (.e., counts number trials stimulus, type 1 response, type 2 response.) data aggregation makes model fitting simulation much efficient. sometimes researchers interested trial-level effects. One common example often called “crossed random effects”. example, design participants make responses set items, researcher might want estimate participant-level item-level effects model parameters. can simulate data design like : Don’t worry details simulation code- matters data set repeated measures participants: repeated measures items:","code":"library(tidyverse) library(tidybayes) library(hmetad)  ## average model parameters K <- 3 ## number of confidence levels mu_log_M <- -0.5 mu_dprime <- 1.5 mu_c <- 0 mu_c2_0 <- rep(-1, K - 1) mu_c2_1 <- rep(-1, K - 1)  ## participant-level standard deviations sd_log_M_participant <- 0.25 sd_dprime_participant <- 0.5 sd_c_participant <- 0.33 sd_c2_0_participant <- cov_matrix(rep(0.25, K - 1), diag(K - 1)) sd_c2_1_participant <- cov_matrix(rep(0.25, K - 1), diag(K - 1))  ## item-level standard deviations sd_log_M_item <- 0.1 sd_dprime_item <- 0.5 sd_c_item <- 0.75 sd_c2_0_item <- cov_matrix(rep(0.1, K - 1), diag(K - 1)) sd_c2_1_item <- cov_matrix(rep(0.1, K - 1), diag(K - 1))   ## simulate data d <- expand_grid(   participant = 1:50,   item = 1:10 ) |>   ## simulate participant-level differences   group_by(participant) |>   mutate(     z_log_M_participant = rnorm(1, sd = sd_log_M_participant),     z_dprime_participant = rnorm(1, sd = sd_dprime_participant),     z_c_participant = rnorm(1, sd = sd_c_participant),     z_c2_0_participant = list(rmulti_normal(1, mu = rep(0, K - 1), Sigma = sd_c2_0_participant)),     z_c2_1_participant = list(rmulti_normal(1, mu = rep(0, K - 1), Sigma = sd_c2_1_participant))   ) |>   ## simulate item-level differences   group_by(item) |>   mutate(     z_log_M_item = rnorm(1, sd = sd_log_M_item),     z_dprime_item = rnorm(1, sd = sd_dprime_item),     z_c_item = rnorm(1, sd = sd_c_item),     z_c2_0_item = list(rmulti_normal(1, mu = rep(0, K - 1), Sigma = sd_c2_0_item)),     z_c2_1_item = list(rmulti_normal(1, mu = rep(0, K - 1), Sigma = sd_c2_1_item))   ) |>   ungroup() |>   ## compute model parameters   mutate(     log_M = mu_log_M + z_log_M_participant + z_log_M_item,     dprime = mu_dprime + z_dprime_participant + z_dprime_item,     c = mu_c + z_c_participant + z_c_item,     c2_0_diff = map2(       z_c2_0_participant, z_c2_0_item,       ~ exp(mu_c2_0 + .x + .y)     ),     c2_1_diff = map2(       z_c2_1_participant, z_c2_1_item,       ~ exp(mu_c2_1 + .x + .y)     )   ) |>   ## simulate two trials per participant/item (stimulus = 0 and stimulus = 1)   mutate(trial = pmap(list(dprime, c, log_M, c2_0_diff, c2_1_diff), sim_metad, N_trials = 2)) |>   select(participant, item, trial) |>   unnest(trial) #> # A tibble: 1,000 × 16 #>    participant  item trial stimulus response correct confidence dprime        c #>          <int> <int> <int>    <int>    <int>   <int>      <int>  <dbl>    <dbl> #>  1           1     1     1        0        0       1          3   1.76  0.00633 #>  2           1     1     1        1        0       0          3   1.76  0.00633 #>  3           1     2     1        0        0       1          1   2.46 -0.652   #>  4           1     2     1        1        1       1          3   2.46 -0.652   #>  5           1     3     1        0        0       1          2   2.34 -0.848   #>  6           1     3     1        1        1       1          3   2.34 -0.848   #>  7           1     4     1        0        0       1          2   2.83 -0.859   #>  8           1     4     1        1        1       1          3   2.83 -0.859   #>  9           1     5     1        0        0       1          3   1.88 -0.382   #> 10           1     5     1        1        1       1          3   1.88 -0.382   #> # ℹ 990 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl> count(d, participant) #> # A tibble: 50 × 2 #>    participant     n #>          <int> <int> #>  1           1    20 #>  2           2    20 #>  3           3    20 #>  4           4    20 #>  5           5    20 #>  6           6    20 #>  7           7    20 #>  8           8    20 #>  9           9    20 #> 10          10    20 #> # ℹ 40 more rows count(d, item) #> # A tibble: 10 × 2 #>     item     n #>    <int> <int> #>  1     1   100 #>  2     2   100 #>  3     3   100 #>  4     4   100 #>  5     5   100 #>  6     6   100 #>  7     7   100 #>  8     8   100 #>  9     9   100 #> 10    10   100"},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"standard-model-with-data-aggregation","dir":"Articles","previous_headings":"","what":"Standard model with data aggregation","title":"Estimating trial-level effects","text":"like, can use fit_metad function data participant-level item-level effects. However, aggregate data , can see aggregation doesn’t really help us : can see, aggregated data set 500 rows (two observations per row), much smaller trial-level data started ! , case, probably easier aggregate data. Nevertheless, nothing stopping us fitting model like normal:1","code":"aggregate_metad(d, participant, item) #> # A tibble: 500 × 5 #>    participant item    N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] #>    <fct>       <fct> <int> <int>       <int>      <int>      <int>      <int> #>  1 1           1         1     1           1          0          0          0 #>  2 1           2         1     1           0          0          1          0 #>  3 1           3         1     1           0          1          0          0 #>  4 1           4         1     1           0          1          0          0 #>  5 1           5         1     1           1          0          0          0 #>  6 1           6         1     1           1          0          0          0 #>  7 1           7         1     1           0          1          0          0 #>  8 1           8         1     1           0          0          0          0 #>  9 1           9         1     1           1          0          0          0 #> 10 1           10        1     1           1          0          0          0 #> # ℹ 490 more rows #> # ℹ 1 more variable: N[5:12] <int> m.multinomial <- fit_metad(   bf(     N ~ 1 + (1 | participant) + (1 | item),     dprime + c +       metac2zero1diff + metac2zero2diff +       metac2one1diff + metac2one2diff ~       1 + (1 | participant) + (1 | item)   ),   data = d, init = 0,   file = \"models/multinomial.rds\",   prior = prior(normal(0, .25), class = Intercept) +     prior(normal(0, .25), class = Intercept, dpar = dprime) +     prior(normal(0, .25), class = Intercept, dpar = c) +     prior(normal(0, .1), class = Intercept, dpar = metac2zero1diff) +     prior(normal(0, .1), class = Intercept, dpar = metac2zero2diff) +     prior(normal(0, .1), class = Intercept, dpar = metac2one1diff) +     prior(normal(0, .1), class = Intercept, dpar = metac2one2diff) +     prior(normal(0, 1), class = sd) +     prior(normal(0, 1), class = sd, dpar = dprime) +     prior(normal(0, 1), class = sd, dpar = c) +     prior(normal(0, 1), class = sd, dpar = metac2zero1diff) +     prior(normal(0, 1), class = sd, dpar = metac2zero2diff) +     prior(normal(0, 1), class = sd, dpar = metac2one1diff) +     prior(normal(0, 1), class = sd, dpar = metac2one2diff) ) #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 7.8e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.461 seconds (Warm-up) #> Chain 1:                0.258 seconds (Sampling) #> Chain 1:                0.719 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 3e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.459 seconds (Warm-up) #> Chain 2:                0.257 seconds (Sampling) #> Chain 2:                0.716 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 2.9e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.476 seconds (Warm-up) #> Chain 3:                0.26 seconds (Sampling) #> Chain 3:                0.736 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 3e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.488 seconds (Warm-up) #> Chain 4:                0.257 seconds (Sampling) #> Chain 4:                0.745 seconds (Total) #> Chain 4: #>  Family: metad__3__normal__absolute__multinomial  #>   Links: mu = log; dprime = identity; c = identity; metac2zero1diff = log; metac2zero2diff = log; metac2one1diff = log; metac2one2diff = log  #> Formula: N ~ 1 + (1 | participant) + (1 | item)  #>          dprime ~ 1 + (1 | participant) + (1 | item) #>          c ~ 1 + (1 | participant) + (1 | item) #>          metac2zero1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2zero2diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one2diff ~ 1 + (1 | participant) + (1 | item) #>    Data: data.aggregated (Number of observations: 500)  #>   Draws: 4 chains, each with iter = 1000; warmup = 500; thin = 1; #>          total post-warmup draws = 2000 #>  #> Multilevel Hyperparameters: #> ~item (Number of levels: 10)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.08      0.06     0.00     0.22 1.00 #> sd(dprime_Intercept)              0.41      0.30     0.02     1.13 1.00 #> sd(c_Intercept)                   0.60      0.45     0.03     1.69 1.00 #> sd(metac2zero1diff_Intercept)     0.08      0.06     0.00     0.23 1.00 #> sd(metac2zero2diff_Intercept)     0.08      0.06     0.00     0.23 1.00 #> sd(metac2one1diff_Intercept)      0.08      0.06     0.00     0.22 1.01 #> sd(metac2one2diff_Intercept)      0.08      0.06     0.00     0.22 1.00 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                     1674      963 #> sd(dprime_Intercept)              1893      999 #> sd(c_Intercept)                   1856      832 #> sd(metac2zero1diff_Intercept)     1862     1060 #> sd(metac2zero2diff_Intercept)     1592      698 #> sd(metac2one1diff_Intercept)      1527      956 #> sd(metac2one2diff_Intercept)      1921     1069 #>  #> ~participant (Number of levels: 50)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.21      0.15     0.01     0.56 1.00 #> sd(dprime_Intercept)              0.40      0.31     0.02     1.15 1.00 #> sd(c_Intercept)                   0.26      0.20     0.01     0.73 1.00 #> sd(metac2zero1diff_Intercept)     0.20      0.15     0.01     0.55 1.00 #> sd(metac2zero2diff_Intercept)     0.20      0.15     0.01     0.57 1.00 #> sd(metac2one1diff_Intercept)      0.20      0.15     0.01     0.55 1.00 #> sd(metac2one2diff_Intercept)      0.20      0.15     0.01     0.57 1.00 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                     1279      634 #> sd(dprime_Intercept)              1546      800 #> sd(c_Intercept)                   1952     1244 #> sd(metac2zero1diff_Intercept)     1732      951 #> sd(metac2zero2diff_Intercept)     1043      645 #> sd(metac2one1diff_Intercept)      2032     1049 #> sd(metac2one2diff_Intercept)      1773      975 #>  #> Regression Coefficients: #>                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS #> Intercept                    -0.50      0.25    -0.96    -0.02 1.00     2692 #> dprime_Intercept              1.50      0.25     1.00     2.00 1.00     2654 #> c_Intercept                   0.00      0.25    -0.48     0.51 1.00     2560 #> metac2zero1diff_Intercept    -1.00      0.10    -1.19    -0.80 1.00     2170 #> metac2zero2diff_Intercept    -1.00      0.10    -1.19    -0.79 1.00     2636 #> metac2one1diff_Intercept     -1.00      0.11    -1.22    -0.79 1.00     1769 #> metac2one2diff_Intercept     -1.00      0.10    -1.19    -0.81 1.00     2578 #>                           Tail_ESS #> Intercept                     1467 #> dprime_Intercept              1516 #> c_Intercept                   1387 #> metac2zero1diff_Intercept     1293 #> metac2zero2diff_Intercept     1626 #> metac2one1diff_Intercept      1157 #> metac2one2diff_Intercept      1423 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data preparation","title":"Estimating trial-level effects","text":"Fitting trial-level model require data aggregation, however still requires small amount data preparation. fit model, need things: column stimulus per trial (0 1), column containing joint type 1/type 2 responses per trial (1 2*K). data already stimulus column separate columns two responses. , can add joint response column now:","code":"d <- d |>   mutate(joint_response = joint_response(response, confidence, K)) |>   relocate(joint_response, .after = \"stimulus\") #> # A tibble: 1,000 × 17 #>    participant  item trial stimulus joint_response response correct confidence #>          <int> <int> <int>    <int>          <dbl>    <int>   <int>      <int> #>  1           1     1     1        0              1        0       1          3 #>  2           1     1     1        1              1        0       0          3 #>  3           1     2     1        0              3        0       1          1 #>  4           1     2     1        1              6        1       1          3 #>  5           1     3     1        0              2        0       1          2 #>  6           1     3     1        1              6        1       1          3 #>  7           1     4     1        0              2        0       1          2 #>  8           1     4     1        1              6        1       1          3 #>  9           1     5     1        0              1        0       1          3 #> 10           1     5     1        1              6        1       1          3 #> # ℹ 990 more rows #> # ℹ 9 more variables: dprime <dbl>, c <dbl>, meta_dprime <dbl>, M <dbl>, #> #   meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, #> #   theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Estimating trial-level effects","text":"Now data, can fit trial-level model using joint_response response variable, stimulus extra variable passed brms, argument categorical=TRUE tell fit_metad aggregate data: can see, aside way data formatted, model exactly multinomial model .","code":"m.categorical <- fit_metad(   bf(     joint_response | vint(stimulus) ~ 1 + (1 | participant) + (1 | item),     dprime + c +       metac2zero1diff + metac2zero2diff +       metac2one1diff + metac2one2diff ~       1 + (1 | participant) + (1 | item)   ),   data = d, categorical = TRUE, init = 0,   file = \"models/categorical.rds\",   prior = prior(normal(0, .25), class = Intercept) +     prior(normal(0, .25), class = Intercept, dpar = dprime) +     prior(normal(0, .25), class = Intercept, dpar = c) +     prior(normal(0, .1), class = Intercept, dpar = metac2zero1diff) +     prior(normal(0, .1), class = Intercept, dpar = metac2zero2diff) +     prior(normal(0, .1), class = Intercept, dpar = metac2one1diff) +     prior(normal(0, .1), class = Intercept, dpar = metac2one2diff) +     prior(normal(0, 1), class = sd) +     prior(normal(0, 1), class = sd, dpar = dprime) +     prior(normal(0, 1), class = sd, dpar = c) +     prior(normal(0, 1), class = sd, dpar = metac2zero1diff) +     prior(normal(0, 1), class = sd, dpar = metac2zero2diff) +     prior(normal(0, 1), class = sd, dpar = metac2one1diff) +     prior(normal(0, 1), class = sd, dpar = metac2one2diff) ) #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 4e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.464 seconds (Warm-up) #> Chain 1:                0.325 seconds (Sampling) #> Chain 1:                0.789 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 2.8e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.468 seconds (Warm-up) #> Chain 2:                0.267 seconds (Sampling) #> Chain 2:                0.735 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 3.2e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.469 seconds (Warm-up) #> Chain 3:                0.272 seconds (Sampling) #> Chain 3:                0.741 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 3e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.459 seconds (Warm-up) #> Chain 4:                0.263 seconds (Sampling) #> Chain 4:                0.722 seconds (Total) #> Chain 4: #>  Family: metad__3__normal__absolute__categorical  #>   Links: mu = log; dprime = identity; c = identity; metac2zero1diff = log; metac2zero2diff = log; metac2one1diff = log; metac2one2diff = log  #> Formula: joint_response | vint(stimulus) ~ 1 + (1 | participant) + (1 | item)  #>          dprime ~ 1 + (1 | participant) + (1 | item) #>          c ~ 1 + (1 | participant) + (1 | item) #>          metac2zero1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2zero2diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one1diff ~ 1 + (1 | participant) + (1 | item) #>          metac2one2diff ~ 1 + (1 | participant) + (1 | item) #>    Data: data.aggregated (Number of observations: 1000)  #>   Draws: 4 chains, each with iter = 1000; warmup = 500; thin = 1; #>          total post-warmup draws = 2000 #>  #> Multilevel Hyperparameters: #> ~item (Number of levels: 10)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.08      0.06     0.00     0.23 1.00 #> sd(dprime_Intercept)              0.41      0.30     0.03     1.15 1.00 #> sd(c_Intercept)                   0.60      0.43     0.04     1.61 1.00 #> sd(metac2zero1diff_Intercept)     0.08      0.06     0.00     0.22 1.00 #> sd(metac2zero2diff_Intercept)     0.08      0.06     0.00     0.22 1.00 #> sd(metac2one1diff_Intercept)      0.08      0.06     0.00     0.22 1.00 #> sd(metac2one2diff_Intercept)      0.08      0.06     0.00     0.22 1.00 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                     1427      896 #> sd(dprime_Intercept)              1980     1313 #> sd(c_Intercept)                   2456     1404 #> sd(metac2zero1diff_Intercept)     1093      547 #> sd(metac2zero2diff_Intercept)     1213      762 #> sd(metac2one1diff_Intercept)      1359      856 #> sd(metac2one2diff_Intercept)      1073      662 #>  #> ~participant (Number of levels: 50)  #>                               Estimate Est.Error l-95% CI u-95% CI Rhat #> sd(Intercept)                     0.19      0.15     0.01     0.56 1.00 #> sd(dprime_Intercept)              0.40      0.32     0.02     1.16 1.00 #> sd(c_Intercept)                   0.26      0.20     0.01     0.75 1.00 #> sd(metac2zero1diff_Intercept)     0.20      0.15     0.01     0.58 1.00 #> sd(metac2zero2diff_Intercept)     0.20      0.15     0.01     0.55 1.00 #> sd(metac2one1diff_Intercept)      0.20      0.15     0.01     0.55 1.00 #> sd(metac2one2diff_Intercept)      0.20      0.14     0.01     0.54 1.01 #>                               Bulk_ESS Tail_ESS #> sd(Intercept)                     1099      469 #> sd(dprime_Intercept)              1876     1225 #> sd(c_Intercept)                   1561      846 #> sd(metac2zero1diff_Intercept)     1396      758 #> sd(metac2zero2diff_Intercept)     1487      725 #> sd(metac2one1diff_Intercept)      1826      960 #> sd(metac2one2diff_Intercept)      1581      958 #>  #> Regression Coefficients: #>                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS #> Intercept                    -0.50      0.26    -1.01    -0.00 1.00     2138 #> dprime_Intercept              1.50      0.25     1.01     1.98 1.00     2541 #> c_Intercept                   0.00      0.25    -0.51     0.49 1.01     2386 #> metac2zero1diff_Intercept    -1.00      0.10    -1.20    -0.81 1.00     2786 #> metac2zero2diff_Intercept    -1.00      0.10    -1.19    -0.80 1.00     2676 #> metac2one1diff_Intercept     -1.00      0.10    -1.18    -0.81 1.00     2539 #> metac2one2diff_Intercept     -1.00      0.10    -1.21    -0.80 1.00     2308 #>                           Tail_ESS #> Intercept                     1138 #> dprime_Intercept              1419 #> c_Intercept                   1333 #> metac2zero1diff_Intercept     1412 #> metac2zero2diff_Intercept     1347 #> metac2one1diff_Intercept      1369 #> metac2one2diff_Intercept      1347 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"extracting-model-estimates","dir":"Articles","previous_headings":"","what":"Extracting model estimates","title":"Estimating trial-level effects","text":"Obtaining posterior estimates model parameters, predictions, estimates similar multinomial model (details, see vignette(\"hmetad\")). , focus type 1 ROC curves, time using roc1_rvars instead roc1_draws increased efficiency. get posterior estimates, need specify data set make predictions , well random effects formula use model predictions. example, estimate ROC averaging participants items, can use empty data set re_formula=NA: process exactly categorical model: Next, get participant-level ROCs (averaging items), can use data set one row per participant participant-level random effects: can use similar process get item-level ROCs (averaging participants):","code":"roc1_rvars(m.multinomial, tibble(.row = 1), re_formula = NA) #> # A tibble: 5 × 6 #> # Groups:   .row, joint_response, response, confidence [5] #>    .row joint_response response confidence           p_fa         p_hit #>   <int>          <int>    <int>      <dbl>     <rvar[1d]>    <rvar[1d]> #> 1     1              1        0          3  0.552 ± 0.104  0.91 ± 0.047 #> 2     1              2        0          2  0.391 ± 0.100  0.85 ± 0.067 #> 3     1              3        0          1  0.235 ± 0.084  0.76 ± 0.085 #> 4     1              4        1          1  0.152 ± 0.065  0.61 ± 0.101 #> 5     1              5        1          2  0.089 ± 0.046  0.45 ± 0.104 roc1_rvars(m.categorical, tibble(.row = 1), re_formula = NA) #> # A tibble: 5 × 6 #> # Groups:   .row, joint_response, response, confidence [5] #>    .row joint_response response confidence           p_fa         p_hit #>   <int>          <int>    <int>      <dbl>     <rvar[1d]>    <rvar[1d]> #> 1     1              1        0          3  0.551 ± 0.105  0.91 ± 0.048 #> 2     1              2        0          2  0.391 ± 0.101  0.85 ± 0.068 #> 3     1              3        0          1  0.235 ± 0.085  0.76 ± 0.086 #> 4     1              4        1          1  0.151 ± 0.066  0.61 ± 0.102 #> 5     1              5        1          2  0.089 ± 0.047  0.45 ± 0.106 roc1_rvars(m.categorical, distinct(d, participant), re_formula = ~ (1 | participant)) #> # A tibble: 250 × 7 #> # Groups:   .row, participant, joint_response, response, confidence [250] #>     .row participant joint_response response confidence         p_fa #>    <int>       <int>          <int>    <int>      <dbl>   <rvar[1d]> #>  1     1           1              1        0          3  0.55 ± 0.18 #>  2     2           2              1        0          3  0.55 ± 0.17 #>  3     3           3              1        0          3  0.56 ± 0.16 #>  4     4           4              1        0          3  0.56 ± 0.17 #>  5     5           5              1        0          3  0.56 ± 0.18 #>  6     6           6              1        0          3  0.55 ± 0.17 #>  7     7           7              1        0          3  0.56 ± 0.17 #>  8     8           8              1        0          3  0.55 ± 0.17 #>  9     9           9              1        0          3  0.55 ± 0.17 #> 10    10          10              1        0          3  0.55 ± 0.17 #> # ℹ 240 more rows #> # ℹ 1 more variable: p_hit <rvar[1d]> roc1_rvars(m.categorical, distinct(d, item), re_formula = ~ (1 | item)) #> # A tibble: 50 × 7 #> # Groups:   .row, item, joint_response, response, confidence [50] #>     .row  item joint_response response confidence         p_fa        p_hit #>    <int> <int>          <int>    <int>      <dbl>   <rvar[1d]>   <rvar[1d]> #>  1     1     1              1        0          3  0.56 ± 0.23  0.87 ± 0.16 #>  2     2     2              1        0          3  0.55 ± 0.22  0.87 ± 0.15 #>  3     3     3              1        0          3  0.54 ± 0.23  0.86 ± 0.17 #>  4     4     4              1        0          3  0.54 ± 0.23  0.86 ± 0.17 #>  5     5     5              1        0          3  0.55 ± 0.23  0.87 ± 0.17 #>  6     6     6              1        0          3  0.55 ± 0.22  0.87 ± 0.16 #>  7     7     7              1        0          3  0.54 ± 0.23  0.87 ± 0.16 #>  8     8     8              1        0          3  0.54 ± 0.23  0.86 ± 0.17 #>  9     9     9              1        0          3  0.54 ± 0.24  0.85 ± 0.18 #> 10    10    10              1        0          3  0.55 ± 0.23  0.86 ± 0.16 #> # ℹ 40 more rows"},{"path":"https://metacoglab.github.io/hmetad/articles/categorical.html","id":"other-benefits","dir":"Articles","previous_headings":"","what":"Other benefits","title":"Estimating trial-level effects","text":"Aside representing data convenient format, trial-level model useful things like model comparison using loo package, multivariate models, mediation models. features mostly work box still active development, stay tuned!","code":""},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Fitting the meta-d' model","text":"vignette demonstrates use hmetad package fit meta-d’ model (Maniscalco Lau 2012) dataset including binary decision confidence ratings.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data preparation","title":"Fitting the meta-d' model","text":"get better idea kind datasets hmetad package designed , can start simulating one (see help('sim_metad') description data simulation function): can see, dataset column trial number, presented stimulus trial (0 1), participant’s type 1 response (0 1), corresponding type 2 response (confidence; 1:K). trials dataset sorted stimulus, response, confidence data set simulated, otherwise look similar kind data immediately get running experiment.","code":"library(tidyverse) library(tidybayes) library(hmetad)  d <- sim_metad(   N_trials = 1000, dprime = .75, c = -.5, log_M = -1,   c2_0 = c(.25, .75, 1), c2_1 = c(.5, 1, 1.25) ) #> # A tibble: 1,000 × 4 #> # Groups:   stimulus, response, confidence [16] #>    trial stimulus response confidence #>    <int>    <int>    <int>      <int> #>  1     1        0        0          1 #>  2     2        0        0          1 #>  3     3        0        0          1 #>  4     4        0        0          1 #>  5     5        0        0          1 #>  6     6        0        0          1 #>  7     7        0        0          1 #>  8     8        0        0          1 #>  9     9        0        0          1 #> 10    10        0        0          1 #> # ℹ 990 more rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"type-1-type-2-and-joint-responses","dir":"Articles","previous_headings":"Data preparation","what":"Type 1, type 2, and joint responses","title":"Fitting the meta-d' model","text":"One hiccup paradigms collect separate decision (.e., type 1 response) confidence rating (.e., type 2 response)—rather, collect single rating reflecting primary decision confidence. example, instead binary type 1 response type 2 response ranging 1 K (K maximum confidence level), sometimes participants asked make rating scale 1 2*K, 1 represents confidence \"0\" response, K represents uncertain \"0\" response, K+1 represents uncertain \"1\" response, 2*K represents confident \"1\" response. refer joint response, combination type 1 response type 2 response. like convert joint response separate type 1 type 2 responses, can use corresponding functions type1_response type2_response. example, instead dataset looked like : convert joint response like : Similarly, can also convert separate responses joint response: Note cases need specify confidence scale K=4 levels (meaning joint type 1/type 2 scale 8 levels).","code":"#> # A tibble: 1,000 × 2 #>    trial joint_response #>    <int>          <dbl> #>  1     1              4 #>  2     2              4 #>  3     3              4 #>  4     4              4 #>  5     5              4 #>  6     6              4 #>  7     7              4 #>  8     8              4 #>  9     9              4 #> 10    10              4 #> # ℹ 990 more rows d.joint_response |>   mutate(     response = type1_response(joint_response, K = 4),     confidence = type2_response(joint_response, K = 4)   ) #> # A tibble: 1,000 × 4 #>    trial joint_response response confidence #>    <int>          <dbl>    <int>      <dbl> #>  1     1              4        0          1 #>  2     2              4        0          1 #>  3     3              4        0          1 #>  4     4              4        0          1 #>  5     5              4        0          1 #>  6     6              4        0          1 #>  7     7              4        0          1 #>  8     8              4        0          1 #>  9     9              4        0          1 #> 10    10              4        0          1 #> # ℹ 990 more rows d |>   mutate(joint_response = joint_response(response, confidence, K = 4)) #> # A tibble: 1,000 × 5 #> # Groups:   stimulus, response, confidence [16] #>    trial stimulus response confidence joint_response #>    <int>    <int>    <int>      <int>          <dbl> #>  1     1        0        0          1              4 #>  2     2        0        0          1              4 #>  3     3        0        0          1              4 #>  4     4        0        0          1              4 #>  5     5        0        0          1              4 #>  6     6        0        0          1              4 #>  7     7        0        0          1              4 #>  8     8        0        0          1              4 #>  9     9        0        0          1              4 #> 10    10        0        0          1              4 #> # ℹ 990 more rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"signed-and-unsigned-binary-numbers","dir":"Articles","previous_headings":"Data preparation","what":"Signed and unsigned binary numbers","title":"Fitting the meta-d' model","text":"Often datasets use -1 1 instead 0 1 represent two possible stimuli type 1 responses. hmetad package designed use unsigned (0 1) version, provides helper functions convert two:","code":"to_unsigned(c(-1, 1)) #> [1] 0 1 to_signed(c(0, 1)) #> [1] -1  1"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"data-aggregation","dir":"Articles","previous_headings":"Data preparation","what":"Data aggregation","title":"Fitting the meta-d' model","text":"Finally, ensure model runs efficiently, hmetad package currently requires data aggregated. easier, hmetad package aggregate data fit model. like manually (e.g., plotting follow-analyses), aggregate_metad function can : resulting data frame three columns: N_0 number trials stimulus==0, N_1 number trials stimulus==1, N matrix containing number joint responses two possible stimuli (column names indicating stimulus joint_response). like use variable name N counts, can change name .name argument: Finally, columns dataset (e.g., participant condition columns) like aggregated separately, can simply add function call:","code":"d.summary <- aggregate_metad(d) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   500   500           3         59        117         44         83        135 #> # ℹ 1 more variable: N[7:16] <int> aggregate_metad(d, .name = \"y\") #> # A tibble: 1 × 3 #>     y_0   y_1 y[,\"y_0_1\"] [,\"y_0_2\"] [,\"y_0_3\"] [,\"y_0_4\"] [,\"y_0_5\"] [,\"y_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   500   500           3         59        117         44         83        135 #> # ℹ 1 more variable: y[7:16] <int> aggregate_metad(d, participant, condition)"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Fitting the meta-d' model","text":"fit model, can use fit_metad function. function simply wrapper around brms::brm, users strongly encouraged become familiar brms model fitting. Since aggregate_metad place dataset trial counts column named N default, can use N response variable even data yet aggregated. fit model fixed values parameter, , can use formula N ~ 1: Note arbitrarily chosen use standard normal priors parameters. get better idea set informed priors, please refer help('set_prior', package='brms'). model, Intercept estimate \\textrm{log}(M) = \\textrm{log}\\frac{\\textrm{meta-}d'}{d'}, dprime estimate d', c estimate c, metac2zero1diff metac2zero2diff distances successive confidence thresholds \"0\" responses, metac2one1diff metac2one2diff distances successive confidence thresholds \"1\" responses. parameter, brms shows posterior means (Estimate), posterior standard deviations (Est. Error), upper- lower-95% posterior quantiles (l-95% CI u-95% CI), well convergence metrics (Rhat, Bulk_ESS, Tail_ESS).","code":"m <- fit_metad(N ~ 1,   data = d,   file = \"models/metad.rds\",   prior = prior(normal(0, 1), class = Intercept) +     prior(normal(0, 1), class = dprime) +     prior(normal(0, 1), class = c) +     prior(lognormal(0, 1), class = metac2zero1diff) +     prior(lognormal(0, 1), class = metac2zero2diff) +     prior(lognormal(0, 1), class = metac2one1diff) +     prior(lognormal(0, 1), class = metac2one2diff) ) #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -0.69      0.32    -1.43    -0.15 1.00     4865     3047 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              0.71      0.08     0.54     0.87 1.00     6299     2751 #> c                  -0.49      0.04    -0.57    -0.41 1.00     4208     2761 #> metac2zero1diff     0.21      0.02     0.17     0.26 1.00     6164     2998 #> metac2zero2diff     0.78      0.05     0.68     0.89 1.00     5144     2949 #> metac2zero3diff     1.27      0.17     0.97     1.63 1.00     5911     3002 #> metac2one1diff      0.47      0.03     0.41     0.54 1.00     5660     3143 #> metac2one2diff      1.00      0.05     0.91     1.09 1.00     5878     2975 #> metac2one3diff      1.30      0.11     1.10     1.52 1.00     8763     3453 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"extract-model-estimates","dir":"Articles","previous_headings":"","what":"Extract model estimates","title":"Fitting the meta-d' model","text":"fitted model, many estimates can extract . Although brms provides functions extracting posterior estimates, hmetad package designed interface well tidybayes package make easier work model posterior samples.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"parameter-estimates","dir":"Articles","previous_headings":"Extract model estimates","what":"Parameter estimates","title":"Fitting the meta-d' model","text":"First, often useful extract posterior draws model parameters, can linpred_draws_metad (wrapper around tidybayes::linpred_draws): tibble separate row every posterior sample separate column every model parameter. format useful purposes, often useful pivot separate row model parameter posterior sample: Now posterior samples stored single column .value, easy get posterior summaries using e.g. tidybayes::median_qi:","code":"draws.metad <- tibble(.row = 1) |>   add_linpred_draws_metad(m) #> # A tibble: 4,000 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime      c meta_dprime meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>  <dbl>       <dbl>  <dbl> #>  1     1     NA         NA     1 0.635  0.756 -0.505       0.480 -0.505 #>  2     1     NA         NA     2 0.419  0.723 -0.503       0.303 -0.505 #>  3     1     NA         NA     3 0.358  0.775 -0.499       0.277 -0.505 #>  4     1     NA         NA     4 0.571  0.687 -0.463       0.392 -0.505 #>  5     1     NA         NA     5 0.499  0.803 -0.540       0.401 -0.505 #>  6     1     NA         NA     6 0.398  0.735 -0.557       0.293 -0.505 #>  7     1     NA         NA     7 0.574  0.605 -0.475       0.347 -0.505 #>  8     1     NA         NA     8 0.456  0.716 -0.501       0.326 -0.505 #>  9     1     NA         NA     9 0.693  0.476 -0.482       0.330 -0.505 #> 10     1     NA         NA    10 0.596  0.777 -0.481       0.463 -0.505 #> # ℹ 3,990 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl> draws.metad <- tibble(.row = 1) |>   add_linpred_draws_metad(m, pivot_longer = TRUE) #> # A tibble: 44,000 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable    .value #>    <int>  <int>      <int> <int> <chr>         <dbl> #>  1     1     NA         NA     1 M            0.635  #>  2     1     NA         NA     1 dprime       0.756  #>  3     1     NA         NA     1 c           -0.505  #>  4     1     NA         NA     1 meta_dprime  0.480  #>  5     1     NA         NA     1 meta_c      -0.505  #>  6     1     NA         NA     1 meta_c2_0_1 -0.706  #>  7     1     NA         NA     1 meta_c2_0_2 -1.46   #>  8     1     NA         NA     1 meta_c2_0_3 -3.03   #>  9     1     NA         NA     1 meta_c2_1_1 -0.0206 #> 10     1     NA         NA     1 meta_c2_1_2  1.01   #> # ℹ 43,990 more rows draws.metad |>   median_qi() #> # A tibble: 11 × 8 #>     .row .variable    .value  .lower  .upper .width .point .interval #>    <int> <chr>         <dbl>   <dbl>   <dbl>  <dbl> <chr>  <chr>     #>  1     1 c           -0.493  -0.574  -0.409    0.95 median qi        #>  2     1 dprime       0.707   0.543   0.871    0.95 median qi        #>  3     1 M            0.518   0.240   0.865    0.95 median qi        #>  4     1 meta_c      -0.505  -0.505  -0.505    0.95 median qi        #>  5     1 meta_c2_0_1 -0.718  -0.769  -0.673    0.95 median qi        #>  6     1 meta_c2_0_2 -1.50   -1.62   -1.39     0.95 median qi        #>  7     1 meta_c2_0_3 -2.76   -3.14   -2.45     0.95 median qi        #>  8     1 meta_c2_1_1 -0.0339 -0.0968  0.0334   0.95 median qi        #>  9     1 meta_c2_1_2  0.965   0.862   1.07     0.95 median qi        #> 10     1 meta_c2_1_3  2.26    2.05    2.50     0.95 median qi        #> 11     1 meta_dprime  0.367   0.171   0.573    0.95 median qi"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Extract model estimates","what":"Posterior predictions","title":"Fitting the meta-d' model","text":"One way evaluate model fit perform posterior predictive check: simulate data model’s posterior compare simulated actual data. can using function predicted_draws_metad (wrapper around tidybayes::predicted_draws): data frame, columns aggregated data d.summary well stimulus, joint_response, response, confidence (indicating simulated trial type), well .prediction (indicating number simulated trials per trial type). , can plot posterior predictions (points error-bars) actual data (bars):","code":"draws.predicted <- predicted_draws_metad(m, d.summary) #> # A tibble: 64,000 × 12 #> # Groups:   .row, N_0, N_1, N, stimulus, joint_response, response, confidence #> #   [16] #>     .row   N_0   N_1 N[,\"N_0_1\"] stimulus joint_response response confidence #>    <int> <int> <int>       <int>    <int>          <int>    <int>      <dbl> #>  1     1   500   500           3        0              1        0          4 #>  2     1   500   500           3        0              1        0          4 #>  3     1   500   500           3        0              1        0          4 #>  4     1   500   500           3        0              1        0          4 #>  5     1   500   500           3        0              1        0          4 #>  6     1   500   500           3        0              1        0          4 #>  7     1   500   500           3        0              1        0          4 #>  8     1   500   500           3        0              1        0          4 #>  9     1   500   500           3        0              1        0          4 #> 10     1   500   500           3        0              1        0          4 #> # ℹ 63,990 more rows #> # ℹ 5 more variables: N[2:16] <int>, .prediction <int>, .chain <int>, #> #   .iteration <int>, .draw <int> draws.predicted |>   group_by(.row, stimulus, joint_response, response, confidence) |>   median_qi(.prediction) |>   group_by(.row) |>   mutate(N = t(d.summary$N[.row, ])) |>   ggplot(aes(x = joint_response)) +   geom_col(aes(y = N), fill = \"grey80\") +   geom_pointrange(aes(y = .prediction, ymin = .lower, ymax = .upper)) +   facet_wrap(~stimulus, labeller = label_both) +   theme_classic(18) #> Warning in `[<-.data.frame`(`*tmp*`, , y_vars, value = list(y = c(3, 59, : #> replacement element 1 has 256 rows to replace 16 rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"posterior-expectations","dir":"Articles","previous_headings":"Extract model estimates","what":"Posterior expectations","title":"Fitting the meta-d' model","text":"Usually simpler compare response probabilities rather raw response counts. , can use workflow using epred_draws_metad (wrapper around tidybayes::epred_draws):","code":"draws.epred <- epred_draws_metad(m, newdata = tibble(.row = 1)) #> # A tibble: 64,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence  .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>   <dbl>  <int>      <int> #>  1     1        0              1        0          4 0.00296     NA         NA #>  2     1        0              1        0          4 0.0100      NA         NA #>  3     1        0              1        0          4 0.00375     NA         NA #>  4     1        0              1        0          4 0.0122      NA         NA #>  5     1        0              1        0          4 0.00535     NA         NA #>  6     1        0              1        0          4 0.00504     NA         NA #>  7     1        0              1        0          4 0.00363     NA         NA #>  8     1        0              1        0          4 0.00509     NA         NA #>  9     1        0              1        0          4 0.00828     NA         NA #> 10     1        0              1        0          4 0.00637     NA         NA #> # ℹ 63,990 more rows #> # ℹ 1 more variable: .draw <int> draws.epred |>   group_by(.row, stimulus, joint_response, response, confidence) |>   median_qi(.epred) |>   group_by(.row) |>   mutate(.true = t(response_probabilities(d.summary$N[.row, ]))) |>   ggplot(aes(x = joint_response)) +   geom_col(aes(y = .true), fill = \"grey80\") +   geom_pointrange(aes(y = .epred, ymin = .lower, ymax = .upper)) +   scale_alpha_discrete(range = c(.25, 1)) +   facet_wrap(~stimulus, labeller = label_both) +   theme_classic(18) #> Warning: Using alpha for a discrete variable is not advised. #> Warning in `[<-.data.frame`(`*tmp*`, , y_vars, value = list(y = c(0.006, : #> replacement element 1 has 256 rows to replace 16 rows"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"mean-confidence","dir":"Articles","previous_headings":"Extract model estimates","what":"Mean confidence","title":"Fitting the meta-d' model","text":"One can also compute implied values mean confidence meta-d’ model using mean_confidence_draws: , .epred refers model-estimated mean confidence per stimulus response, .true empirical mean confidence. addition, can compute mean confidence marginalizing stimuli: responses: stimuli responses:","code":"tibble(.row = 1) |>   add_mean_confidence_draws(m) |>   median_qi(.epred) |>   left_join(d |>     group_by(stimulus, response) |>     summarize(.true = mean(confidence))) #> `summarise()` has regrouped the output. #> Joining with `by = join_by(stimulus, response)` #> ℹ Summaries were computed grouped by stimulus and response. #> ℹ Output is grouped by stimulus. #> ℹ Use `summarise(.groups = \"drop_last\")` to silence this message. #> ℹ Use `summarise(.by = c(stimulus, response))` for per-operation grouping #>   (`?dplyr::dplyr_by`) instead. #> # A tibble: 4 × 10 #>    .row stimulus response .epred .lower .upper .width .point .interval .true #>   <int>    <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0        0   2.07   1.99   2.15   0.95 median qi         2.09 #> 2     1        0        1   1.91   1.83   1.99   0.95 median qi         1.92 #> 3     1        1        0   1.95   1.86   2.04   0.95 median qi         1.90 #> 4     1        1        1   2.08   2.02   2.15   0.95 median qi         2.07 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_stimulus = FALSE) |>   median_qi(.epred) |>   left_join(d |>     group_by(response) |>     summarize(.true = mean(confidence))) #> Joining with `by = join_by(response)` #> # A tibble: 2 × 9 #>    .row response .epred .lower .upper .width .point .interval .true #>   <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0   2.03   1.95   2.11   0.95 median qi         2.03 #> 2     1        1   2.01   1.96   2.07   0.95 median qi         2.01 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_response = FALSE) |>   median_qi(.epred) |>   left_join(d |>     group_by(stimulus) |>     summarize(.true = mean(confidence))) #> Joining with `by = join_by(stimulus)` #> # A tibble: 2 × 9 #>    .row stimulus .epred .lower .upper .width .point .interval .true #>   <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0   1.98   1.93   2.03   0.95 median qi         2    #> 2     1        1   2.06   2.01   2.11   0.95 median qi         2.04 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_stimulus = FALSE, by_response = FALSE) |>   median_qi(.epred) |>   bind_cols(d |>     ungroup() |>     summarize(.true = mean(confidence))) #> # A tibble: 1 × 8 #>    .row .epred .lower .upper .width .point .interval .true #>   <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1   2.02   1.97   2.06   0.95 median qi         2.02"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"metacognitive-bias","dir":"Articles","previous_headings":"Extract model estimates","what":"Metacognitive bias","title":"Fitting the meta-d' model","text":"mean confidence often empirically informative, recommended measure metacognitive bias known confounded type 1 response characteristics (.e., d' c) metacognitive sensitivity (.e., \\textrm{meta-}d'). Instead, recommend new measure metacognitive bias, \\textrm{meta-}\\Delta, distance average confidence criteria \\textrm{meta-}c. \\textrm{meta-}\\Delta can interpreted lying two extremes: \\textrm{meta-}\\Delta = 0, observer uses highest confidence rating, \\textrm{meta-}\\Delta = \\infty, observer uses lowest confidence rating. obtain estimates \\textrm{meta-}\\Delta, one can use function metacognitive_bias_draws:","code":"tibble(.row = 1) |>   add_metacognitive_bias_draws(m) |>   median_qi() #> # A tibble: 2 × 8 #>    .row response metacognitive_bias .lower .upper .width .point .interval #>   <int>    <int>              <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     #> 1     1        0               1.16   1.03   1.30   0.95 median qi        #> 2     1        1               1.57   1.47   1.67   0.95 median qi"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"pseudo-type-1-roc","dir":"Articles","previous_headings":"Extract model estimates","what":"Pseudo Type 1 ROC","title":"Fitting the meta-d' model","text":"obtain type 1 performance pseudo-type 1 ROC, can use add_roc1_draws: , tidy tibble columns .chain, .iteration, .draw identifying individual posterior samples, joint_response, response, confidence identifying different points ROC, .row identifying different ROCs (since data frame one row, one ROC). addition, also p_hit p_fa, contain posterior estimates type 1 hit rate (.e., probability \"1\" response confidence >= c given stimulus==1) type 1 false alarm rate (.e., probability \"1\" response confidence >= c given stimulus==0). visualization, can get posterior summaries ROC using tidybayes::median_qi simply plot line:","code":"draws.roc1 <- tibble(.row = 1) |>   add_roc1_draws(m) #> # A tibble: 28,000 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.997 1.000 #>  2     1              1        0          4     NA         NA     2 0.990 0.997 #>  3     1              1        0          4     NA         NA     3 0.996 0.999 #>  4     1              1        0          4     NA         NA     4 0.988 0.997 #>  5     1              1        0          4     NA         NA     5 0.995 0.999 #>  6     1              1        0          4     NA         NA     6 0.995 0.999 #>  7     1              1        0          4     NA         NA     7 0.996 0.999 #>  8     1              1        0          4     NA         NA     8 0.995 0.999 #>  9     1              1        0          4     NA         NA     9 0.992 0.997 #> 10     1              1        0          4     NA         NA    10 0.994 0.999 #> # ℹ 27,990 more rows draws.roc1 |>   median_qi(p_fa, p_hit) |>   ggplot(aes(     x = p_fa, xmin = p_fa.lower, xmax = p_fa.upper,     y = p_hit, ymin = p_hit.lower, ymax = p_hit.upper   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(False Alarm)\") +   ylab(\"P(Hit)\") +   theme_bw(18)"},{"path":"https://metacoglab.github.io/hmetad/articles/hmetad.html","id":"type-2-roc","dir":"Articles","previous_headings":"Extract model estimates","what":"Type 2 ROC","title":"Fitting the meta-d' model","text":"Finally, plot type 2 performance type 2 ROC, can use add_roc2_draws: tibble looks roc1_draws, except now columns p_hit2 representing type 2 hit rate (.e., probability correct response confidence >= c given response) type 2 false alarm rate (.e., probability incorrect response confidence >= c given response). Note response-specific type 2 ROC, two separate curves two type 1 responses. can also plot type 2 ROC similarly:","code":"draws.roc2 <- tibble(.row = 1) |>   add_roc2_draws(m) #> # A tibble: 24,000 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw  p_hit2   p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>   <dbl>   <dbl> #>  1     1        0          4     NA         NA     1 0.00659 0.00233 #>  2     1        0          4     NA         NA     2 0.0226  0.0134  #>  3     1        0          4     NA         NA     3 0.00824 0.00468 #>  4     1        0          4     NA         NA     4 0.0270  0.0138  #>  5     1        0          4     NA         NA     5 0.0120  0.00552 #>  6     1        0          4     NA         NA     6 0.0119  0.00678 #>  7     1        0          4     NA         NA     7 0.00841 0.00410 #>  8     1        0          4     NA         NA     8 0.0115  0.00608 #>  9     1        0          4     NA         NA     9 0.0205  0.0114  #> 10     1        0          4     NA         NA    10 0.0138  0.00559 #> # ℹ 23,990 more rows draws.roc2 |>   median_qi(p_hit2, p_fa2) |>   mutate(response = factor(response)) |>   ggplot(aes(     x = p_fa2, xmin = p_fa2.lower, xmax = p_fa2.upper,     y = p_hit2, ymin = p_hit2.lower, ymax = p_hit2.upper,     color = response   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(Type 2 False Alarm)\") +   ylab(\"P(Type 2 Hit)\") +   theme_bw(18)"},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parameterization of the meta-d' model","text":"metacognition research, decision-making often categorized two kinds. type 1 decision primary decision hand, example judging orientation grating left right, judging word either presented (old) (new). context meta-d’ model, type 1 decision binary decision task (.e., either yes-decision task two-alternative forced choice task). contrast, type 2 decision task rating confidence type 1 decision. meta-d’ model applicable type 2 decision categorical (.e., confidence rated ordinal scale 1 K, 1 indicates low confidence K indicates high confidence). line distinction type 1 type 2 decisions, meta-d’ model conjunction two models (one decision). models based Signal Detection Theory (SDT). However, insight meta-d’ model information available type 2 decisions might differ information available type 1 decisions.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"model-for-type-1-decisions","dir":"Articles","previous_headings":"","what":"Model for type 1 decisions","title":"Parameterization of the meta-d' model","text":"SDT, observer presented noisy signal depending underlying stimulus x_1 \\sim \\mathcal{D}_S(d') following distribution \\mathcal{D} dependent stimulus S \\\\{0, 1\\} observer’s sensitivity d'. Typically, \\mathcal{D} chosen equal-variance normal distribution, \\mathcal{D}_0(d') = \\mathcal{N}\\left(-\\frac{d'}{2}, 1\\right) \\mathcal{D}_1(d') = \\mathcal{N}\\left(\\frac{d'}{2}, 1\\right) However, decision arbitrary options available. Given noisy encoding x_1, observer tasked determining true value S. , simply threshold x_1 response R = [x_1 > c] setup, observer makes correct response R = S. importantly, trials can categorized hits (S = 1 R = 1), misses (S = 1 R = 0), false alarms (FAs; S = 0 R = 1), correct rejections (CRs; S = 0 R = 0). generative model type 1 decisions implies following response probabilities: P(R=r \\;\\vert\\; S=s) = \\begin{cases} 1 - F_{\\mathcal{D}_s(d')}\\left(c\\right) & \\textrm{} r=1 \\\\ F_{\\mathcal{D}_s(d')}\\left(c\\right) & \\textrm{} r=0 \\end{cases}","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"model-for-type-2-decisions","dir":"Articles","previous_headings":"","what":"Model for type 2 decisions","title":"Parameterization of the meta-d' model","text":"classical SDT, type 2 decisions treated just like type 1 decisions stringent liberal response criteria. However, assumes observers access information making type 1 type 2 decisions. Relaxing assumption, meta-d’ model assumes type 2 decisions derived separate decision variable: x_2 \\sim \\begin{cases} \\mathcal{D}_S^{(-\\infty, \\textrm{meta-}c]}\\left(\\textrm{meta-}d'\\right) & \\textrm{} R=0 \\\\ \\mathcal{D}_S^{[\\textrm{meta-}c, \\infty)}\\left(\\textrm{meta-}d'\\right) & \\textrm{} R=1 \\end{cases} Importantly, decision variable follows distribution type 1 decision, two differences. First, distribution truncated either type 1 criterion \\textrm{meta-}c depending initial type 1 response. type 2 decision contradict type 1 decision (.e., meta-d’ model allow changes mind). Second, sensitivity type 2 decision \\textrm{meta-}d' rather d' allow task-level sensitivity metacognitive sensitivity differ. , determine confidence level C \\\\{ 1 \\ldots K\\}, observer rates confidence using one two sets K-1 ordered confidence criteria (\\textrm{meta-}c_2^0 \\textrm{meta-}c_2^1): \\begin{align*}     C &= \\begin{cases}     1+\\Sigma_{k=1}^{K-1}[x_2 < \\textrm{meta-}c_{2,k}^0] & \\textrm{} R=0 \\\\     1+\\Sigma_{k=1}^{K-1} [x_2 > \\textrm{meta-}c_{2,k}^1] & \\textrm{} R=1     \\end{cases} \\end{align*} generative model implies , conditional stimulus type 1 response, type 2 response probabilities \\begin{align*}     P(C=c \\;\\vert\\; R=r,S=s) &= \\begin{cases}     \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,1}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=0, c=1 \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k}^0\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k+1}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}       & \\textrm{} r=0, 1 \\le c \\le K \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,K}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=0, c = K \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,1}^0\\right) -     F_{\\mathcal{D}_s}\\left(\\textrm{meta-}c \\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, c=1 \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k+1}^0\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k}^0\\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, 1 \\le c \\le K \\\\          \\frac{1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,K}^0 \\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, c = K     \\end{cases} \\end{align*} formulas, numerator probability x_2 lies successive confidence thresholds denominator probability type 1 response r given type 2 parameters \\textrm{meta-}d' \\textrm{meta-}c account truncation type 2 signal distributions \\textrm{meta-}c.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"joint-model-for-type-1-and-type-2-decisions","dir":"Articles","previous_headings":"","what":"Joint model for type 1 and type 2 decisions","title":"Parameterization of the meta-d' model","text":"Ultimately, interested joint type 1 type 2 response probabilities stimulus. can conveniently decomposed type 1 response probability conditional type 2 response probability follows: P(R=r, C=c \\;\\vert\\; S=s) = P(R=r \\;\\vert\\; S=s) \\; P(C=c \\;\\vert\\; R=r, S=s) Given joint response probabilities stimulus, can formulate log likelihood meta-d’ one two ways. trial-level effects interest, one can model individual trials using categorical likelihood: LL \\;=\\; \\sum_n \\textrm{categorical}\\_\\textrm{lpmf}\\left(\\textrm{joint}\\_\\textrm{response}(r_n,c_n) \\;\\vert\\; P(R=r_n, C=c_n \\;\\vert\\; S=s_n)\\right) However, formulation requires likelihood evaluated per trial, well-powered experiments can take long time. , default hmetad package uses multinomial likelihood aggregated data. N_{s,r,c} number trials S=s, R=r, C=c: \\begin{align*} LL \\;&=\\; \\textrm{multinomial}\\_\\textrm{lpmf}\\left(N_{0,r,c} \\;\\vert\\; P(R=r, C=c \\;\\vert\\; S=0)\\right) \\\\ &\\;\\quad+\\; \\textrm{multinomial}\\_\\textrm{lpmf}\\left(N_{1,r,c} \\;\\vert\\; P(R=r, C=c \\;\\vert\\; S=1)\\right) \\end{align*} formulation requires model likelihood evaluated twice (per stimulus), dramatically increasing efficiency model fitting. increase efficiency, multinomial likelihood default hmetad package. categorical likelihood desired (e.g., trial-level effects crossed random effects), can used argument categorical=TRUE.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"fixing-the-type-1-threshold-for-type-2-responses","dir":"Articles","previous_headings":"","what":"Fixing the type 1 threshold for type 2 responses","title":"Parameterization of the meta-d' model","text":"meta-d’ model requires parameter \\textrm{meta-}c fixed equal respect type 1 criterion c. discussed (Maniscalco & Lau, 2014), multiple ways fixing \\textrm{meta-}c. hmetad package implements two: fixed parameterization, \\textrm{meta-}c = c. parameterization used default, since also used Hmeta-d toolbox (see also Fleming (2017)). Alternatively, relative parameterization, \\frac{\\textrm{meta-}c}{\\textrm{meta-}d'} = \\frac{c}{d'}, achieved setting \\textrm{meta-}c = M c. parameterization used (Maniscalco & Lau, 2012, 2014). switch two parameterizations, fit_metad sim_metad functions argument metac_absolute TRUE default. use relative parameterization, simply set metac_absolute=FALSE call function.","code":""},{"path":"https://metacoglab.github.io/hmetad/articles/parameterization.html","id":"model-parameterization","dir":"Articles","previous_headings":"","what":"Model parameterization","title":"Parameterization of the meta-d' model","text":"increase efficiency model fitting help convergence, hmetad parameterizes meta-d’ model parameters unconstrained variables (.e., fall range (-\\infty, \\infty)). parameters type 1 responses (d' c) already unconstrained, estimated normally. However, parameters type 2 parameters bounded. First, instead fitting \\textrm{meta-}d' directly, hmetad package models M-ratio M = \\frac{\\textrm{meta-}d'}{d'}. parameterization helps regularize strong differences \\textrm{meta-}d' d', M-ratio still bounded zero. , hmetad package models M-ratio logarithmic scale, .e., \\textrm{log }M = \\textrm{log}\\frac{\\textrm{meta-}d'}{d'}. parameterization, one can compute \\textrm{meta-}d' \\textrm{meta-}d' = e^{\\textrm{log }M}d'. Second, confidence criteria \\textrm{meta-}c_{2,1:K}^0 \\textrm{meta-}c_{2,1:K}^1 two constraints. Namely, \\textrm{meta-}c_{2,1:K}^0 must strictly decreasing less \\textrm{meta-}c, whereas \\textrm{meta-}c_{2,1:K}^1 must strictly increasing greater \\textrm{meta-}c. deal constraints, hmetad package estimates differences successive confidence criteria: \\textrm{dmeta-}c_{2,k}^0 = \\begin{cases}   \\textrm{meta-}c - \\textrm{meta-}c_{2,1}^0 & \\textrm{} k = 1 \\\\   \\textrm{meta-}c_{2,k-1}^0  - \\textrm{meta-}c_{2,k}^0 & \\textrm{} 2 \\le k \\le K \\end{cases}   \\textrm{dmeta-}c_{2,k}^1 = \\begin{cases}   \\textrm{meta-}c_{2,1}^0 - \\textrm{meta-}c & \\textrm{} k = 1 \\\\   \\textrm{meta-}c_{2,k}^1  - \\textrm{meta-}c_{2,k-1}^1 & \\textrm{} 2 \\le k \\le K \\end{cases} Like M-ratio, differences successive confidence criteria also modeled logarithmic scale (parameters named metac2zero<k>diff metac2one<k>diff). parameterization, confidence criteria can computed follows: \\begin{align*} \\textrm{meta-}c_2^0 &= \\textrm{meta-}c - \\textrm{cumulative}\\_\\textrm{sum}\\left(e^{\\textrm{dmeta-}c_2^0}\\right) \\\\ \\textrm{meta-}c_2^1 &= \\textrm{meta-}c + \\textrm{cumulative}\\_\\textrm{sum}\\left(e^{\\textrm{dmeta-}c_2^1}\\right) \\end{align*}","code":""},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kevin O'Neill. Author, maintainer, copyright holder.","code":""},{"path":"https://metacoglab.github.io/hmetad/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"O'Neill K (2026). hmetad: Fit Meta-D' Model Confidence Ratings Using 'brms'. R package version 0.0.1, https://metacoglab.github.io/hmetad/.","code":"@Manual{,   title = {hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms'},   author = {Kevin O'Neill},   year = {2026},   note = {R package version 0.0.1},   url = {https://metacoglab.github.io/hmetad/}, }"},{"path":"https://metacoglab.github.io/hmetad/index.html","id":"hmetad","dir":"","previous_headings":"","what":"Fit the Meta-D Model of Confidence Ratings Using brms'","title":"Fit the Meta-D Model of Confidence Ratings Using brms'","text":"hmetad package designed fit meta-d’ model confidence ratings (Maniscalco & Lau, 2012, 2014). Like Hmeta-d toolbox (Fleming, 2017), hmetad package uses Bayesian modeling approach. hmetad package builds Hmeta-d toolbox implementation custom family brms package, provides friendly interface probabilistic programming language Stan. provides major benefits: Model designs can specified simple R formulas Support complex model designs (e.g., multilevel models, distributional models, multivariate models) Interfaces packages surrounding brms (e.g., tidybayes, ggdist, bayesplot, loo, posterior, bridgesampling, bayestestR) Computation model-implied quantities (e.g., mean confidence, type 1 type 2 receiver operating characteristic curves, metacognitive bias) Increased sampling efficiency better convergence diagnostics","code":""},{"path":"https://metacoglab.github.io/hmetad/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fit the Meta-D Model of Confidence Ratings Using brms'","text":"hmetad currently submission CRAN, means soon able install using: now, can install development version hmetad GitHub :","code":"install.packages(\"hmetad\") # install.packages(\"pak\") pak::pak(\"metacoglab/hmetad\")"},{"path":"https://metacoglab.github.io/hmetad/index.html","id":"quick-setup","dir":"","previous_headings":"","what":"Quick setup","title":"Fit the Meta-D Model of Confidence Ratings Using brms'","text":"Let’s say data binary decision task ordinal confidence ratings: can fit intercepts-meta-d’ model using fit_metad: Now let’s say complicated design, within-participant manipulation: account repeated measures design, can simply adjust formula include participant-level effects:","code":"#> # A tibble: 1,000 × 5 #>    trial stimulus response correct confidence #>    <int>    <int>    <int>   <int>      <int> #>  1     1        1        0       0          3 #>  2     2        1        1       1          2 #>  3     3        1        1       1          4 #>  4     4        1        1       1          1 #>  5     5        1        1       1          4 #>  6     6        0        0       1          1 #>  7     7        1        0       0          2 #>  8     8        1        1       1          2 #>  9     9        0        0       1          3 #> 10    10        1        1       1          3 #> # ℹ 990 more rows library(hmetad)  m <- fit_metad(N ~ 1, data = d, file = \"vignettes/models/readme1.rds\") #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept     0.00      0.15    -0.30     0.28 1.00     3061     2726 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              1.01      0.08     0.84     1.17 1.00     3858     3126 #> c                   0.02      0.04    -0.06     0.10 1.00     3950     2891 #> metac2zero1diff     0.52      0.04     0.45     0.60 1.00     4451     3184 #> metac2zero2diff     0.47      0.04     0.40     0.55 1.00     5156     2827 #> metac2zero3diff     0.50      0.05     0.41     0.59 1.00     4886     3072 #> metac2one1diff      0.45      0.03     0.38     0.51 1.00     5075     3382 #> metac2one2diff      0.48      0.04     0.40     0.55 1.00     4820     3042 #> metac2one3diff      0.53      0.05     0.44     0.62 1.00     6408     3018 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1). #> # A tibble: 5,000 × 7 #> # Groups:   participant, condition [50] #>    participant condition trial stimulus response correct confidence #>          <int>     <int> <int>    <int>    <int>   <int>      <int> #>  1           1         1     1        0        0       1          2 #>  2           1         1     2        1        1       1          4 #>  3           1         1     3        0        0       1          4 #>  4           1         1     4        1        0       0          1 #>  5           1         1     5        0        1       0          1 #>  6           1         1     6        1        0       0          1 #>  7           1         1     7        1        0       0          1 #>  8           1         1     8        1        1       1          4 #>  9           1         1     9        0        0       1          4 #> 10           1         1    10        0        0       1          4 #> # ℹ 4,990 more rows m <- fit_metad(   bf(     N ~ condition + (condition | participant),     dprime + c +       metac2zero1diff + metac2zero2diff + metac2zero3diff +       metac2one1diff + metac2one2diff + metac2one3diff ~       condition + (condition | participant)   ),   data = d, init = \"0\", file = \"vignettes/models/readme2.rds\",   prior = prior(normal(0, 1)) +     prior(normal(0, 1), dpar = dprime) +     prior(normal(0, 1), dpar = c) +     prior(normal(0, 1), dpar = metac2zero1diff) +     prior(normal(0, 1), dpar = metac2zero2diff) +     prior(normal(0, 1), dpar = metac2zero3diff) +     prior(normal(0, 1), dpar = metac2one1diff) +     prior(normal(0, 1), dpar = metac2one2diff) +     prior(normal(0, 1), dpar = metac2one3diff) ) #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log; dprime = identity; c = identity; metac2zero1diff = log; metac2zero2diff = log; metac2zero3diff = log; metac2one1diff = log; metac2one2diff = log; metac2one3diff = log  #> Formula: N ~ condition + (condition | participant)  #>          dprime ~ condition + (condition | participant) #>          c ~ condition + (condition | participant) #>          metac2zero1diff ~ condition + (condition | participant) #>          metac2zero2diff ~ condition + (condition | participant) #>          metac2zero3diff ~ condition + (condition | participant) #>          metac2one1diff ~ condition + (condition | participant) #>          metac2one2diff ~ condition + (condition | participant) #>          metac2one3diff ~ condition + (condition | participant) #>    Data: data.aggregated (Number of observations: 50)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Multilevel Hyperparameters: #> ~participant (Number of levels: 25)  #>                                                           Estimate Est.Error #> sd(Intercept)                                                 0.17      0.12 #> sd(condition2)                                                0.69      0.21 #> sd(dprime_Intercept)                                          0.38      0.08 #> sd(dprime_condition2)                                         0.76      0.14 #> sd(c_Intercept)                                               0.66      0.10 #> sd(c_condition2)                                              0.93      0.14 #> sd(metac2zero1diff_Intercept)                                 0.07      0.06 #> sd(metac2zero1diff_condition2)                                0.10      0.08 #> sd(metac2zero2diff_Intercept)                                 0.11      0.08 #> sd(metac2zero2diff_condition2)                                0.22      0.13 #> sd(metac2zero3diff_Intercept)                                 0.09      0.06 #> sd(metac2zero3diff_condition2)                                0.11      0.09 #> sd(metac2one1diff_Intercept)                                  0.08      0.06 #> sd(metac2one1diff_condition2)                                 0.15      0.10 #> sd(metac2one2diff_Intercept)                                  0.06      0.05 #> sd(metac2one2diff_condition2)                                 0.24      0.13 #> sd(metac2one3diff_Intercept)                                  0.15      0.09 #> sd(metac2one3diff_condition2)                                 0.14      0.10 #> cor(Intercept,condition2)                                    -0.29      0.47 #> cor(dprime_Intercept,dprime_condition2)                      -0.59      0.17 #> cor(c_Intercept,c_condition2)                                -0.71      0.11 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)    -0.30      0.58 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)    -0.49      0.52 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)    -0.19      0.57 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)      -0.17      0.58 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)      -0.11      0.58 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)       0.10      0.56 #>                                                           l-95% CI u-95% CI #> sd(Intercept)                                                 0.01     0.44 #> sd(condition2)                                                0.37     1.21 #> sd(dprime_Intercept)                                          0.25     0.55 #> sd(dprime_condition2)                                         0.53     1.07 #> sd(c_Intercept)                                               0.49     0.89 #> sd(c_condition2)                                              0.70     1.25 #> sd(metac2zero1diff_Intercept)                                 0.00     0.22 #> sd(metac2zero1diff_condition2)                                0.00     0.31 #> sd(metac2zero2diff_Intercept)                                 0.00     0.29 #> sd(metac2zero2diff_condition2)                                0.02     0.51 #> sd(metac2zero3diff_Intercept)                                 0.00     0.24 #> sd(metac2zero3diff_condition2)                                0.00     0.31 #> sd(metac2one1diff_Intercept)                                  0.00     0.22 #> sd(metac2one1diff_condition2)                                 0.01     0.38 #> sd(metac2one2diff_Intercept)                                  0.00     0.18 #> sd(metac2one2diff_condition2)                                 0.02     0.52 #> sd(metac2one3diff_Intercept)                                  0.01     0.33 #> sd(metac2one3diff_condition2)                                 0.01     0.36 #> cor(Intercept,condition2)                                    -0.95     0.78 #> cor(dprime_Intercept,dprime_condition2)                      -0.85    -0.22 #> cor(c_Intercept,c_condition2)                                -0.88    -0.47 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)    -0.99     0.89 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)    -0.99     0.81 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)    -0.97     0.91 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)      -0.97     0.93 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)      -0.96     0.94 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)      -0.92     0.95 #>                                                           Rhat Bulk_ESS #> sd(Intercept)                                             1.00      894 #> sd(condition2)                                            1.00      881 #> sd(dprime_Intercept)                                      1.00     1591 #> sd(dprime_condition2)                                     1.00     1070 #> sd(c_Intercept)                                           1.00      695 #> sd(c_condition2)                                          1.00      686 #> sd(metac2zero1diff_Intercept)                             1.00     1307 #> sd(metac2zero1diff_condition2)                            1.00     1289 #> sd(metac2zero2diff_Intercept)                             1.00      987 #> sd(metac2zero2diff_condition2)                            1.00      719 #> sd(metac2zero3diff_Intercept)                             1.00     1332 #> sd(metac2zero3diff_condition2)                            1.00     1132 #> sd(metac2one1diff_Intercept)                              1.00     1552 #> sd(metac2one1diff_condition2)                             1.01      766 #> sd(metac2one2diff_Intercept)                              1.00     1951 #> sd(metac2one2diff_condition2)                             1.00      818 #> sd(metac2one3diff_Intercept)                              1.00     1196 #> sd(metac2one3diff_condition2)                             1.00     1443 #> cor(Intercept,condition2)                                 1.01      457 #> cor(dprime_Intercept,dprime_condition2)                   1.00      677 #> cor(c_Intercept,c_condition2)                             1.01      610 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2) 1.00     2033 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2) 1.00     1017 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2) 1.00     3046 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)   1.00     1288 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)   1.00      788 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)   1.00     2317 #>                                                           Tail_ESS #> sd(Intercept)                                                 1943 #> sd(condition2)                                                 483 #> sd(dprime_Intercept)                                          2145 #> sd(dprime_condition2)                                         2167 #> sd(c_Intercept)                                               1344 #> sd(c_condition2)                                              1493 #> sd(metac2zero1diff_Intercept)                                 1966 #> sd(metac2zero1diff_condition2)                                1732 #> sd(metac2zero2diff_Intercept)                                 1638 #> sd(metac2zero2diff_condition2)                                1191 #> sd(metac2zero3diff_Intercept)                                 2255 #> sd(metac2zero3diff_condition2)                                1212 #> sd(metac2one1diff_Intercept)                                  1946 #> sd(metac2one1diff_condition2)                                  508 #> sd(metac2one2diff_Intercept)                                  1211 #> sd(metac2one2diff_condition2)                                 1499 #> sd(metac2one3diff_Intercept)                                  1495 #> sd(metac2one3diff_condition2)                                 1986 #> cor(Intercept,condition2)                                      992 #> cor(dprime_Intercept,dprime_condition2)                       1722 #> cor(c_Intercept,c_condition2)                                 1272 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)     2653 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)     2062 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)     3145 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)       2284 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)       1688 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)       2324 #>  #> Regression Coefficients: #>                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS #> Intercept                      0.18      0.10    -0.03     0.37 1.00     3126 #> dprime_Intercept               0.93      0.09     0.75     1.12 1.00     1744 #> c_Intercept                    0.15      0.13    -0.12     0.40 1.00      447 #> metac2zero1diff_Intercept     -0.97      0.06    -1.09    -0.87 1.00     5437 #> metac2zero2diff_Intercept     -1.13      0.07    -1.27    -0.99 1.00     2138 #> metac2zero3diff_Intercept     -0.91      0.06    -1.04    -0.79 1.00     5887 #> metac2one1diff_Intercept      -1.04      0.06    -1.16    -0.92 1.00     4920 #> metac2one2diff_Intercept      -0.98      0.06    -1.11    -0.86 1.00     6606 #> metac2one3diff_Intercept      -1.06      0.08    -1.22    -0.91 1.00     2715 #> condition2                    -0.22      0.21    -0.66     0.18 1.00     1489 #> dprime_condition2              0.07      0.17    -0.26     0.40 1.00      844 #> c_condition2                  -0.02      0.18    -0.37     0.34 1.00      536 #> metac2zero1diff_condition2    -0.04      0.08    -0.20     0.14 1.00     5345 #> metac2zero2diff_condition2     0.12      0.10    -0.08     0.32 1.00     2607 #> metac2zero3diff_condition2    -0.18      0.09    -0.36    -0.00 1.00     4658 #> metac2one1diff_condition2     -0.01      0.09    -0.20     0.17 1.00     4540 #> metac2one2diff_condition2     -0.14      0.11    -0.36     0.07 1.00     2922 #> metac2one3diff_condition2      0.00      0.11    -0.21     0.21 1.00     3172 #>                            Tail_ESS #> Intercept                      2775 #> dprime_Intercept               2402 #> c_Intercept                     774 #> metac2zero1diff_Intercept      3154 #> metac2zero2diff_Intercept       655 #> metac2zero3diff_Intercept      2420 #> metac2one1diff_Intercept       3165 #> metac2one2diff_Intercept       3128 #> metac2one3diff_Intercept        596 #> condition2                     1211 #> dprime_condition2              1515 #> c_condition2                   1152 #> metac2zero1diff_condition2     2301 #> metac2zero2diff_condition2      674 #> metac2zero3diff_condition2     3009 #> metac2one1diff_condition2      2980 #> metac2one2diff_condition2      2464 #> metac2one3diff_condition2      1546 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate data by response, confidence, and other columns — aggregate_metad","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"Counts number rows data unique combinations values columns response, confidence, columns ....","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"","code":"aggregate_metad(   data,   ...,   .stimulus = \"stimulus\",   .response = \"response\",   .confidence = \"confidence\",   .joint_response = \"joint_response\",   .name = \"N\",   K = NULL )"},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"data data frame aggregate ... Grouping columns data. columns converted factors. .stimulus name \"stimulus\" column .response name \"response\" column .confidence name \"confidence\" column .joint_response name \"joint_response\" column .name name resulting column containing trial counts K number confidence levels data. NULL, estimated data.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"tibble one row per combination variables ..., another column named value .response containing trial counts. \\(K\\) confidence levels, \\(N \\times K*4\\) matrix, columns represent (stimulus \\(S\\), type 1 response \\(R\\), type 2 response \\(C\\)): $$  [N_{S=0, R=0, C=K}, \\ldots, N_{S=0, R=0, C=1}, \\\\  N_{S=0, R=1, C=1}, \\ldots, N_{S=0, R=1, C=K}, \\\\  N_{S=1, R=0, C=K}, \\ldots, N_{S=1, R=0, C=1}, \\\\  N_{S=1, R=1, C=1}, \\ldots, N_{S=1, R=1, C=K}] \\\\ $$","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"data frame data must one column name given .stimulus. Additionally, must either: Two columns names given .response .confidence One column name given .joint_response Finally, must also columns additional variables ....","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/aggregate_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"","code":"# aggregate a dataset without grouping factors d <- sim_metad() aggregate_metad(d) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1    50    50           8          5          4         12         10          7 #> # ℹ 1 more variable: N[7:16] <int>  # aggregate a dataset with grouping factors d2 <- sim_metad_condition() aggregate_metad(d2, condition) #> # A tibble: 2 × 4 #>   condition   N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] #>   <fct>     <int> <int>       <int>      <int>      <int>      <int>      <int> #> 1 1            50    50           7          4         10         16          5 #> 2 2            50    50           3          6         10         13          9 #> # ℹ 1 more variable: N[6:16] <int>  # can also aggregate ignoring grouping factors aggregate_metad(d2) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   100   100          10         10         20         29         14          9 #> # ℹ 1 more variable: N[7:16] <int>  # aggregate data with only `joint_response` column library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union d |>   ungroup() |>   mutate(joint_response = joint_response(     response, confidence,     n_distinct(confidence)   )) |>   select(-response, -confidence) |>   aggregate_metad() #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1    50    50           8          5          4         12         10          7 #> # ℹ 1 more variable: N[7:16] <int>"},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"Computes \\(\\textrm{meta-}\\Delta\\), index metacognitive bias. \\(\\textrm{meta-}\\Delta\\) distance meta_c average confidence criteria meta_c2_0 meta_c2_1. metacognitive_bias_draws add_metacognitive_bias_draws, parameters returned tidy tibble one row per posterior draw per response. metacognitive_bias_rvars add_metacognitive_bias_rvars, parameters returned posterior::rvars, one row per row newdata per response.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"","code":"metacognitive_bias_draws(object, newdata, ..., by_response = TRUE)  add_metacognitive_bias_draws(newdata, object, ...)  metacognitive_bias_rvars(object, newdata, ..., by_response = TRUE)  add_metacognitive_bias_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws tidybayes::epred_rvars by_response TRUE, compute metacognitive bias separately two type 1 responses. FALSE, compute un-weighted average two measures.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"tibble containing posterior draws \\(\\textrm{meta-}\\Delta\\) following columns: .row: row newdata .chain, .iteration, .draw: metacognitive_bias_draws add_metacognitive_bias_draws, identifiers posterior sample response: type 1 response perceived stimulus presence metacognitive_bias: distance meta_c average confidence criteria meta_c2_{response}.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/bias_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"","code":"if (FALSE) { # \\dontrun{   # running few iterations so example runs quickly, use more in practice   example_data <- sim_metad(N_trials=1000)   example_model <- fit_metad(N ~ 1, example_data, chains = 1, iter = 500) } # } example_model <- hmetad:::example_model newdata <- tidyr::tibble(.row = 1)  # compute metacognitive bias metacognitive_bias_draws(example_model, newdata) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row response .chain .iteration .draw metacognitive_bias #>    <int>    <int>  <int>      <int> <int>              <dbl> #>  1     1        0     NA         NA     1              0.949 #>  2     1        0     NA         NA     2              0.938 #>  3     1        0     NA         NA     3              0.974 #>  4     1        0     NA         NA     4              1.08  #>  5     1        0     NA         NA     5              1.03  #>  6     1        0     NA         NA     6              1.04  #>  7     1        0     NA         NA     7              0.948 #>  8     1        0     NA         NA     8              0.941 #>  9     1        0     NA         NA     9              0.969 #> 10     1        0     NA         NA    10              1.01  #> # ℹ 490 more rows add_metacognitive_bias_draws(newdata, example_model) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row response .chain .iteration .draw metacognitive_bias #>    <int>    <int>  <int>      <int> <int>              <dbl> #>  1     1        0     NA         NA     1              0.949 #>  2     1        0     NA         NA     2              0.938 #>  3     1        0     NA         NA     3              0.974 #>  4     1        0     NA         NA     4              1.08  #>  5     1        0     NA         NA     5              1.03  #>  6     1        0     NA         NA     6              1.04  #>  7     1        0     NA         NA     7              0.948 #>  8     1        0     NA         NA     8              0.941 #>  9     1        0     NA         NA     9              0.969 #> 10     1        0     NA         NA    10              1.01  #> # ℹ 490 more rows  # use posterior::rvar for increased efficiency metacognitive_bias_rvars(example_model, newdata) #> # A tibble: 2 × 3 #> # Groups:   .row, response [2] #>    .row response metacognitive_bias #>   <dbl>    <int>         <rvar[1d]> #> 1     1        0       0.98 ± 0.044 #> 2     1        1       1.01 ± 0.047 add_metacognitive_bias_rvars(newdata, example_model) #> # A tibble: 2 × 3 #> # Groups:   .row, response [2] #>    .row response metacognitive_bias #>   <dbl>    <int>         <rvar[1d]> #> 1     1        0       0.98 ± 0.044 #> 2     1        1       1.01 ± 0.047  # average over the two type 1 responses metacognitive_bias_draws(example_model, newdata, by_response = FALSE) #> # A tibble: 250 × 5 #> # Groups:   .row [1] #>     .row .chain .iteration .draw metacognitive_bias #>    <int>  <int>      <int> <int>              <dbl> #>  1     1     NA         NA     1              1.00  #>  2     1     NA         NA     2              1.01  #>  3     1     NA         NA     3              0.994 #>  4     1     NA         NA     4              0.984 #>  5     1     NA         NA     5              1.02  #>  6     1     NA         NA     6              0.996 #>  7     1     NA         NA     7              0.996 #>  8     1     NA         NA     8              1.00  #>  9     1     NA         NA     9              1.02  #> 10     1     NA         NA    10              1.01  #> # ℹ 240 more rows metacognitive_bias_rvars(example_model, newdata, by_response = FALSE) #> # A tibble: 1 × 2 #> # Groups:   .row [1] #>    .row metacognitive_bias #>   <dbl>         <rvar[1d]> #> 1     1        0.99 ± 0.03"},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"Generate correlation matrix -diagonal values equal r","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"","code":"cor_matrix(r, nrow = 2)"},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"r correlation fill matrix -diagonals nrow number rows (columns) resulting matrix","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"[nrow x nrow] matrix values along diagonal equal 1 values diagonal equal r","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cor_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"","code":"cor_matrix(0, nrow = 3) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1  cor_matrix(-.5, nrow = 4) #>      [,1] [,2] [,3] [,4] #> [1,]  1.0 -0.5 -0.5 -0.5 #> [2,] -0.5  1.0 -0.5 -0.5 #> [3,] -0.5 -0.5  1.0 -0.5 #> [4,] -0.5 -0.5 -0.5  1.0"},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a covariance matrix. — cov_matrix","title":"Generate a covariance matrix. — cov_matrix","text":"Generate covariance matrix.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a covariance matrix. — cov_matrix","text":"","code":"cov_matrix(S, OMEGA)"},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a covariance matrix. — cov_matrix","text":"S vector standard deviations OMEGA correlation matrix","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a covariance matrix. — cov_matrix","text":"\\(N \\times N\\) covariance matrix, N = length(S).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/cov_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a covariance matrix. — cov_matrix","text":"","code":"sds <- c(1, 2) corrs <- matrix(c(1, .5, .5, 1), nrow = 2) cov_matrix(sds, corrs) #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    4"},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of joint response probabilities — epred_draws_metad","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"Given data frame meta-d' model, adds estimates joint type 1 type 2 response probabilities. epred_draws_metad add_epred_draws_metad, estimates returned tidy tibble one row per posterior draw. epred_rvars_metad add_epred_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"","code":"epred_draws_metad(object, newdata, ...)  add_epred_draws_metad(newdata, object, ...)  epred_rvars_metad(object, newdata, ...)  add_epred_rvars_metad(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_epred_draws tidybayes::add_epred_rvars","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: epred_draws_metad, identifiers posterior sample stimulus, joint_response, response, confidence: identifiers response type .epred: probability type 1 type 2 response given stimulus, \\(P(R, C \\;\\vert\\; S)\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/epred_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"","code":"if (FALSE) { # \\dontrun{   # running few iterations so example runs quickly, use more in practice   example_data <- sim_metad(N_trials=1000)   example_model <- fit_metad(N ~ 1, example_data, chains = 1, iter = 500) } # } example_model <- hmetad:::example_model newdata <- tidyr::tibble(.row = 1)  # obtain model predictions epred_draws_metad(example_model, newdata) #> # A tibble: 4,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>  <dbl>  <int>      <int> #>  1     1        0              1        0          4  0.191     NA         NA #>  2     1        0              1        0          4  0.209     NA         NA #>  3     1        0              1        0          4  0.171     NA         NA #>  4     1        0              1        0          4  0.174     NA         NA #>  5     1        0              1        0          4  0.196     NA         NA #>  6     1        0              1        0          4  0.185     NA         NA #>  7     1        0              1        0          4  0.183     NA         NA #>  8     1        0              1        0          4  0.176     NA         NA #>  9     1        0              1        0          4  0.184     NA         NA #> 10     1        0              1        0          4  0.172     NA         NA #> # ℹ 3,990 more rows #> # ℹ 1 more variable: .draw <int> add_epred_draws_metad(newdata, example_model) #> # A tibble: 4,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>  <dbl>  <int>      <int> #>  1     1        0              1        0          4  0.191     NA         NA #>  2     1        0              1        0          4  0.209     NA         NA #>  3     1        0              1        0          4  0.171     NA         NA #>  4     1        0              1        0          4  0.174     NA         NA #>  5     1        0              1        0          4  0.196     NA         NA #>  6     1        0              1        0          4  0.185     NA         NA #>  7     1        0              1        0          4  0.183     NA         NA #>  8     1        0              1        0          4  0.176     NA         NA #>  9     1        0              1        0          4  0.184     NA         NA #> 10     1        0              1        0          4  0.172     NA         NA #> # ℹ 3,990 more rows #> # ℹ 1 more variable: .draw <int>  # obtain model predictions (posterior::rvar) epred_rvars_metad(example_model, newdata) #> # A tibble: 16 × 6 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence          .epred #>    <int>    <int>          <int>    <int>      <dbl>      <rvar[1d]> #>  1     1        0              1        0          4  0.188 ± 0.0169 #>  2     1        0              2        0          3  0.147 ± 0.0142 #>  3     1        0              3        0          2  0.180 ± 0.0159 #>  4     1        0              4        0          1  0.184 ± 0.0150 #>  5     1        0              5        1          1  0.143 ± 0.0144 #>  6     1        0              6        1          2  0.099 ± 0.0099 #>  7     1        0              7        1          3  0.040 ± 0.0051 #>  8     1        0              8        1          4  0.019 ± 0.0039 #>  9     1        1              1        0          4  0.025 ± 0.0045 #> 10     1        1              2        0          3  0.043 ± 0.0057 #> 11     1        1              3        0          2  0.088 ± 0.0087 #> 12     1        1              4        0          1  0.155 ± 0.0149 #> 13     1        1              5        1          1  0.171 ± 0.0131 #> 14     1        1              6        1          2  0.208 ± 0.0145 #> 15     1        1              7        1          3  0.153 ± 0.0139 #> 16     1        1              8        1          4  0.158 ± 0.0152 add_epred_rvars_metad(newdata, example_model) #> # A tibble: 16 × 6 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence          .epred #>    <int>    <int>          <int>    <int>      <dbl>      <rvar[1d]> #>  1     1        0              1        0          4  0.188 ± 0.0169 #>  2     1        0              2        0          3  0.147 ± 0.0142 #>  3     1        0              3        0          2  0.180 ± 0.0159 #>  4     1        0              4        0          1  0.184 ± 0.0150 #>  5     1        0              5        1          1  0.143 ± 0.0144 #>  6     1        0              6        1          2  0.099 ± 0.0099 #>  7     1        0              7        1          3  0.040 ± 0.0051 #>  8     1        0              8        1          4  0.019 ± 0.0039 #>  9     1        1              1        0          4  0.025 ± 0.0045 #> 10     1        1              2        0          3  0.043 ± 0.0057 #> 11     1        1              3        0          2  0.088 ± 0.0087 #> 12     1        1              4        0          1  0.155 ± 0.0149 #> 13     1        1              5        1          1  0.171 ± 0.0131 #> 14     1        1              6        1          2  0.208 ± 0.0145 #> 15     1        1              7        1          3  0.153 ± 0.0139 #> 16     1        1              8        1          4  0.158 ± 0.0152"},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit the meta-d' model using brms package — fit_metad","title":"Fit the meta-d' model using brms package — fit_metad","text":"function wrapper around brms::brm() using custom family meta-d' model.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit the meta-d' model using brms package — fit_metad","text":"","code":"fit_metad(   formula,   data,   ...,   aggregate = TRUE,   .stimulus = \"stimulus\",   .response = \"response\",   .confidence = \"confidence\",   .joint_response = \"joint_response\",   K = NULL,   distribution = \"normal\",   metac_absolute = TRUE,   stanvars = NULL,   categorical = FALSE )"},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit the meta-d' model using brms package — fit_metad","text":"formula model formula parameters metad brms family. display parameter names model K confidence levels, use metad(K). data tibble containing data fit model. aggregate==TRUE, data one row per observation columns stimulus, response, confidence, variables formula aggregate==FALSE, aggregated one row per cell design matrix, joint type 1/type 2 response counts matrix column (see aggregate_metad()). ... Additional parameters passed brm function. aggregate TRUE, automatically aggregate data variables included formula using aggregate_metad(). Otherwise, data already aggregated. .stimulus name \"stimulus\" column .response name \"response\" column .confidence name \"confidence\" column .joint_response name \"joint_response\" column K number confidence levels. default, estimated data. distribution noise distribution use signal detection model. default, uses normal distribution mean parameterized dprime. metac_absolute TRUE, fix type 2 criterion equal type 1 criterion. Otherwise, equate criteria relatively metac/metadprime = c/dprime. stanvars Additional stanvars pass model code, example define alternative distribution custom model prior (see brms::stanvar()). categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit the meta-d' model using brms package — fit_metad","text":"brmsfit object containing fitted model","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit the meta-d' model using brms package — fit_metad","text":"fit_metad(formula, data, ...) approximately brm(formula, data=aggregate_metad(data, ...), family=metad(...), stanvars=stanvars_metad(...), ...). models, may often easier use explicit version using fit_metad.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/fit_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit the meta-d' model using brms package — fit_metad","text":"","code":"# check which parameters the model has metad(3) #>  #> Custom family: metad__3__normal__absolute__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2one1diff, metac2one2diff  #>   # fit a basic model on simulated data # (use `empty=true` to bypass fitting, *do not use in real analysis*) fit_metad(N ~ 1, sim_metad(), empty=TRUE) #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>  #> The model does not contain posterior draws.  if (FALSE) { # \\dontrun{   # fit a basic model on simulated data   fit_metad(N ~ 1, sim_metad())    # fit a model with condition-level effects   fit_metad(     bf(N ~ condition,        dprime + c + metac2zero1diff + metac2zero2diff +          metac2one1diff + metac2one1diff ~ condition),     data=sim_metad_condition()   ) } # }"},{"path":"https://metacoglab.github.io/hmetad/reference/hmetad-package.html","id":null,"dir":"Reference","previous_headings":"","what":"hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms' — hmetad-package","title":"hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms' — hmetad-package","text":"Implementation Bayesian regressions meta-d\\' model psychological data two alternative forced choice tasks ordinal confidence ratings. information, see Maniscalco & Lau (2012) doi:10.1016/j.concog.2011.09.021 . package front-end 'brms' package, facilitates wide range regression designs, well tools efficiently extracting posterior estimates, plotting, significance testing.","code":""},{"path":[]},{"path":"https://metacoglab.github.io/hmetad/reference/hmetad-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"hmetad: Fit the Meta-D' Model of Confidence Ratings Using 'brms' — hmetad-package","text":"Maintainer: Kevin O'Neill kevin.o'neill@ucl.ac.uk (ORCID) [copyright holder]","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"Given data frame meta-d' model, adds estimates model parameters. linpred_draws_metad add_linpred_draws_metad, parameters returned tidy tibble one row per posterior draw. linpred_rvars_metad add_linpred_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"","code":"linpred_draws_metad(object, newdata, ..., pivot_longer = FALSE)  add_linpred_draws_metad(newdata, object, ..., pivot_longer = FALSE)  linpred_rvars_metad(object, newdata, ..., pivot_longer = FALSE)  add_linpred_rvars_metad(newdata, object, pivot_longer = FALSE)"},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_linpred_draws tidybayes::add_linpred_rvars pivot_longer Return draws long format? TRUE, resulting data frame one row per posterior draw per model parameter FALSE (default), resulting data frame one row per posterior draw","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: linpred_draws_metad, identifiers posterior sample .variable, .value: pivot_longer=TRUE, .variable identifies different meta-d' model parameters .value stores posterior samples M, dprime, c, meta_dprime, meta_c, meta_c2_0_<k>, meta_c2_1_<k>: pivot_longer=FALSE, posterior samples meta-d' model parameters","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/linpred_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"","code":"if (FALSE) { # \\dontrun{   # running few iterations so example runs quickly, use more in practice   example_data <- sim_metad(N_trials=1000)   example_model <- fit_metad(N ~ 1, example_data, chains = 1, iter = 500) } # } example_model <- hmetad:::example_model newdata <- tidyr::tibble(.row = 1)  # obtain model parameters (wide format) linpred_draws_metad(example_model, newdata) #> # A tibble: 250 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime       c meta_dprime  meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>   <dbl>       <dbl>   <dbl> #>  1     1     NA         NA     1 1.07   1.03  -0.0303        1.11 -0.0303 #>  2     1     NA         NA     2 1.19   1.06  -0.0200        1.26 -0.0303 #>  3     1     NA         NA     3 1.29   0.928 -0.0623        1.20 -0.0303 #>  4     1     NA         NA     4 0.958  1.14   0.101         1.09 -0.0303 #>  5     1     NA         NA     5 1.08   1.05   0.126         1.14 -0.0303 #>  6     1     NA         NA     6 1.20   0.995  0.0572        1.20 -0.0303 #>  7     1     NA         NA     7 1.07   1.08  -0.0559        1.15 -0.0303 #>  8     1     NA         NA     8 1.12   0.984 -0.0592        1.10 -0.0303 #>  9     1     NA         NA     9 1.28   1.01  -0.0244        1.30 -0.0303 #> 10     1     NA         NA    10 1.21   0.900 -0.0106        1.09 -0.0303 #> # ℹ 240 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl> add_linpred_draws_metad(newdata, example_model) #> # A tibble: 250 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime       c meta_dprime  meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>   <dbl>       <dbl>   <dbl> #>  1     1     NA         NA     1 1.07   1.03  -0.0303        1.11 -0.0303 #>  2     1     NA         NA     2 1.19   1.06  -0.0200        1.26 -0.0303 #>  3     1     NA         NA     3 1.29   0.928 -0.0623        1.20 -0.0303 #>  4     1     NA         NA     4 0.958  1.14   0.101         1.09 -0.0303 #>  5     1     NA         NA     5 1.08   1.05   0.126         1.14 -0.0303 #>  6     1     NA         NA     6 1.20   0.995  0.0572        1.20 -0.0303 #>  7     1     NA         NA     7 1.07   1.08  -0.0559        1.15 -0.0303 #>  8     1     NA         NA     8 1.12   0.984 -0.0592        1.10 -0.0303 #>  9     1     NA         NA     9 1.28   1.01  -0.0244        1.30 -0.0303 #> 10     1     NA         NA    10 1.21   0.900 -0.0106        1.09 -0.0303 #> # ℹ 240 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl>  # obtain model parameters (long format) linpred_draws_metad(example_model, newdata, pivot_longer = TRUE) #> # A tibble: 2,750 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable    .value #>    <int>  <int>      <int> <int> <chr>         <dbl> #>  1     1     NA         NA     1 M            1.07   #>  2     1     NA         NA     1 dprime       1.03   #>  3     1     NA         NA     1 c           -0.0303 #>  4     1     NA         NA     1 meta_dprime  1.11   #>  5     1     NA         NA     1 meta_c      -0.0303 #>  6     1     NA         NA     1 meta_c2_0_1 -0.553  #>  7     1     NA         NA     1 meta_c2_0_2 -0.971  #>  8     1     NA         NA     1 meta_c2_0_3 -1.41   #>  9     1     NA         NA     1 meta_c2_1_1  0.477  #> 10     1     NA         NA     1 meta_c2_1_2  1.03   #> # ℹ 2,740 more rows add_linpred_draws_metad(newdata, example_model, pivot_longer = TRUE) #> # A tibble: 2,750 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable    .value #>    <int>  <int>      <int> <int> <chr>         <dbl> #>  1     1     NA         NA     1 M            1.07   #>  2     1     NA         NA     1 dprime       1.03   #>  3     1     NA         NA     1 c           -0.0303 #>  4     1     NA         NA     1 meta_dprime  1.11   #>  5     1     NA         NA     1 meta_c      -0.0303 #>  6     1     NA         NA     1 meta_c2_0_1 -0.553  #>  7     1     NA         NA     1 meta_c2_0_2 -0.971  #>  8     1     NA         NA     1 meta_c2_0_3 -1.41   #>  9     1     NA         NA     1 meta_c2_1_1  0.477  #> 10     1     NA         NA     1 meta_c2_1_2  1.03   #> # ℹ 2,740 more rows  # obtain model parameters (wide format, posterior::rvar) linpred_rvars_metad(example_model, newdata) #> # A tibble: 1 × 12 #> # Groups:   .row [1] #>    .row           M     dprime              c meta_dprime         meta_c #>   <dbl>  <rvar[1d]> <rvar[1d]>     <rvar[1d]>  <rvar[1d]>     <rvar[1d]> #> 1     1  1.1 ± 0.15  1 ± 0.082  0.013 ± 0.044  1.1 ± 0.12  0.013 ± 0.044 #> # ℹ 6 more variables: meta_c2_0_1 <rvar[1d]>, meta_c2_0_2 <rvar[1d]>, #> #   meta_c2_0_3 <rvar[1d]>, meta_c2_1_1 <rvar[1d]>, meta_c2_1_2 <rvar[1d]>, #> #   meta_c2_1_3 <rvar[1d]> add_linpred_rvars_metad(newdata, example_model) #> # A tibble: 1 × 12 #> # Groups:   .row [1] #>    .row           M     dprime              c meta_dprime         meta_c #>   <dbl>  <rvar[1d]> <rvar[1d]>     <rvar[1d]>  <rvar[1d]>     <rvar[1d]> #> 1     1  1.1 ± 0.15  1 ± 0.082  0.013 ± 0.044  1.1 ± 0.12  0.013 ± 0.044 #> # ℹ 6 more variables: meta_c2_0_1 <rvar[1d]>, meta_c2_0_2 <rvar[1d]>, #> #   meta_c2_0_3 <rvar[1d]>, meta_c2_1_1 <rvar[1d]>, meta_c2_1_2 <rvar[1d]>, #> #   meta_c2_1_3 <rvar[1d]>  # obtain model parameters (long format, posterior::rvar) linpred_rvars_metad(example_model, newdata, pivot_longer = TRUE) #> # A tibble: 11 × 3 #> # Groups:   .row, .variable [11] #>     .row .variable            .value #>    <dbl> <chr>            <rvar[1d]> #>  1     1 M             1.119 ± 0.147 #>  2     1 dprime        1.020 ± 0.082 #>  3     1 c             0.013 ± 0.044 #>  4     1 meta_dprime   1.134 ± 0.122 #>  5     1 meta_c        0.013 ± 0.044 #>  6     1 meta_c2_0_1  -0.492 ± 0.045 #>  7     1 meta_c2_0_2  -0.967 ± 0.048 #>  8     1 meta_c2_0_3  -1.433 ± 0.059 #>  9     1 meta_c2_1_1   0.481 ± 0.045 #> 10     1 meta_c2_1_2   1.036 ± 0.049 #> 11     1 meta_c2_1_3   1.551 ± 0.064 add_linpred_rvars_metad(newdata, example_model, pivot_longer = TRUE) #> # A tibble: 11 × 3 #> # Groups:   .row, .variable [11] #>     .row .variable            .value #>    <dbl> <chr>            <rvar[1d]> #>  1     1 M             1.119 ± 0.147 #>  2     1 dprime        1.020 ± 0.082 #>  3     1 c             0.013 ± 0.044 #>  4     1 meta_dprime   1.134 ± 0.122 #>  5     1 meta_c        0.013 ± 0.044 #>  6     1 meta_c2_0_1  -0.492 ± 0.045 #>  7     1 meta_c2_0_2  -0.967 ± 0.048 #>  8     1 meta_c2_0_3  -1.433 ± 0.059 #>  9     1 meta_c2_1_1   0.481 ± 0.045 #> 10     1 meta_c2_1_2   1.036 ± 0.049 #> 11     1 meta_c2_1_3   1.551 ± 0.064"},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of mean confidence — mean_confidence_draws","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"Computes posterior mean confidence conditional stimulus response (\\(\\mathbb{E}[C \\;\\vert\\; S=s,R=r]\\)), stimulus (averaging responses, \\(\\mathbb{E}[C \\;\\vert\\; S=s]\\)), response (averaging stimuli, \\(\\mathbb{E}[C \\;\\vert\\; R=r]\\)), neither (averaging stimuli responses, \\(\\mathbb{E}[C]\\)). mean_confidence_draws add_mean_confidence_draws, estimates returned tidy tibble one row per posterior draw, stimulus, response. mean_confidence_rvars add_mean_confidence_rvars, estimates returned posterior::rvars, one row per row newdata. add_mean_confidence_draws alias mean_confidence_draws argument order swapped.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"","code":"mean_confidence_draws(   object,   newdata,   ...,   by_stimulus = TRUE,   by_response = TRUE )  add_mean_confidence_draws(newdata, object, ...)  mean_confidence_rvars(   object,   newdata,   ...,   by_stimulus = TRUE,   by_response = TRUE )  add_mean_confidence_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments tidybayes::epred_draws tidybayes::epred_rvars by_stimulus TRUE, predict mean confidence separately stimulus. Otherwise, predict mean confidence averaging stimuli. by_response TRUE, predict mean confidence separately response Otherwise, predict mean confidence averaging responses.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"tibble containing posterior draws mean confidence following columns: .row: row newdata .chain, .iteration, .draw: mean_confidence_draws add_mean_confidence_draws, identifiers posterior sample stimulus: indicator stimulus presence (by_stimulus==TRUE) response: indicator type 1 response (by_response==TRUE) .epred: predicted mean confidence","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/mean_conf_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"","code":"if (FALSE) { # \\dontrun{   # running few iterations so example runs quickly, use more in practice   example_data <- sim_metad(N_trials=1000)   example_model <- fit_metad(N ~ 1, example_data, chains = 1, iter = 500) } # } example_model <- hmetad:::example_model newdata <- tidyr::tibble(.row = 1)  # compute mean confidence by stimulus and response mean_confidence_draws(example_model, newdata) #> # A tibble: 1,000 × 7 #> # Groups:   .row, stimulus, response [4] #>     .row .chain .iteration .draw stimulus response .epred #>    <int>  <int>      <int> <int>    <int>    <int>  <dbl> #>  1     1     NA         NA     1        0        0   2.48 #>  2     1     NA         NA     1        0        1   1.75 #>  3     1     NA         NA     1        1        0   1.80 #>  4     1     NA         NA     1        1        1   2.39 #>  5     1     NA         NA     2        0        0   2.56 #>  6     1     NA         NA     2        0        1   1.70 #>  7     1     NA         NA     2        1        0   1.80 #>  8     1     NA         NA     2        1        1   2.41 #>  9     1     NA         NA     3        0        0   2.45 #> 10     1     NA         NA     3        0        1   1.78 #> # ℹ 990 more rows add_mean_confidence_draws(newdata, example_model) #> # A tibble: 1,000 × 7 #> # Groups:   .row, stimulus, response [4] #>     .row .chain .iteration .draw stimulus response .epred #>    <int>  <int>      <int> <int>    <int>    <int>  <dbl> #>  1     1     NA         NA     1        0        0   2.48 #>  2     1     NA         NA     1        0        1   1.75 #>  3     1     NA         NA     1        1        0   1.80 #>  4     1     NA         NA     1        1        1   2.39 #>  5     1     NA         NA     2        0        0   2.56 #>  6     1     NA         NA     2        0        1   1.70 #>  7     1     NA         NA     2        1        0   1.80 #>  8     1     NA         NA     2        1        1   2.41 #>  9     1     NA         NA     3        0        0   2.45 #> 10     1     NA         NA     3        0        1   1.78 #> # ℹ 990 more rows  # compute mean confidence by stimulus mean_confidence_draws(example_model, newdata, by_response = FALSE) #> # A tibble: 500 × 6 #> # Groups:   .row, stimulus [2] #>     .row .chain .iteration .draw stimulus .epred #>    <int>  <int>      <int> <int>    <int>  <dbl> #>  1     1     NA         NA     1        0   2.25 #>  2     1     NA         NA     1        1   2.22 #>  3     1     NA         NA     2        0   2.30 #>  4     1     NA         NA     2        1   2.23 #>  5     1     NA         NA     3        0   2.22 #>  6     1     NA         NA     3        1   2.27 #>  7     1     NA         NA     4        0   2.27 #>  8     1     NA         NA     4        1   2.27 #>  9     1     NA         NA     5        0   2.31 #> 10     1     NA         NA     5        1   2.17 #> # ℹ 490 more rows  # compute mean confidence by response mean_confidence_draws(example_model, newdata, by_stimulus = FALSE) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row .chain .iteration .draw response .epred #>    <int>  <int>      <int> <int>    <int>  <dbl> #>  1     1     NA         NA     1        0   2.27 #>  2     1     NA         NA     1        1   2.20 #>  3     1     NA         NA     2        0   2.33 #>  4     1     NA         NA     2        1   2.19 #>  5     1     NA         NA     3        0   2.23 #>  6     1     NA         NA     3        1   2.26 #>  7     1     NA         NA     4        0   2.19 #>  8     1     NA         NA     4        1   2.36 #>  9     1     NA         NA     5        0   2.28 #> 10     1     NA         NA     5        1   2.19 #> # ℹ 490 more rows  # compute mean confidence averaging over stimuli and responses mean_confidence_draws(example_model, newdata, by_stimulus = FALSE, by_response = FALSE) #> # A tibble: 250 × 5 #> # Groups:   .row [1] #>     .row .chain .iteration .draw .epred #>    <int>  <int>      <int> <int>  <dbl> #>  1     1     NA         NA     1   2.23 #>  2     1     NA         NA     2   2.26 #>  3     1     NA         NA     3   2.25 #>  4     1     NA         NA     4   2.27 #>  5     1     NA         NA     5   2.24 #>  6     1     NA         NA     6   2.26 #>  7     1     NA         NA     7   2.26 #>  8     1     NA         NA     8   2.23 #>  9     1     NA         NA     9   2.25 #> 10     1     NA         NA    10   2.20 #> # ℹ 240 more rows  # use posterior::rvar for increased efficiency mean_confidence_rvars(example_model, newdata) #> # A tibble: 4 × 4 #> # Groups:   .row, stimulus, response [4] #>    .row stimulus response       .epred #>   <int>    <int>    <int>   <rvar[1d]> #> 1     1        0        0  2.5 ± 0.057 #> 2     1        0        1  1.8 ± 0.062 #> 3     1        1        0  1.8 ± 0.062 #> 4     1        1        1  2.4 ± 0.052"},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":null,"dir":"Reference","previous_headings":"","what":"brms family for the metad' model — metad","title":"brms family for the metad' model — metad","text":"brms family metad' model","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"brms family for the metad' model — metad","text":"","code":"metad(K, distribution = \"normal\", metac_absolute = TRUE, categorical = FALSE)"},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"brms family for the metad' model — metad","text":"K number confidence levels distribution noise distribution use signal detection model metac_absolute TRUE, fix type 2 criterion equal type 1 criterion. Otherwise, equate criteria relatively $$\\frac{\\textrm{meta-}c}{\\textrm{meta-}d'} = \\frac{c}{d'}$$ categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"brms family for the metad' model — metad","text":"brms family metad' model \\(K\\) confidence levels","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"brms family for the metad' model — metad","text":"","code":"# create a family using the normal distribution and 3 levels of confidence metad(3) #>  #> Custom family: metad__3__normal__absolute__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2one1diff, metac2one2diff  #>   # create a family with meta_c = M * c metad(3, metac_absolute = FALSE) #>  #> Custom family: metad__3__normal__relative__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2one1diff, metac2one2diff  #>   # create a family with an alternative distribution # note: cumulative distribution functions must be defined # in R and in Stan using [brms::stanvar()] metad(4, distribution = \"gumbel_min\") #>  #> Custom family: metad__4__gumbel_min__absolute__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2zero3diff, metac2one1diff, metac2one2diff, metac2one3diff  #>"},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"Generate (log) probability simplex joint type 1/type 2 responses","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"","code":"metad_pmf(   stimulus,   dprime,   c,   meta_dprime,   meta_c,   meta_c2_0,   meta_c2_1,   lcdf = normal_lcdf,   lccdf = normal_lccdf,   log = FALSE )"},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"stimulus stimulus (0 1) dprime type 1 sensitivity c type 1 response criterion meta_dprime type 2 sensitivity meta_c type 1 criteriom generating confidence ratings meta_c2_0 type 2 response criteria \"0\" responses, indexed increasing confidence levels meta_c2_1 type 2 response criteria \"1\" responses, indexed increasing confidence levels lcdf log cumulative distribution function underlying distribution metad' model. default, uses normal distribution standard deviation 1. lccdf log complement cumulative distribution function underlying distribution metad' model. default, uses normal distribution standard deviation 1. log TRUE, return log probabilities instead probabilities","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"probability simplex $$\\begin{bmatrix} P(R=0, C=K \\vert S=0), \\ldots, P(R=0, C=1 \\vert S=0), P(R=0, C=1 \\vert S=1), \\ldots, P(R=1, C=1 \\vert S=1)\\end{bmatrix}$$ response \\(R\\) confidence \\(C\\) given stimulus \\(S\\), defined meta-d' model.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/metad_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"","code":"metad_pmf(   stimulus = 0, dprime = 2, c = .5, meta_dprime = 1, meta_c = .5,   meta_c2_0 = c(0, -.5), meta_c2_1 = c(1, 1.5) ) #> [1] 0.554584077 0.212364065 0.166244657 0.038675753 0.018551730 0.009579718"},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal cumulative distribution functions — normal_lcdf","title":"Normal cumulative distribution functions — normal_lcdf","text":"Normal cumulative distribution functions","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal cumulative distribution functions — normal_lcdf","text":"","code":"normal_lcdf(x, mu)  normal_lccdf(x, mu)"},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal cumulative distribution functions — normal_lcdf","text":"x quantile evaluate l(c)cdf mu mean normal distribution","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal cumulative distribution functions — normal_lcdf","text":"\\(log(P(X < x))\\) (normal_lcdf) \\(log(P(X > x))\\) (normal_lccdf) \\(X\\) sampled normal distribution mean mu standard deviation \\(1\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/normal_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal cumulative distribution functions — normal_lcdf","text":"","code":"normal_lcdf(0, mu = 1) #> [1] -1.841022 normal_lccdf(0, mu = 1) #> [1] -0.1727538"},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior predictions of joint responses — predicted_draws_metad","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"Given data frame meta-d' model, adds predictions joint type 1 type 2 responses predicted_draws_metad add_predicted_draws_metad, predictions returned tidy tibble one row per posterior draw. predicted_rvars_metad add_predicted_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"","code":"predicted_draws_metad(object, newdata, ...)  add_predicted_draws_metad(newdata, object, ...)  predicted_rvars_metad(object, newdata, ...)  add_predicted_rvars_metad(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_predicted_draws tidybayes::add_predicted_rvars","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: predicted_draws_metad, identifiers posterior sample stimulus, joint_response, response, confidence: identifiers response type .prediction: predicted type 1 type 2 responses given stimulus","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/predicted_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"","code":"if (FALSE) { # \\dontrun{   # running few iterations so example runs quickly, use more in practice   example_data <- sim_metad(N_trials=1000)   example_model <- fit_metad(N ~ 1, example_data, chains = 1, iter = 500) } # } example_data <- hmetad:::example_data example_model <- hmetad:::example_model   # obtain model predictions predicted_draws_metad(example_model, aggregate_metad(example_data)) add_predicted_draws_metad(aggregate_metad(example_data), example_model)  # obtain model predictions (posterior::rvar) predicted_rvars_metad(example_model, aggregate_metad(example_data)) #> # A tibble: 16 × 9 #> # Groups:   .row, N_0, N_1, N, stimulus, joint_response, response, confidence #> #   [16] #>     .row   N_0   N_1 N[,\"N_0_1\"] stimulus joint_response response confidence #>    <int> <int> <int>       <int>    <int>          <int>    <int>      <dbl> #>  1     1   500   500          89        0              1        0          4 #>  2     1   500   500          89        0              2        0          3 #>  3     1   500   500          89        0              3        0          2 #>  4     1   500   500          89        0              4        0          1 #>  5     1   500   500          89        0              5        1          1 #>  6     1   500   500          89        0              6        1          2 #>  7     1   500   500          89        0              7        1          3 #>  8     1   500   500          89        0              8        1          4 #>  9     1   500   500          89        1              1        0          4 #> 10     1   500   500          89        1              2        0          3 #> 11     1   500   500          89        1              3        0          2 #> 12     1   500   500          89        1              4        0          1 #> 13     1   500   500          89        1              5        1          1 #> 14     1   500   500          89        1              6        1          2 #> 15     1   500   500          89        1              7        1          3 #> 16     1   500   500          89        1              8        1          4 #> # ℹ 2 more variables: N[2:16] <int>, .prediction <rvar[1d]> add_predicted_rvars_metad(aggregate_metad(example_data), example_model) #> # A tibble: 16 × 9 #> # Groups:   .row, N_0, N_1, N, stimulus, joint_response, response, confidence #> #   [16] #>     .row   N_0   N_1 N[,\"N_0_1\"] stimulus joint_response response confidence #>    <int> <int> <int>       <int>    <int>          <int>    <int>      <dbl> #>  1     1   500   500          89        0              1        0          4 #>  2     1   500   500          89        0              2        0          3 #>  3     1   500   500          89        0              3        0          2 #>  4     1   500   500          89        0              4        0          1 #>  5     1   500   500          89        0              5        1          1 #>  6     1   500   500          89        0              6        1          2 #>  7     1   500   500          89        0              7        1          3 #>  8     1   500   500          89        0              8        1          4 #>  9     1   500   500          89        1              1        0          4 #> 10     1   500   500          89        1              2        0          3 #> 11     1   500   500          89        1              3        0          2 #> 12     1   500   500          89        1              4        0          1 #> 13     1   500   500          89        1              5        1          1 #> 14     1   500   500          89        1              6        1          2 #> 15     1   500   500          89        1              7        1          3 #> 16     1   500   500          89        1              8        1          4 #> # ℹ 2 more variables: N[2:16] <int>, .prediction <rvar[1d]>"},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute joint response probabilities from aggregated counts — response_probabilities","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"Compute joint response probabilities aggregated counts","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"","code":"response_probabilities(counts)"},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"counts vector (matrix) counts joint type 1/type 2 responses provided aggregate_metad","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"vector (matrix) response probabilities \\(P(R, C \\;\\vert\\; S)\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"response \\(R\\), confidence \\(C\\), stimulus \\(S\\), number confidence levels \\(K\\), counts vector (matrix rows) form: $$  [N_{S=0, R=0, C=K}, \\ldots, N_{S=0, R=0, C=1}, \\\\  N_{S=0, R=1, C=1}, \\ldots, N_{S=0, R=1, C=K}, \\\\  N_{S=1, R=0, C=K}, \\ldots, N_{S=1, R=0, C=1}, \\\\  N_{S=1, R=1, C=1}, \\ldots, N_{S=1, R=1, C=K}] \\\\ $$ Returns vector (matrix rows) form: $$ [P(R=0, C=K \\;\\vert\\; S=0), ..., P(R=0, C=1 \\;\\vert\\; S=0), \\\\  P(R=1, C=1 \\;\\vert\\; S=0), ..., P(R=1, C=K \\;\\vert\\; S=0), \\\\  P(R=0, C=K \\;\\vert\\; S=1), ..., P(R=0, C=1 \\;\\vert\\; S=1), \\\\  P(R=1, C=1 \\;\\vert\\; S=1), ..., P(R=1, C=K \\;\\vert\\; S=1)] $$","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/response_probabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"","code":"# Aggregate responses from simulated data d <- sim_metad() |> aggregate_metad()  # Compute conditional response probabilities response_probabilities(d$N) #>      N_0_1 N_0_2 N_0_3 N_0_4 N_0_5 N_0_6 N_0_7 N_0_8 N_1_1 N_1_2 N_1_3 N_1_4 #> [1,]  0.08  0.24  0.12  0.36   0.1  0.08     0  0.02     0  0.04  0.06  0.22 #>      N_1_5 N_1_6 N_1_7 N_1_8 #> [1,]  0.24   0.2  0.08  0.16  # Also works on matrices matrix(rep(1, 16), nrow = 2) |> response_probabilities() #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #> [1,] 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 #> [2,] 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25"},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between separate and joint type 1/type 2 responses — joint_response","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"Confidence ratings decisions collected one two ways. separate ratings, type 1 response (\\(R \\\\{0, 1\\}\\)) type 2 response (\\(C \\[1, K]\\)). joint ratings, instead combined type 1/type 2 response (\\(J \\[1, 2K]\\)), values \\([1, K]\\) indicating type 1 response \\(0\\) values \\([K+1, 2K]\\) indicating type 1 response \\(1\\), confident responses ends scale. joint_response converts separate type 1 type 2 responses joint format type1_response type2_response convert joint response separate responses.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"","code":"joint_response(response, confidence, K)  type1_response(joint_response, K)  type2_response(joint_response, K)"},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"response type 1 response (0 1) confidence type 2 response/confidence rating (1:K) K number confidence levels joint_response joint type 1/type 2 response","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"joint response (joint_response), type 1 response (type1_response), type 2 response (type2_response)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/responses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"","code":"# convert joint_response to separate responses joint <- 1:8 K <- 4 type1_response(joint, K) #> [1] 0 0 0 0 1 1 1 1 type2_response(joint, K) #> [1] 4 3 2 1 1 2 3 4  # convert separate responses to a joint response t1 <- rep(c(0, 1), each = 4) t2 <- c(4:1, 1:4) joint_response(t1, t2, K) #> [1] 1 2 3 4 5 6 7 8"},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a matrix-normal distribution — rmatrixnorm","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"Sample matrix-normal distribution","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"","code":"rmatrixnorm(mu, L_sigma_rows, L_sigma_cols)"},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"mu matrix means L_sigma_rows Cholesky-decomposed covariance matrix rows L_sigma_cols Cholesky-decomposed covariance matrix columns","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"single sample matrix-normal distribution mean mu (matrix), row-wise covariances sigma_rows, column-wise covariances sigma_cols, L_sigma_rows L_sigma_cols Cholesky-decomposed covariance matrices","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/rmatrixnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"","code":"mu <- matrix(rep(0, 8), nrow = 4) sd_rows <- rep(1, 4) sd_cols <- rep(1, 2) r_rows <- cor_matrix(.25, 4) r_cols <- cor_matrix(.75, 2) L_sigma_rows <- chol(cov_matrix(sd_rows, r_rows)) L_sigma_cols <- chol(cov_matrix(sd_cols, r_cols)) rmatrixnorm(mu, L_sigma_rows, L_sigma_cols) #>           [,1]      [,2] #> [1,] 0.9552839 1.3966967 #> [2,] 0.5366211 0.8307115 #> [3,] 2.0308863 1.2952785 #> [4,] 1.2145352 1.5980098"},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"Given data frame meta-d' model, adds estimates cumulative probability joint_responses. roc1_draws add_roc1_draws, estimates returned tidy tibble one row per posterior draw per joint response. roc1_rvars add_roc1_rvars, parameters returned posterior::rvars, one row per row newdata per joint response.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"","code":"roc1_draws(object, newdata, ..., bounds = FALSE)  add_roc1_draws(newdata, object, ...)  roc1_rvars(object, newdata, ..., bounds = FALSE)  add_roc1_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws tidybayes::epred_rvars bounds TRUE, include endpoints ROC \\((0, 0)\\) \\((1, 1)\\). Otherwise, endpoints excluded.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"tibble containing posterior draws pseudo type 1 ROC following columns: .row: row newdata .chain, .iteration, .draw: roc1_draws add_roc1_draws, identifiers posterior sample joint_response: combined type 1 / type 2 response (\\(J \\[1, 2K]\\)) \\(K\\) confidence levels) response: type 1 response perceived stimulus presence (\\(R \\\\{0, 1\\}\\)) confidence: type 2 confidence response (\\(C \\[1, K]\\)) p_fa: cumulative probability 'present'/'old' response stimulus==0 (\\(P(J \\ge j \\;\\vert\\; S=0)\\)) p_hit: cumulative probability 'present'/'old' response stimulus==1 (\\(P(J \\ge j \\;\\vert\\; S=1)\\))","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc1_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"","code":"if (FALSE) { # \\dontrun{   # running few iterations so example runs quickly, use more in practice   example_data <- sim_metad(N_trials=1000)   example_model <- fit_metad(N ~ 1, example_data, chains = 1, iter = 500) } # } example_model <- hmetad:::example_model newdata <- tidyr::tibble(.row = 1)  # compute pseudo-type 1 ROC curve roc1_draws(example_model, newdata) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.809 0.974 #>  2     1              1        0          4     NA         NA     2 0.791 0.976 #>  3     1              1        0          4     NA         NA     3 0.829 0.979 #>  4     1              1        0          4     NA         NA     4 0.826 0.980 #>  5     1              1        0          4     NA         NA     5 0.804 0.975 #>  6     1              1        0          4     NA         NA     6 0.815 0.978 #>  7     1              1        0          4     NA         NA     7 0.817 0.978 #>  8     1              1        0          4     NA         NA     8 0.824 0.976 #>  9     1              1        0          4     NA         NA     9 0.816 0.981 #> 10     1              1        0          4     NA         NA    10 0.828 0.975 #> # ℹ 1,740 more rows add_roc1_draws(newdata, example_model) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.809 0.974 #>  2     1              1        0          4     NA         NA     2 0.791 0.976 #>  3     1              1        0          4     NA         NA     3 0.829 0.979 #>  4     1              1        0          4     NA         NA     4 0.826 0.980 #>  5     1              1        0          4     NA         NA     5 0.804 0.975 #>  6     1              1        0          4     NA         NA     6 0.815 0.978 #>  7     1              1        0          4     NA         NA     7 0.817 0.978 #>  8     1              1        0          4     NA         NA     8 0.824 0.976 #>  9     1              1        0          4     NA         NA     9 0.816 0.981 #> 10     1              1        0          4     NA         NA    10 0.828 0.975 #> # ℹ 1,740 more rows  # use posterior::rvar for additional efficiency roc1_rvars(example_model, newdata) #> # A tibble: 7 × 6 #> # Groups:   .row, joint_response, response, confidence [7] #>    .row joint_response response confidence            p_fa          p_hit #>   <int>          <int>    <int>      <dbl>      <rvar[1d]>     <rvar[1d]> #> 1     1              1        0          4  0.812 ± 0.0169  0.98 ± 0.0045 #> 2     1              2        0          3  0.665 ± 0.0194  0.93 ± 0.0085 #> 3     1              3        0          2  0.485 ± 0.0219  0.85 ± 0.0135 #> 4     1              4        0          1  0.301 ± 0.0215  0.69 ± 0.0202 #> 5     1              5        1          1  0.158 ± 0.0142  0.52 ± 0.0212 #> 6     1              6        1          2  0.059 ± 0.0078  0.31 ± 0.0188 #> 7     1              7        1          3  0.019 ± 0.0039  0.16 ± 0.0152 add_roc1_draws(newdata, example_model) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.809 0.974 #>  2     1              1        0          4     NA         NA     2 0.791 0.976 #>  3     1              1        0          4     NA         NA     3 0.829 0.979 #>  4     1              1        0          4     NA         NA     4 0.826 0.980 #>  5     1              1        0          4     NA         NA     5 0.804 0.975 #>  6     1              1        0          4     NA         NA     6 0.815 0.978 #>  7     1              1        0          4     NA         NA     7 0.817 0.978 #>  8     1              1        0          4     NA         NA     8 0.824 0.976 #>  9     1              1        0          4     NA         NA     9 0.816 0.981 #> 10     1              1        0          4     NA         NA    10 0.828 0.975 #> # ℹ 1,740 more rows  # include the ROC bounds roc1_draws(example_model, newdata, bounds = TRUE) #> # A tibble: 2,250 × 9 #> # Groups:   .row, joint_response, response, confidence [9] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <dbl>    <dbl>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              0        0          5     NA         NA     1     1     1 #>  2     1              0        0          5     NA         NA     2     1     1 #>  3     1              0        0          5     NA         NA     3     1     1 #>  4     1              0        0          5     NA         NA     4     1     1 #>  5     1              0        0          5     NA         NA     5     1     1 #>  6     1              0        0          5     NA         NA     6     1     1 #>  7     1              0        0          5     NA         NA     7     1     1 #>  8     1              0        0          5     NA         NA     8     1     1 #>  9     1              0        0          5     NA         NA     9     1     1 #> 10     1              0        0          5     NA         NA    10     1     1 #> # ℹ 2,240 more rows"},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"Given data frame meta-d' model, adds estimates cumulative probability confidence type 1 response. roc2_draws add_roc2_draws, estimates returned tidy tibble one row per posterior draw per joint response. roc2_rvars add_roc2_rvars, parameters returned posterior::rvars, one row per row newdata per joint response.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"","code":"roc2_draws(object, newdata, ..., bounds = FALSE)  add_roc2_draws(newdata, object, ...)  roc2_rvars(object, newdata, ..., bounds = FALSE)  add_roc2_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws bounds TRUE, include endpoints ROC \\((0, 0)\\) \\((1, 1)\\). Otherwise, endpoints excluded.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"tibble containing posterior draws pseudo type 1 ROC following columns: .row: row newdata .chain, .iteration, .draw: roc2_draws add_roc2_draws, identifiers posterior sample response: type 1 response perceived stimulus presence (\\(R \\\\{0, 1\\}\\)) confidence: type 2 confidence response (\\(C \\[1, K]\\)) p_fa2: cumulative probability incorrect response (\\(P(C\\ge c \\;\\vert\\; R\\ne S)\\)) p_hit2: cumulative probability correct response (\\(P(C\\ge c \\;\\vert\\; R = S)\\))","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/roc2_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"","code":"if (FALSE) { # \\dontrun{   # running few iterations so example runs quickly, use more in practice   example_data <- sim_metad(N_trials=1000)   example_model <- fit_metad(N ~ 1, example_data, chains = 1, iter = 500) } # } example_model <- hmetad:::example_model newdata <- tidyr::tibble(.row = 1)  # compute type 2 ROC curve roc2_draws(example_model, newdata) #> # A tibble: 1,500 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.279 0.0877 #>  2     1        0          4     NA         NA     2  0.302 0.0820 #>  3     1        0          4     NA         NA     3  0.261 0.0706 #>  4     1        0          4     NA         NA     4  0.233 0.0639 #>  5     1        0          4     NA         NA     5  0.264 0.0722 #>  6     1        0          4     NA         NA     6  0.260 0.0664 #>  7     1        0          4     NA         NA     7  0.267 0.0781 #>  8     1        0          4     NA         NA     8  0.264 0.0822 #>  9     1        0          4     NA         NA     9  0.268 0.0627 #> 10     1        0          4     NA         NA    10  0.256 0.0777 #> # ℹ 1,490 more rows add_roc2_draws(newdata, example_model) #> # A tibble: 1,500 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.279 0.0877 #>  2     1        0          4     NA         NA     2  0.302 0.0820 #>  3     1        0          4     NA         NA     3  0.261 0.0706 #>  4     1        0          4     NA         NA     4  0.233 0.0639 #>  5     1        0          4     NA         NA     5  0.264 0.0722 #>  6     1        0          4     NA         NA     6  0.260 0.0664 #>  7     1        0          4     NA         NA     7  0.267 0.0781 #>  8     1        0          4     NA         NA     8  0.264 0.0822 #>  9     1        0          4     NA         NA     9  0.268 0.0627 #> 10     1        0          4     NA         NA    10  0.256 0.0777 #> # ℹ 1,490 more rows  # use posterior::rvar for additional efficiency roc2_rvars(example_model, newdata) #> # A tibble: 6 × 5 #> # Groups:   .row, response, confidence [6] #>    .row response confidence        p_hit2          p_fa2 #>   <int>    <int>      <dbl>    <rvar[1d]>     <rvar[1d]> #> 1     1        0          2  0.74 ± 0.020  0.500 ± 0.033 #> 2     1        0          3  0.48 ± 0.024  0.217 ± 0.024 #> 3     1        0          4  0.27 ± 0.023  0.080 ± 0.014 #> 4     1        1          1  0.75 ± 0.019  0.525 ± 0.032 #> 5     1        1          2  0.45 ± 0.023  0.195 ± 0.024 #> 6     1        1          3  0.23 ± 0.021  0.062 ± 0.013 add_roc2_rvars(newdata, example_model) #> # A tibble: 6 × 5 #> # Groups:   .row, response, confidence [6] #>    .row response confidence        p_hit2          p_fa2 #>   <int>    <int>      <dbl>    <rvar[1d]>     <rvar[1d]> #> 1     1        0          2  0.74 ± 0.020  0.500 ± 0.033 #> 2     1        0          3  0.48 ± 0.024  0.217 ± 0.024 #> 3     1        0          4  0.27 ± 0.023  0.080 ± 0.014 #> 4     1        1          1  0.75 ± 0.019  0.525 ± 0.032 #> 5     1        1          2  0.45 ± 0.023  0.195 ± 0.024 #> 6     1        1          3  0.23 ± 0.021  0.062 ± 0.013  # include the ROC bounds roc2_draws(example_model, newdata, bounds = TRUE) #> # A tibble: 2,500 × 8 #> # Groups:   .row, response, confidence [10] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <dbl>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.279 0.0877 #>  2     1        0          4     NA         NA     2  0.302 0.0820 #>  3     1        0          4     NA         NA     3  0.261 0.0706 #>  4     1        0          4     NA         NA     4  0.233 0.0639 #>  5     1        0          4     NA         NA     5  0.264 0.0722 #>  6     1        0          4     NA         NA     6  0.260 0.0664 #>  7     1        0          4     NA         NA     7  0.267 0.0781 #>  8     1        0          4     NA         NA     8  0.264 0.0822 #>  9     1        0          4     NA         NA     9  0.268 0.0627 #> 10     1        0          4     NA         NA    10  0.256 0.0777 #> # ℹ 2,490 more rows"},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"to_signed(x) converts \\(x \\\\{0, 1\\}\\) \\(x' \\\\{-1, 1\\}\\) to_unsigned(x) converts \\(x \\\\{-1, 1\\}\\) \\(x' \\\\{0, 1\\}\\)","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"","code":"to_signed(x)  to_unsigned(x)"},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"x binary variable","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"signed (to_signed) unsigned (to_unsigned) version x","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/signed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"","code":"# should return `1` to_signed(0) #> [1] -1  # should return `1` to_signed(1) #> [1] 1  # should return `0` to_unsigned(-1) #> [1] 0  # should return `1` to_unsigned(1) #> [1] 1  # `to_signed` also works with objects `R` interprets as `0` or `1` to_signed(10) #> [1] 1  # `to_unsigned` also works with any signed integer to_unsigned(-10) #> [1] 0  if (FALSE) { # \\dontrun{   # neither function works with factors   to_unsigned(factor(1)) } # }"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the meta-d' model — sim_metad","title":"Simulate from the meta-d' model — sim_metad","text":"Generate simulated dataset meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the meta-d' model — sim_metad","text":"","code":"sim_metad(   N_trials = 100,   dprime = 1,   c = 0,   log_M = 0,   c2_0_diff = rep(0.5, 3),   c2_1_diff = rep(0.5, 3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the meta-d' model — sim_metad","text":"N_trials Total number trials simulate. Half trials stimulus=0 half stimulus=1. dprime sensitivity signal detection agent simulate c response bias signal detection agent simulate log_M metacognitive efficiency agent logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. c2_0_diff, c2_1_diff Distances confidence thresholds \"0\" \"1\" responses, meta_c2_0 = meta_c - cumsum(c2_0_diff) meta_c2_1 = meta_c + cumsum(c2_1_diff). metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf, lccdf log (complement) cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the meta-d' model — sim_metad","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the meta-d' model — sim_metad","text":"","code":"sim_metad(N_trials = 10) #> # A tibble: 10 × 14 #> # Groups:   stimulus, response, confidence [6] #>    trial stimulus response correct confidence dprime     c meta_dprime     M #>    <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> <dbl> #>  1     1        0        0       1          3      1     0           1     1 #>  2     2        0        0       1          3      1     0           1     1 #>  3     3        0        1       0          1      1     0           1     1 #>  4     4        0        1       0          3      1     0           1     1 #>  5     5        0        1       0          3      1     0           1     1 #>  6     1        1        0       0          2      1     0           1     1 #>  7     2        1        0       0          2      1     0           1     1 #>  8     3        1        1       1          1      1     0           1     1 #>  9     4        1        1       1          3      1     0           1     1 #> 10     5        1        1       1          3      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad(N_trials = 10000, summarize = TRUE) #> # A tibble: 16 × 14 #> # Groups:   stimulus [2] #>    stimulus response correct confidence     n dprime     c meta_dprime     M #>       <int>    <int>   <int>      <int> <int>  <dbl> <dbl>       <dbl> <dbl> #>  1        0        0       1          1   928      1     0           1     1 #>  2        0        0       1          2   987      1     0           1     1 #>  3        0        0       1          3   757      1     0           1     1 #>  4        0        0       1          4   763      1     0           1     1 #>  5        0        1       0          1   768      1     0           1     1 #>  6        0        1       0          2   474      1     0           1     1 #>  7        0        1       0          3   219      1     0           1     1 #>  8        0        1       0          4   104      1     0           1     1 #>  9        1        0       0          1   775      1     0           1     1 #> 10        1        0       0          2   472      1     0           1     1 #> 11        1        0       0          3   235      1     0           1     1 #> 12        1        0       0          4   103      1     0           1     1 #> 13        1        1       1          1   954      1     0           1     1 #> 14        1        1       1          2   968      1     0           1     1 #> 15        1        1       1          3   737      1     0           1     1 #> 16        1        1       1          4   756      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad(N_trials = 10, c2_0_diff = 1, c2_1_diff = 1) #> # A tibble: 10 × 14 #> # Groups:   stimulus, response, confidence [5] #>    trial stimulus response correct confidence dprime     c meta_dprime     M #>    <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> <dbl> #>  1     1        0        0       1          1      1     0           1     1 #>  2     2        0        0       1          2      1     0           1     1 #>  3     3        0        0       1          2      1     0           1     1 #>  4     4        0        1       0          1      1     0           1     1 #>  5     5        0        1       0          1      1     0           1     1 #>  6     1        1        0       0          2      1     0           1     1 #>  7     2        1        1       1          1      1     0           1     1 #>  8     3        1        1       1          1      1     0           1     1 #>  9     4        1        1       1          1      1     0           1     1 #> 10     5        1        1       1          1      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"Generate simulated dataset across separate conditions meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"","code":"sim_metad_condition(   N_trials = 100,   dprime = rep(1, 2),   c = rep(0, 2),   log_M = rep(0, 2),   c2_0_diff = list(rep(0.5, 3), rep(0.5, 3)),   c2_1_diff = list(rep(0.5, 3), rep(0.5, 3)),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"N_trials Total number trials simulate. Half trials stimulus=0 half stimulus=1. dprime sensitivity signal detection agent simulate c response bias signal detection agent simulate log_M metacognitive efficiency agent logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. c2_0_diff, c2_1_diff Distances confidence thresholds \"0\" \"1\" responses, meta_c2_0 = meta_c - cumsum(c2_0_diff) meta_c2_1 = meta_c + cumsum(c2_1_diff). metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf, lccdf log (complement) cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number condition: simulated condition number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"","code":"sim_metad_condition(N_trials = 10) #> # A tibble: 20 × 15 #>    condition trial stimulus response correct confidence dprime     c meta_dprime #>        <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> #>  1         1     1        0        0       1          1      1     0           1 #>  2         1     2        0        0       1          2      1     0           1 #>  3         1     3        0        0       1          3      1     0           1 #>  4         1     4        0        0       1          3      1     0           1 #>  5         1     5        0        1       0          1      1     0           1 #>  6         1     1        1        1       1          1      1     0           1 #>  7         1     2        1        1       1          1      1     0           1 #>  8         1     3        1        1       1          2      1     0           1 #>  9         1     4        1        1       1          2      1     0           1 #> 10         1     5        1        1       1          3      1     0           1 #> 11         2     1        0        0       1          1      1     0           1 #> 12         2     2        0        0       1          3      1     0           1 #> 13         2     3        0        0       1          3      1     0           1 #> 14         2     4        0        0       1          3      1     0           1 #> 15         2     5        0        1       0          1      1     0           1 #> 16         2     1        1        0       0          2      1     0           1 #> 17         2     2        1        1       1          1      1     0           1 #> 18         2     3        1        1       1          4      1     0           1 #> 19         2     4        1        1       1          4      1     0           1 #> 20         2     5        1        1       1          4      1     0           1 #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad_condition(N_trials = 10000, summarize = TRUE) #> # A tibble: 32 × 15 #>    condition stimulus response correct confidence     n dprime     c meta_dprime #>        <int>    <int>    <int>   <int>      <int> <int>  <dbl> <dbl>       <dbl> #>  1         1        0        0       1          1   935      1     0           1 #>  2         1        0        0       1          2   978      1     0           1 #>  3         1        0        0       1          3   748      1     0           1 #>  4         1        0        0       1          4   828      1     0           1 #>  5         1        0        1       0          1   771      1     0           1 #>  6         1        0        1       0          2   407      1     0           1 #>  7         1        0        1       0          3   218      1     0           1 #>  8         1        0        1       0          4   115      1     0           1 #>  9         1        1        0       0          1   732      1     0           1 #> 10         1        1        0       0          2   471      1     0           1 #> # ℹ 22 more rows #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad_condition(N_trials = 10, c2_0_diff = list(1, .5), c2_1_diff = list(1, .5)) #> # A tibble: 20 × 15 #>    condition trial stimulus response correct confidence dprime     c meta_dprime #>        <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> #>  1         1     1        0        0       1          2      1     0           1 #>  2         1     2        0        0       1          2      1     0           1 #>  3         1     3        0        0       1          2      1     0           1 #>  4         1     4        0        0       1          2      1     0           1 #>  5         1     5        0        1       0          1      1     0           1 #>  6         1     1        1        1       1          1      1     0           1 #>  7         1     2        1        1       1          2      1     0           1 #>  8         1     3        1        1       1          2      1     0           1 #>  9         1     4        1        1       1          2      1     0           1 #> 10         1     5        1        1       1          2      1     0           1 #> 11         2     1        0        0       1          2      1     0           1 #> 12         2     2        0        0       1          2      1     0           1 #> 13         2     3        0        0       1          2      1     0           1 #> 14         2     4        0        0       1          2      1     0           1 #> 15         2     5        0        1       0          1      1     0           1 #> 16         2     1        1        0       0          1      1     0           1 #> 17         2     2        1        0       0          2      1     0           1 #> 18         2     3        1        0       0          2      1     0           1 #> 19         2     4        1        0       0          2      1     0           1 #> 20         2     5        1        1       1          1      1     0           1 #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the hierarchical meta-d' model — sim_metad_participant","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"Generate simulated dataset across participants meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"","code":"sim_metad_participant(   N_participants = 100,   N_trials = 100,   mu_dprime = 1,   sd_dprime = 0.5,   mu_c = 0,   sd_c = 0.5,   mu_log_M = 0,   sd_log_M = 0.5,   mu_z_c2_0 = rep(-1, 3),   sd_z_c2_0 = rep(0.1, 3),   r_z_c2_0 = diag(3),   mu_z_c2_1 = rep(-1, 3),   sd_z_c2_1 = rep(0.1, 3),   r_z_c2_1 = diag(3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"N_trials, N_participants Total number participants trials simulate per participant. Half trials stimulus=0 half stimulus=1. mu_dprime, sd_dprime mean standard deviation sensitivities signal detection agents simulate mu_c, sd_c mean standard deviation response bias signal detection agents simulate mu_log_M, sd_log_M mean standard deviation metacognitive efficiency agents logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. mu_z_c2_0, mu_z_c2_1 Mean distance confidence thresholds \"0\" \"1\" responses log_scale, meta_c2_0 = meta_c - cumulative_sum(exp(z_c2_0)) meta_c2_1 = meta_c + cumulative_sum(exp(z_c2_1)). sd_z_c2_0, sd_z_c2_1 SD log distances confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0, r_z_c2_1 Correlation log distances confidence thresholds \"0\" \"1\" responses log_scale. metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf log cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution. lccdf log complement cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number participant: simulated participant number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"","code":"sim_metad_participant(N_participants = 10, N_trials = 10) #> # A tibble: 100 × 15 #>    participant trial stimulus response correct confidence dprime     c #>          <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl> #>  1           1     1        0        0       1          2  0.923 0.188 #>  2           1     2        0        0       1          4  0.923 0.188 #>  3           1     3        0        0       1          4  0.923 0.188 #>  4           1     4        0        0       1          4  0.923 0.188 #>  5           1     5        0        0       1          4  0.923 0.188 #>  6           1     1        1        0       0          2  0.923 0.188 #>  7           1     2        1        0       0          3  0.923 0.188 #>  8           1     3        1        1       1          2  0.923 0.188 #>  9           1     4        1        1       1          2  0.923 0.188 #> 10           1     5        1        1       1          4  0.923 0.188 #> # ℹ 90 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl> sim_metad_participant(mu_dprime = 2, mu_log_M = -1) #> # A tibble: 10,000 × 15 #>    participant trial stimulus response correct confidence dprime      c #>          <int> <int>    <int>    <int>   <int>      <int>  <dbl>  <dbl> #>  1           1     1        0        0       1          1   2.70 -0.271 #>  2           1     2        0        0       1          1   2.70 -0.271 #>  3           1     3        0        0       1          1   2.70 -0.271 #>  4           1     4        0        0       1          1   2.70 -0.271 #>  5           1     5        0        0       1          1   2.70 -0.271 #>  6           1     6        0        0       1          1   2.70 -0.271 #>  7           1     7        0        0       1          1   2.70 -0.271 #>  8           1     8        0        0       1          1   2.70 -0.271 #>  9           1     9        0        0       1          2   2.70 -0.271 #> 10           1    10        0        0       1          2   2.70 -0.271 #> # ℹ 9,990 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"Generate simulated dataset across participants conditions meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"","code":"sim_metad_participant_condition(   N_participants = 100,   N_trials = 100,   mu_dprime = rep(1, 2),   sd_dprime = rep(0.5, 2),   r_dprime = diag(2),   mu_c = rep(0, 2),   sd_c = rep(0.5, 2),   r_c = diag(2),   mu_log_M = rep(0, 2),   sd_log_M = rep(0.5, 2),   r_log_M = diag(2),   mu_z_c2_0 = matrix(rep(-1, 6), nrow = 3, ncol = 2),   sd_z_c2_0_condition = rep(0.1, 2),   r_z_c2_0_condition = diag(2),   sd_z_c2_0_confidence = rep(0.1, 3),   r_z_c2_0_confidence = diag(3),   mu_z_c2_1 = matrix(rep(-1, 6), nrow = 3, ncol = 2),   sd_z_c2_1_condition = rep(0.1, 2),   r_z_c2_1_condition = diag(2),   sd_z_c2_1_confidence = rep(0.1, 3),   r_z_c2_1_confidence = diag(3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"N_trials, N_participants Total number participants trials simulate per participant. Half trials stimulus=0 half stimulus=1. mu_dprime, sd_dprime, r_dprime mean, standard deviation, within-participant correlations sensitivities signal detection agents simulate mu_c, sd_c, r_c mean, standard deviation, within-participant correlations response bias signal detection agents simulate mu_log_M, sd_log_M, r_log_M mean, standard deviation, within-participant correlations metacognitive efficiency agents logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. mu_z_c2_0, mu_z_c2_1 Mean distance confidence thresholds \"0\" \"1\" responses log_scale, meta_c2_0 = meta_c - cumulative_sum(exp(z_c2_0)) meta_c2_1 = meta_c + cumulative_sum(exp(z_c2_1)). sd_z_c2_0_condition, sd_z_c2_1_condition SD log distances across conditions confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0_condition, r_z_c2_1_condition Correlation across conditions log distances confidence thresholds \"0\" \"1\" responses log_scale. sd_z_c2_0_confidence, sd_z_c2_1_confidence SD log distances across confidence levels confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0_confidence, r_z_c2_1_confidence Correlation across confidence levels log distances confidence thresholds \"0\" \"1\" responses log_scale. metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf log cumulative distribution function underlying signal distribution. default, uses normal(+/- dprime/2, 1) distribution. lccdf log complement cumulative distribution function underlying signal distribution. default, uses normal(+/- dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/sim_metad_participant_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"","code":"sim_metad_participant_condition(10, 10) #> # A tibble: 200 × 16 #>    participant condition trial stimulus response correct confidence dprime     c #>          <int>     <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl> #>  1           1         1     1        0        0       1          2   1.37 0.741 #>  2           1         1     2        0        0       1          3   1.37 0.741 #>  3           1         1     3        0        0       1          4   1.37 0.741 #>  4           1         1     4        0        0       1          4   1.37 0.741 #>  5           1         1     5        0        1       0          3   1.37 0.741 #>  6           1         1     1        1        0       0          2   1.37 0.741 #>  7           1         1     2        1        0       0          2   1.37 0.741 #>  8           1         1     3        1        0       0          3   1.37 0.741 #>  9           1         1     4        1        1       1          1   1.37 0.741 #> 10           1         1     5        1        1       1          1   1.37 0.741 #> # ℹ 190 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Stan code for the meta-d' model — stanvars_metad","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"Generate Stan code meta-d' model","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"","code":"stanvars_metad(   K,   distribution = \"normal\",   metac_absolute = TRUE,   categorical = FALSE )"},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"K number confidence levels distribution noise distribution use. parameter-free distribution, .e., one mean-centered without additional variance/shape parameters. distribution already available stan, must additionally provide two functions Stan (one <distribution>_lcdf one <distribution>_lccdf). metac_absolute type 2 criterion (metac) fixed absolute type 1 criterion (c)? TRUE, model set metac = c. Otherwise, set metac = M * c, type 2 criterion relatively equal type 1 criterion (.e., meta_c/meta_dprime = c/dprime) categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"brms::stanvar object containing Stan code defining likelihood metad' model K confidence levels, signal distributed according distribution distribution, metac = c metac_absolute==TRUE, metac = M*c otherwise.","code":""},{"path":"https://metacoglab.github.io/hmetad/reference/stanvars_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"","code":"# create stancode for the meta-d' model # using the normal distribution and 3 levels of confidence stanvars_metad(3) #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_normal_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = std_normal_lccdf(c - to_signed(stimulus)*dprime/2);\\n    real lp_0 = std_normal_lcdf(c - to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = std_normal_lccdf(meta_c - meta_mu);\\n    lp2_0[1] = std_normal_lcdf(meta_c - meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = std_normal_lccdf(meta_c2_1[k-1] - meta_mu);\\n      lp2_0[k] = std_normal_lcdf(meta_c2_0[k-1] - meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__3__normal__absolute__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_1_1, real z_meta_c2_1_2) {\\n  int K = 3; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_normal_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_normal_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\"  # create stancode for the meta-d' model with meta_c = M * c stanvars_metad(3, metac_absolute = FALSE) #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_normal_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = std_normal_lccdf(c - to_signed(stimulus)*dprime/2);\\n    real lp_0 = std_normal_lcdf(c - to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = std_normal_lccdf(meta_c - meta_mu);\\n    lp2_0[1] = std_normal_lcdf(meta_c - meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = std_normal_lccdf(meta_c2_1[k-1] - meta_mu);\\n      lp2_0[k] = std_normal_lcdf(meta_c2_0[k-1] - meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__3__normal__relative__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_1_1, real z_meta_c2_1_2) {\\n  int K = 3; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = M * c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_normal_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_normal_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\"  # create stancode for the meta-d' model with # an alternative distribution # note: cumulative distribution functions must be defined # in R and in Stan using [brms::stanvar()] stanvars_metad(4, distribution = \"gumbel_min\") #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_gumbel_min_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = gumbel_min_lccdf(c | to_signed(stimulus)*dprime/2);\\n    real lp_0 = gumbel_min_lcdf(c | to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = gumbel_min_lccdf(meta_c | meta_mu);\\n    lp2_0[1] = gumbel_min_lcdf(meta_c | meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = gumbel_min_lccdf(meta_c2_1[k-1] | meta_mu);\\n      lp2_0[k] = gumbel_min_lcdf(meta_c2_0[k-1] | meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__4__gumbel_min__absolute__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_0_3, real z_meta_c2_1_1, real z_meta_c2_1_2, real z_meta_c2_1_3) {\\n  int K = 4; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2, z_meta_c2_0_3]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2, z_meta_c2_1_3]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_gumbel_min_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_gumbel_min_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\""},{"path":"https://metacoglab.github.io/hmetad/news/index.html","id":"hmetad-001","dir":"Changelog","previous_headings":"","what":"hmetad 0.0.1","title":"hmetad 0.0.1","text":"Initial CRAN submission.","code":""}]
