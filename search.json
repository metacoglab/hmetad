[{"path":"https://metacoglab.github.io/mRatio/articles/alternative_distributions.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using alternative signal distributions with the meta-d' model","text":"standard meta-d’ model assumes evidence making type 1 decisions follows equal-variance normal distribution evidence making type 2 decisions follows truncated equal-variance normal distribution. However, recent interest using distributions signal detection theory. distributions identifiable meta-d’ model (e.g., one simultaneously estimate unequal variances \\textrm{meta-}d'), mRatio package allows one specify distribution takes single parameter defining location (.e., mean, median, mode) distribution. demonstrate functionality, implement meta-d’ model Gumbel-min distribution, shown provide parsimonious explanation recognition memory data (Meyer-Grant et al, 2025). begin loading necessary packages R:","code":"library(tidyverse) library(brms) library(tidybayes) library(mRatio)"},{"path":"https://metacoglab.github.io/mRatio/articles/alternative_distributions.html","id":"implementing-a-distribution-function-for-use-with-mratio","dir":"Articles","previous_headings":"","what":"Implementing a distribution function for use with mRatio","title":"Using alternative signal distributions with the meta-d' model","text":"order distribution used mRatio package, one needs implement cumulative distribution functions R Stan. Specifically, since mRatio package computes model likelihood logarithmic scale, one must define: <distribution>_lcdf(x, mu): log cumulative distribution function defining \\textrm{log } P(X \\le x) random variable X \\sim \\textrm{distribution}(\\mu). <distribution>_lccdf(x, mu): log complementary cumulative distribution function defining \\textrm{log } P(X \\ge x) random variable X \\sim \\textrm{distribution}(\\mu). Please note use mRatio package, two functions must use naming scheme (.e., must named <distribution>_l(c)cdf). example, can write gumbel min distribution functions R follows: One also needs implement two functions Stan using brms::stanvar available brms model fitting. Fortunately, functions usually look almost identical definitions R, minor syntactic changes /use efficient helper functions. code implements two functions Stan: , note name functions Stan must match corresponding names R. lcdf lccdf functions implemented R Stan, new distribution ready use mRatio package!","code":"gumbel_min_lcdf <- function(x, g) {   log1p(-exp(-exp(x - g))) } gumbel_min_lccdf <- function(x, g) {   -exp(x - g) } gumbel_min <- stanvar(   scode = \" real gumbel_min_lcdf(real x, real g) {   return log1m_exp(-exp(x - g)); } real gumbel_min_lccdf(real x, real g) {   return -exp(x - g); }\",   block = \"functions\" )"},{"path":"https://metacoglab.github.io/mRatio/articles/alternative_distributions.html","id":"data-simulation","dir":"Articles","previous_headings":"","what":"Data simulation","title":"Using alternative signal distributions with the meta-d' model","text":"continuing model fitting, section describes simulate data meta-d’ model custom distribution. necessary step parameter recovery ensure meta-d’ model well-defined respect distribution. simulate data, can call sim_metad function supplying optional arguments lcdf lccdf:","code":"d <- sim_metad(   N_trials = 10000, dprime = 1.5, c = .1, log_M = -.5,   c2_0_diff = c(.25, .5, .25), c2_1_diff = c(.1, .5, .25),   lcdf = gumbel_min_lcdf, lccdf = gumbel_min_lccdf )"},{"path":"https://metacoglab.github.io/mRatio/articles/alternative_distributions.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Using alternative signal distributions with the meta-d' model","text":"data, fitting model exactly equal-variance normal distribution, now also need specify two additional arguments fit_metad. distribution argument name distribution string. part function names preceding \"_lcdf\" \"_lccdf\" R Stan. stanvars argument stanvar object created containing Stan code cumulative distribution functions. Otherwise, one can call fit_metad just equal-variance normal distribution! Please note, however, scale parameters vary distribution distribution, set priors accordingly. code shows fit meta-d’ model new gumbel_min distribution: model summary can interpreted just model, however can see model family metad__4__gumbel_min__absolute__multinomial, indicating model indeed uses gumbel_min distribution four confidence levels \\textrm{meta-}c = c.","code":"m <- fit_metad(N ~ 1,   data = d,   prior = prior(normal(0, 1), class = Intercept) +     prior(normal(0, 1), class = dprime) +     prior(normal(0, 1), class = c) +     prior(lognormal(-1, 1), class = metac2zero1diff) +     prior(lognormal(-1, 1), class = metac2zero2diff) +     prior(lognormal(-1, 1), class = metac2zero3diff) +     prior(lognormal(-1, 1), class = metac2one1diff) +     prior(lognormal(-1, 1), class = metac2one2diff) +     prior(lognormal(-1, 1), class = metac2one3diff),   distribution = \"gumbel_min\", stanvars = gumbel_min, file = \"models/gumbel.rds\" ) #>  Family: metad__4__gumbel_min__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -0.61      0.06    -0.73    -0.49 1.00     3591     3343 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              1.55      0.03     1.49     1.61 1.00     5722     3474 #> c                   0.11      0.01     0.08     0.14 1.00     3812     2821 #> metac2zero1diff     0.24      0.01     0.22     0.26 1.00     5298     3297 #> metac2zero2diff     0.49      0.01     0.46     0.51 1.00     5293     3210 #> metac2zero3diff     0.25      0.01     0.23     0.27 1.00     6152     2811 #> metac2one1diff      0.10      0.01     0.09     0.11 1.00     4581     2940 #> metac2one2diff      0.48      0.01     0.45     0.50 1.00     4205     3027 #> metac2one3diff      0.25      0.01     0.23     0.27 1.00     4670     2731 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/mRatio/articles/alternative_distributions.html","id":"model-estimates","dir":"Articles","previous_headings":"","what":"Model estimates","title":"Using alternative signal distributions with the meta-d' model","text":"model fit, can post-processed like model mRatio package. alternative distributions often understood terms effects ROC, focus plotting . Looking pseudo-type 1 ROC, can see gumbel_min distribution exhibits asymmetry:  Likewise, gumbel_min distribution also asymmetric type 2 ROCs:","code":"# psuedo type-1 ROC tibble(.row = 1) |>   add_roc1_draws(m, bounds = TRUE) |>   median_qi(p_fa, p_hit) |>   ggplot(aes(     x = p_fa, xmin = p_fa.lower, xmax = p_fa.upper,     y = p_hit, ymin = p_hit.lower, ymax = p_hit.upper   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_point() +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(False Alarm)\") +   ylab(\"P(Hit)\") +   theme_bw(18) # type 2 ROC roc2_draws(m, tibble(.row = 1), bounds = TRUE) |>   median_qi(p_hit2, p_fa2) |>   mutate(response = factor(response)) |>   ggplot(aes(     x = p_fa2, xmin = p_fa2.lower, xmax = p_fa2.upper,     y = p_hit2, ymin = p_hit2.lower, ymax = p_hit2.upper,     color = response   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_point() +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(Type 2 False Alarm)\") +   ylab(\"P(Type 2 Hit)\") +   theme_bw(18)"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Fitting the meta-d' model","text":"vignette demonstrates use mRatio package fit meta-d’ model (Maniscalco Lau 2012) dataset including binary decision confidence ratings.","code":""},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data preparation","title":"Fitting the meta-d' model","text":"get better idea kind datasets mRatio package designed , can start simulating one (see help('sim_metad') description data simulation function): can see, dataset column trial number, presented stimulus trial (0 1), participant’s type 1 response (0 1), corresponding type 2 response (confidence; 1:K). trials dataset sorted stimulus, response, confidence dataset simulated, otherwise look similar kind data immediately get running experiment.","code":"library(tidyverse) library(tidybayes) library(mRatio)  d <- sim_metad(   N_trials = 1000, dprime = .75, c = -.5, log_M = -1,   c2_0 = c(.25, .75, 1), c2_1 = c(.5, 1, 1.25) ) #> # A tibble: 1,000 × 4 #> # Groups:   stimulus, response, confidence [16] #>    trial stimulus response confidence #>    <int>    <int>    <int>      <int> #>  1     1        0        0          1 #>  2     2        0        0          1 #>  3     3        0        0          1 #>  4     4        0        0          1 #>  5     5        0        0          1 #>  6     6        0        0          1 #>  7     7        0        0          1 #>  8     8        0        0          1 #>  9     9        0        0          1 #> 10    10        0        0          1 #> # ℹ 990 more rows"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"type-1-type-2-and-joint-responses","dir":"Articles","previous_headings":"Data preparation","what":"Type 1, type 2, and joint responses","title":"Fitting the meta-d' model","text":"One hiccup paradigms collect separate decision (.e., type 1 response) confidence rating (.e., type 2 response)—rather, collect single rating reflecting primary decision confidence. example, instead binary type 1 response type 2 response ranging 1 K (K maximum confidence level), sometimes participants asked make rating scale 1 2*K, 1 represents confidence \"0\" response, K represents uncertain \"0\" response, K+1 represents uncertain \"1\" response, 2*K represents confident \"1\" response. refer joint response, combination type 1 response type 2 response. like convert joint response separate type 1 type 2 responses, can use corresponding functions type1_response type2_response. example, instead dataset looked like : convert joint response like : Similarly, can also convert separate responses joint response: Note cases need specify confidence scale K=4 levels (meaning joint type 1/type 2 scale 8 levels).","code":"#> # A tibble: 1,000 × 2 #>    trial joint_response #>    <int>          <dbl> #>  1     1              4 #>  2     2              4 #>  3     3              4 #>  4     4              4 #>  5     5              4 #>  6     6              4 #>  7     7              4 #>  8     8              4 #>  9     9              4 #> 10    10              4 #> # ℹ 990 more rows d.joint_response |>   mutate(     response = type1_response(joint_response, K = 4),     confidence = type2_response(joint_response, K = 4)   ) #> # A tibble: 1,000 × 4 #>    trial joint_response response confidence #>    <int>          <dbl>    <int>      <dbl> #>  1     1              4        0          1 #>  2     2              4        0          1 #>  3     3              4        0          1 #>  4     4              4        0          1 #>  5     5              4        0          1 #>  6     6              4        0          1 #>  7     7              4        0          1 #>  8     8              4        0          1 #>  9     9              4        0          1 #> 10    10              4        0          1 #> # ℹ 990 more rows d |>   mutate(joint_response = joint_response(response, confidence, K = 4)) #> # A tibble: 1,000 × 5 #> # Groups:   stimulus, response, confidence [16] #>    trial stimulus response confidence joint_response #>    <int>    <int>    <int>      <int>          <dbl> #>  1     1        0        0          1              4 #>  2     2        0        0          1              4 #>  3     3        0        0          1              4 #>  4     4        0        0          1              4 #>  5     5        0        0          1              4 #>  6     6        0        0          1              4 #>  7     7        0        0          1              4 #>  8     8        0        0          1              4 #>  9     9        0        0          1              4 #> 10    10        0        0          1              4 #> # ℹ 990 more rows"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"signed-and-unsigned-binary-numbers","dir":"Articles","previous_headings":"Data preparation","what":"Signed and unsigned binary numbers","title":"Fitting the meta-d' model","text":"Often datasets use -1 1 instead 0 1 represent two possible stimuli type 1 responses. mRatio package designed use unsigned (0 1) version, provides helper functions convert two:","code":"to_unsigned(c(-1, 1)) #> [1] 0 1 to_signed(c(0, 1)) #> [1] -1  1"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"data-aggregation","dir":"Articles","previous_headings":"Data preparation","what":"Data aggregation","title":"Fitting the meta-d' model","text":"Finally, ensure model runs efficiently, mRatio package currently requires data aggregated. easier, mRatio package aggregate data fit model. like manually (e.g., plotting follow-analyses), aggregate_metad function can : resulting data frame three columns: N_0 number trials stimulus==0, N_1 number trials stimulus==1, N matrix containing number joint responses two possible stimuli (column names indicating stimulus joint_response). like use variable name N counts, can change name .name argument: Finally, columns dataset (e.g., participant condition columns) like aggregated separately, can simply add function call:","code":"d.summary <- aggregate_metad(d) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   500   500           3         59        117         44         83        135 #> # ℹ 1 more variable: N[7:16] <int> aggregate_metad(d, .name = \"y\") #> # A tibble: 1 × 3 #>     y_0   y_1 y[,\"y_0_1\"] [,\"y_0_2\"] [,\"y_0_3\"] [,\"y_0_4\"] [,\"y_0_5\"] [,\"y_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   500   500           3         59        117         44         83        135 #> # ℹ 1 more variable: y[7:16] <int> aggregate_metad(d, participant, condition)"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"Fitting the meta-d' model","text":"fit model, can use fit_metad function. function simply wrapper around brms::brm, users strongly encouraged become familiar brms model fitting. Since aggregate_metad place dataset trial counts column named N default, can use N response variable even data yet aggregated. fit model fixed values parameter, , can use formula N ~ 1: Note arbitrarily chosen use standard normal priors parameters. get better idea set informed priors, please refer help('set_prior', package='brms'). model, Intercept estimate \\textrm{log}(M) = \\textrm{log}\\frac{\\textrm{meta-}d'}{d'}, dprime estimate d', c estimate c, metac2zero1diff metac2zero2diff distances successive confidence thresholds \"0\" responses, metac2one1diff metac2one2diff distances successive confidence thresholds \"1\" responses. parameter, brms shows posterior means (Estimate), posterior standard deviations (Est. Error), upper- lower-95% posterior quantiles (l-95% CI u-95% CI), well convergence metrics (Rhat, Bulk_ESS, Tail_ESS).","code":"m <- fit_metad(N ~ 1,   data = d,   file = \"models/metad.rds\",   prior = prior(normal(0, 1), class = Intercept) +     prior(normal(0, 1), class = dprime) +     prior(normal(0, 1), class = c) +     prior(lognormal(0, 1), class = metac2zero1diff) +     prior(lognormal(0, 1), class = metac2zero2diff) +     prior(lognormal(0, 1), class = metac2one1diff) +     prior(lognormal(0, 1), class = metac2one2diff) ) #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -0.69      0.32    -1.43    -0.15 1.00     4865     3047 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              0.71      0.08     0.54     0.87 1.00     6299     2751 #> c                  -0.49      0.04    -0.57    -0.41 1.00     4208     2761 #> metac2zero1diff     0.21      0.02     0.17     0.26 1.00     6164     2998 #> metac2zero2diff     0.78      0.05     0.68     0.89 1.00     5144     2949 #> metac2zero3diff     1.27      0.17     0.97     1.63 1.00     5911     3002 #> metac2one1diff      0.47      0.03     0.41     0.54 1.00     5660     3143 #> metac2one2diff      1.00      0.05     0.91     1.09 1.00     5878     2975 #> metac2one3diff      1.30      0.11     1.10     1.52 1.00     8763     3453 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"extract-model-estimates","dir":"Articles","previous_headings":"","what":"Extract model estimates","title":"Fitting the meta-d' model","text":"fitted model, many estimates can extract . Although brms provides functions extracting posterior estimates, mRatio package designed interface well tidybayes package make easier work model posterior samples.","code":""},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"parameter-estimates","dir":"Articles","previous_headings":"Extract model estimates","what":"Parameter estimates","title":"Fitting the meta-d' model","text":"First, often useful extract posterior draws model parameters, can linpred_draws_metad (wrapper around tidybayes::linpred_draws): tibble separate row every posterior sample separate column every model parameter. format useful purposes, often useful pivot separate row model parameter posterior sample: Now posterior samples stored single column .value, easy get posterior summaries using e.g. tidybayes::median_qi:","code":"draws.metad <- tibble(.row = 1) |>   add_linpred_draws_metad(m) #> # A tibble: 4,000 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime      c meta_dprime meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>  <dbl>       <dbl>  <dbl> #>  1     1     NA         NA     1 0.635  0.756 -0.505       0.480 -0.505 #>  2     1     NA         NA     2 0.419  0.723 -0.503       0.303 -0.505 #>  3     1     NA         NA     3 0.358  0.775 -0.499       0.277 -0.505 #>  4     1     NA         NA     4 0.571  0.687 -0.463       0.392 -0.505 #>  5     1     NA         NA     5 0.499  0.803 -0.540       0.401 -0.505 #>  6     1     NA         NA     6 0.398  0.735 -0.557       0.293 -0.505 #>  7     1     NA         NA     7 0.574  0.605 -0.475       0.347 -0.505 #>  8     1     NA         NA     8 0.456  0.716 -0.501       0.326 -0.505 #>  9     1     NA         NA     9 0.693  0.476 -0.482       0.330 -0.505 #> 10     1     NA         NA    10 0.596  0.777 -0.481       0.463 -0.505 #> # ℹ 3,990 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl> draws.metad <- tibble(.row = 1) |>   add_linpred_draws_metad(m, pivot_longer = TRUE) #> # A tibble: 44,000 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable    .value #>    <int>  <int>      <int> <int> <chr>         <dbl> #>  1     1     NA         NA     1 M            0.635  #>  2     1     NA         NA     1 dprime       0.756  #>  3     1     NA         NA     1 c           -0.505  #>  4     1     NA         NA     1 meta_dprime  0.480  #>  5     1     NA         NA     1 meta_c      -0.505  #>  6     1     NA         NA     1 meta_c2_0_1 -0.706  #>  7     1     NA         NA     1 meta_c2_0_2 -1.46   #>  8     1     NA         NA     1 meta_c2_0_3 -3.03   #>  9     1     NA         NA     1 meta_c2_1_1 -0.0206 #> 10     1     NA         NA     1 meta_c2_1_2  1.01   #> # ℹ 43,990 more rows draws.metad |>   median_qi() #> # A tibble: 11 × 8 #>     .row .variable    .value  .lower  .upper .width .point .interval #>    <int> <chr>         <dbl>   <dbl>   <dbl>  <dbl> <chr>  <chr>     #>  1     1 c           -0.493  -0.574  -0.409    0.95 median qi        #>  2     1 dprime       0.707   0.543   0.871    0.95 median qi        #>  3     1 M            0.518   0.240   0.865    0.95 median qi        #>  4     1 meta_c      -0.505  -0.505  -0.505    0.95 median qi        #>  5     1 meta_c2_0_1 -0.718  -0.769  -0.673    0.95 median qi        #>  6     1 meta_c2_0_2 -1.50   -1.62   -1.39     0.95 median qi        #>  7     1 meta_c2_0_3 -2.76   -3.14   -2.45     0.95 median qi        #>  8     1 meta_c2_1_1 -0.0339 -0.0968  0.0334   0.95 median qi        #>  9     1 meta_c2_1_2  0.965   0.862   1.07     0.95 median qi        #> 10     1 meta_c2_1_3  2.26    2.05    2.50     0.95 median qi        #> 11     1 meta_dprime  0.367   0.171   0.573    0.95 median qi"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Extract model estimates","what":"Posterior predictions","title":"Fitting the meta-d' model","text":"One way evaluate model fit perform posterior predictive check: simulate data model’s posterior compare simulated actual data. can using function predicted_draws_metad (wrapper around tidybayes::predicted_draws): data frame, columns aggregated data d.summary well stimulus, joint_response, response, confidence (indicating simulated trial type), well .prediction (indicating number simulated trials per trial type). , can plot posterior predictions (points error-bars) actual data (bars):","code":"draws.predicted <- predicted_draws_metad(m, d.summary) #> # A tibble: 64,000 × 12 #> # Groups:   .row, N_0, N_1, N, stimulus, joint_response, response, confidence #> #   [16] #>     .row   N_0   N_1 N[,\"N_0_1\"] stimulus joint_response response confidence #>    <int> <int> <int>       <int>    <int>          <int>    <int>      <dbl> #>  1     1   500   500           3        0              1        0          4 #>  2     1   500   500           3        0              1        0          4 #>  3     1   500   500           3        0              1        0          4 #>  4     1   500   500           3        0              1        0          4 #>  5     1   500   500           3        0              1        0          4 #>  6     1   500   500           3        0              1        0          4 #>  7     1   500   500           3        0              1        0          4 #>  8     1   500   500           3        0              1        0          4 #>  9     1   500   500           3        0              1        0          4 #> 10     1   500   500           3        0              1        0          4 #> # ℹ 63,990 more rows #> # ℹ 5 more variables: N[2:16] <int>, .prediction <int>, .chain <int>, #> #   .iteration <int>, .draw <int> draws.predicted |>   group_by(.row, stimulus, joint_response, response, confidence) |>   median_qi(.prediction) |>   group_by(.row) |>   mutate(N = t(d.summary$N[.row, ])) |>   ggplot(aes(x = joint_response)) +   geom_col(aes(y = N), fill = \"grey80\") +   geom_pointrange(aes(y = .prediction, ymin = .lower, ymax = .upper)) +   facet_wrap(~stimulus, labeller = label_both) +   theme_classic(18) #> Warning in `[<-.data.frame`(`*tmp*`, , y_vars, value = list(y = c(3, 59, : #> replacement element 1 has 256 rows to replace 16 rows"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"posterior-expectations","dir":"Articles","previous_headings":"Extract model estimates","what":"Posterior expectations","title":"Fitting the meta-d' model","text":"Usually simpler compare response probabilities rather raw response counts. , can use workflow using epred_draws_metad (wrapper around tidybayes::epred_draws):","code":"draws.epred <- epred_draws_metad(m, newdata = tibble(.row = 1)) #> # A tibble: 64,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence  .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>   <dbl>  <int>      <int> #>  1     1        0              1        0          4 0.00296     NA         NA #>  2     1        0              1        0          4 0.0100      NA         NA #>  3     1        0              1        0          4 0.00375     NA         NA #>  4     1        0              1        0          4 0.0122      NA         NA #>  5     1        0              1        0          4 0.00535     NA         NA #>  6     1        0              1        0          4 0.00504     NA         NA #>  7     1        0              1        0          4 0.00363     NA         NA #>  8     1        0              1        0          4 0.00509     NA         NA #>  9     1        0              1        0          4 0.00828     NA         NA #> 10     1        0              1        0          4 0.00637     NA         NA #> # ℹ 63,990 more rows #> # ℹ 1 more variable: .draw <int> draws.epred |>   group_by(.row, stimulus, joint_response, response, confidence) |>   median_qi(.epred) |>   group_by(.row) |>   mutate(.true = t(response_probabilities(d.summary$N[.row, ]))) |>   ggplot(aes(x = joint_response)) +   geom_col(aes(y = .true), fill = \"grey80\") +   geom_pointrange(aes(y = .epred, ymin = .lower, ymax = .upper)) +   scale_alpha_discrete(range = c(.25, 1)) +   facet_wrap(~stimulus, labeller = label_both) +   theme_classic(18) #> Warning: Using alpha for a discrete variable is not advised. #> Warning in `[<-.data.frame`(`*tmp*`, , y_vars, value = list(y = c(0.006, : #> replacement element 1 has 256 rows to replace 16 rows"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"mean-confidence","dir":"Articles","previous_headings":"Extract model estimates","what":"Mean confidence","title":"Fitting the meta-d' model","text":"One can also compute implied values mean confidence meta-d’ model using mean_confidence_draws: , .epred refers model-estimated mean confidence per stimulus response, .true empirical mean confidence. addition, can compute mean confidence marginalizing stimuli: responses: stimuli responses:","code":"tibble(.row = 1) |>   add_mean_confidence_draws(m) |>   median_qi(.epred) |>   left_join(d |>     group_by(stimulus, response) |>     summarize(.true = mean(confidence))) #> `summarise()` has regrouped the output. #> Joining with `by = join_by(stimulus, response)` #> ℹ Summaries were computed grouped by stimulus and response. #> ℹ Output is grouped by stimulus. #> ℹ Use `summarise(.groups = \"drop_last\")` to silence this message. #> ℹ Use `summarise(.by = c(stimulus, response))` for per-operation grouping #>   (`?dplyr::dplyr_by`) instead. #> # A tibble: 4 × 10 #>    .row stimulus response .epred .lower .upper .width .point .interval .true #>   <int>    <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0        0   2.07   1.99   2.15   0.95 median qi         2.09 #> 2     1        0        1   1.91   1.83   1.99   0.95 median qi         1.92 #> 3     1        1        0   1.95   1.86   2.04   0.95 median qi         1.90 #> 4     1        1        1   2.08   2.02   2.15   0.95 median qi         2.07 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_stimulus = FALSE) |>   median_qi(.epred) |>   left_join(d |>     group_by(response) |>     summarize(.true = mean(confidence))) #> Joining with `by = join_by(response)` #> # A tibble: 2 × 9 #>    .row response .epred .lower .upper .width .point .interval .true #>   <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0   2.03   1.95   2.11   0.95 median qi         2.03 #> 2     1        1   2.01   1.96   2.07   0.95 median qi         2.01 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_response = FALSE) |>   median_qi(.epred) |>   left_join(d |>     group_by(stimulus) |>     summarize(.true = mean(confidence))) #> Joining with `by = join_by(stimulus)` #> # A tibble: 2 × 9 #>    .row stimulus .epred .lower .upper .width .point .interval .true #>   <int>    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1        0   1.98   1.93   2.03   0.95 median qi         2    #> 2     1        1   2.06   2.01   2.11   0.95 median qi         2.04 tibble(.row = 1) |>   add_mean_confidence_draws(m, by_stimulus = FALSE, by_response = FALSE) |>   median_qi(.epred) |>   bind_cols(d |>     ungroup() |>     summarize(.true = mean(confidence))) #> # A tibble: 1 × 8 #>    .row .epred .lower .upper .width .point .interval .true #>   <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl> #> 1     1   2.02   1.97   2.06   0.95 median qi         2.02"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"metacognitive-bias","dir":"Articles","previous_headings":"Extract model estimates","what":"Metacognitive bias","title":"Fitting the meta-d' model","text":"mean confidence often empirically informative, recommended measure metacognitive bias known confounded type 1 response characteristics (.e., d' c) metacognitive sensitivity (.e., \\textrm{meta-}d'). Instead, recommend new measure metacognitive bias, \\textrm{meta-}\\Delta, distance average confidence criteria \\textrm{meta-}c. \\textrm{meta-}\\Delta can interpreted lying two extremes: \\textrm{meta-}\\Delta = 0, observer uses highest confidence rating, \\textrm{meta-}\\Delta = \\infty, observer uses lowest confidence rating. obtain estimates \\textrm{meta-}\\Delta, one can use function metacognitive_bias_draws:","code":"tibble(.row = 1) |>   add_metacognitive_bias_draws(m) |>   median_qi() #> # A tibble: 2 × 8 #>    .row response metacognitive_bias .lower .upper .width .point .interval #>   <int>    <int>              <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>     #> 1     1        0               1.16   1.03   1.30   0.95 median qi        #> 2     1        1               1.57   1.47   1.67   0.95 median qi"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"pseudo-type-1-roc","dir":"Articles","previous_headings":"Extract model estimates","what":"Pseudo Type 1 ROC","title":"Fitting the meta-d' model","text":"obtain type 1 performance pseudo-type 1 ROC, can use add_roc1_draws: , tidy tibble columns .chain, .iteration, .draw identifying individual posterior samples, joint_response, response, confidence identifying different points ROC, .row identifying different ROCs (since data frame one row, one ROC). addition, also p_hit p_fa, contain posterior estimates type 1 hit rate (.e., probability \"1\" response confidence >= c given stimulus==1) type 1 false alarm rate (.e., probability \"1\" response confidence >= c given stimulus==0). visualization, can get posterior summaries ROC using tidybayes::median_qi simply plot line:","code":"draws.roc1 <- tibble(.row = 1) |>   add_roc1_draws(m) #> # A tibble: 28,000 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.997 1.000 #>  2     1              1        0          4     NA         NA     2 0.990 0.997 #>  3     1              1        0          4     NA         NA     3 0.996 0.999 #>  4     1              1        0          4     NA         NA     4 0.988 0.997 #>  5     1              1        0          4     NA         NA     5 0.995 0.999 #>  6     1              1        0          4     NA         NA     6 0.995 0.999 #>  7     1              1        0          4     NA         NA     7 0.996 0.999 #>  8     1              1        0          4     NA         NA     8 0.995 0.999 #>  9     1              1        0          4     NA         NA     9 0.992 0.997 #> 10     1              1        0          4     NA         NA    10 0.994 0.999 #> # ℹ 27,990 more rows draws.roc1 |>   median_qi(p_fa, p_hit) |>   ggplot(aes(     x = p_fa, xmin = p_fa.lower, xmax = p_fa.upper,     y = p_hit, ymin = p_hit.lower, ymax = p_hit.upper   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(False Alarm)\") +   ylab(\"P(Hit)\") +   theme_bw(18)"},{"path":"https://metacoglab.github.io/mRatio/articles/mRatio.html","id":"type-2-roc","dir":"Articles","previous_headings":"Extract model estimates","what":"Type 2 ROC","title":"Fitting the meta-d' model","text":"Finally, plot type 2 performance type 2 ROC, can use add_roc2_draws: tibble looks roc1_draws, except now columns p_hit2 representing type 2 hit rate (.e., probability correct response confidence >= c given response) type 2 false alarm rate (.e., probability incorrect response confidence >= c given response). Note response-specific type 2 ROC, two separate curves two type 1 responses. can also plot type 2 ROC similarly:","code":"draws.roc2 <- tibble(.row = 1) |>   add_roc2_draws(m) #> # A tibble: 24,000 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw  p_hit2   p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>   <dbl>   <dbl> #>  1     1        0          4     NA         NA     1 0.00659 0.00233 #>  2     1        0          4     NA         NA     2 0.0226  0.0134  #>  3     1        0          4     NA         NA     3 0.00824 0.00468 #>  4     1        0          4     NA         NA     4 0.0270  0.0138  #>  5     1        0          4     NA         NA     5 0.0120  0.00552 #>  6     1        0          4     NA         NA     6 0.0119  0.00678 #>  7     1        0          4     NA         NA     7 0.00841 0.00410 #>  8     1        0          4     NA         NA     8 0.0115  0.00608 #>  9     1        0          4     NA         NA     9 0.0205  0.0114  #> 10     1        0          4     NA         NA    10 0.0138  0.00559 #> # ℹ 23,990 more rows draws.roc2 |>   median_qi(p_hit2, p_fa2) |>   mutate(response = factor(response)) |>   ggplot(aes(     x = p_fa2, xmin = p_fa2.lower, xmax = p_fa2.upper,     y = p_hit2, ymin = p_hit2.lower, ymax = p_hit2.upper,     color = response   )) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   geom_errorbar(orientation = \"y\", width = .01) +   geom_errorbar(orientation = \"x\", width = .01) +   geom_line() +   coord_fixed(xlim = 0:1, ylim = 0:1, expand = FALSE) +   xlab(\"P(Type 2 False Alarm)\") +   ylab(\"P(Type 2 Hit)\") +   theme_bw(18)"},{"path":[]},{"path":"https://metacoglab.github.io/mRatio/articles/parameterization.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parameterization of the meta-d' model","text":"metacognition research, decision-making often categorized two kinds. type 1 decision primary decision hand, example judging orientation grating left right, judging word either presented (old) (new). context meta-d’ model, type 1 decision binary decision task (.e., either yes-decision task two-alternative forced choice task). contrast, type 2 decision task rating confidence type 1 decision. meta-d’ model applicable type 2 decision categorical (.e., confidence rated ordinal scale 1 K, 1 indicates low confidence K indicates high confidence). line distinction type 1 type 2 decisions, meta-d’ model conjunction two models (one decision). models based Signal Detection Theory (SDT). However, insight meta-d’ model information available type 2 decisions might differ information available type 1 decisions.","code":""},{"path":"https://metacoglab.github.io/mRatio/articles/parameterization.html","id":"model-for-type-1-decisions","dir":"Articles","previous_headings":"","what":"Model for type 1 decisions","title":"Parameterization of the meta-d' model","text":"SDT, observer presented noisy signal depending underlying stimulus x_1 \\sim \\mathcal{D}_S(d') following distribution \\mathcal{D} dependent stimulus S \\\\{0, 1\\} observer’s sensitivity d'. Typically, \\mathcal{D} chosen equal-variance normal distribution, \\mathcal{D}_0(d') = \\mathcal{N}\\left(-\\frac{d'}{2}, 1\\right) \\mathcal{D}_1(d') = \\mathcal{N}\\left(\\frac{d'}{2}, 1\\right) However, decision arbitrary options available. Given noisy encoding x_1, observer tasked determining true value S. , simply threshold x_1 response R = [x_1 > c] setup, observer makes correct response R = S. importantly, trials can categorized hits (S = 1 R = 1), misses (S = 1 R = 0), false alarms (FAs; S = 0 R = 1), correct rejections (CRs; S = 0 R = 0). generative model type 1 decisions implies following response probabilities: P(R=r \\;\\vert\\; S=s) = \\begin{cases} 1 - F_{\\mathcal{D}_s(d')}\\left(c\\right) & \\textrm{} r=1 \\\\ F_{\\mathcal{D}_s(d')}\\left(c\\right) & \\textrm{} r=0 \\end{cases}","code":""},{"path":"https://metacoglab.github.io/mRatio/articles/parameterization.html","id":"model-for-type-2-decisions","dir":"Articles","previous_headings":"","what":"Model for type 2 decisions","title":"Parameterization of the meta-d' model","text":"classical SDT, type 2 decisions treated just like type 1 decisions stringent liberal response criteria. However, assumes observers access information making type 1 type 2 decisions. Relaxing assumption, meta-d’ model assumes type 2 decisions derived separate decision variable: x_2 \\sim \\begin{cases} \\mathcal{D}_S^{(-\\infty, \\textrm{meta-}c]}\\left(\\textrm{meta-}d'\\right) & \\textrm{} R=0 \\\\ \\mathcal{D}_S^{[\\textrm{meta-}c, \\infty)}\\left(\\textrm{meta-}d'\\right) & \\textrm{} R=1 \\end{cases} Importantly, decision variable follows distribution type 1 decision, two differences. First, distribution truncated either type 1 criterion \\textrm{meta-}c depending initial type 1 response. type 2 decision contradict type 1 decision (.e., meta-d’ model allow changes mind). Second, sensitivity type 2 decision \\textrm{meta-}d' rather d' allow task-level sensitivity metacognitive sensitivity differ. , determine confidence level C \\\\{ 1 \\ldots K\\}, observer rates confidence using one two sets K-1 ordered confidence criteria (\\textrm{meta-}c_2^0 \\textrm{meta-}c_2^1): \\begin{align*}     C &= \\begin{cases}     1+\\Sigma_{k=1}^{K-1}[x_2 < \\textrm{meta-}c_{2,k}^0] & \\textrm{} R=0 \\\\     1+\\Sigma_{k=1}^{K-1} [x_2 > \\textrm{meta-}c_{2,k}^1] & \\textrm{} R=1     \\end{cases} \\end{align*} generative model implies , conditional stimulus type 1 response, type 2 response probabilities \\begin{align*}     P(C=c \\;\\vert\\; R=r,S=s) &= \\begin{cases}     \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,1}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=0, c=1 \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k}^0\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k+1}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}       & \\textrm{} r=0, 1 \\le c \\le K \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,K}^0\\right)}     {F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=0, c = K \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,1}^0\\right) -     F_{\\mathcal{D}_s}\\left(\\textrm{meta-}c \\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, c=1 \\\\          \\frac{F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k+1}^0\\right) -     F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,k}^0\\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, 1 \\le c \\le K \\\\          \\frac{1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c_{2,K}^0 \\right)}     {1 - F_{\\mathcal{D}_s(\\textrm{meta-}d')}\\left(\\textrm{meta-}c\\right)}     & \\textrm{} r=1, c = K     \\end{cases} \\end{align*} formulas, numerator probability x_2 lies successive confidence thresholds denominator probability type 1 response r given type 2 parameters \\textrm{meta-}d' \\textrm{meta-}c account truncation type 2 signal distributions \\textrm{meta-}c.","code":""},{"path":"https://metacoglab.github.io/mRatio/articles/parameterization.html","id":"joint-model-for-type-1-and-type-2-decisions","dir":"Articles","previous_headings":"","what":"Joint model for type 1 and type 2 decisions","title":"Parameterization of the meta-d' model","text":"Ultimately, interested joint type 1 type 2 response probabilities stimulus. can conveniently decomposed type 1 response probability conditional type 2 response probability follows: P(R=r, C=c \\;\\vert\\; S=s) = P(R=r \\;\\vert\\; S=s) \\; P(C=c \\;\\vert\\; R=r, S=s) Given joint response probabilities stimulus, can formulate log likelihood meta-d’ one two ways. trial-level effects interest, one can model individual trials using categorical likelihood: LL \\;=\\; \\sum_n \\textrm{categorical}\\_\\textrm{lpmf}\\left(\\textrm{joint}\\_\\textrm{response}(r_n,c_n) \\;\\vert\\; P(R=r_n, C=c_n \\;\\vert\\; S=s_n)\\right) However, formulation requires likelihood evaluated per trial, well-powered experiments can take long time. , default mRatio package uses multinomial likelihood aggregated data. N_{s,r,c} number trials S=s, R=r, C=c: \\begin{align*} LL \\;&=\\; \\textrm{multinomial}\\_\\textrm{lpmf}\\left(N_{0,r,c} \\;\\vert\\; P(R=r, C=c \\;\\vert\\; S=0)\\right) \\\\ &\\;\\quad+\\; \\textrm{multinomial}\\_\\textrm{lpmf}\\left(N_{1,r,c} \\;\\vert\\; P(R=r, C=c \\;\\vert\\; S=1)\\right) \\end{align*} formulation requires model likelihood evaluated twice (per stimulus), dramatically increasing efficiency model fitting. increase efficiency, multinomial likelihood default mRatio package. categorical likelihood desired (e.g., trial-level effects crossed random effects), can used argument categorical=TRUE.","code":""},{"path":"https://metacoglab.github.io/mRatio/articles/parameterization.html","id":"fixing-the-type-1-threshold-for-type-2-responses","dir":"Articles","previous_headings":"","what":"Fixing the type 1 threshold for type 2 responses","title":"Parameterization of the meta-d' model","text":"meta-d’ model requires parameter \\textrm{meta-}c fixed equal respect type 1 criterion c. discussed (Maniscalco Lau 2014), multiple ways fixing \\textrm{meta-}c. mRatio package implements two: fixed parameterization, \\textrm{meta-}c = c. parameterization used default, since also used Hmeta-d toolbox (see also Fleming (2017)). Alternatively, relative parameterization, \\frac{\\textrm{meta-}c}{\\textrm{meta-}d'} = \\frac{c}{d'}, achieved setting \\textrm{meta-}c = M c. parameterization used (Maniscalco Lau 2012, 2014). switch two parameterizations, fit_metad sim_metad functions argument metac_absolute TRUE default. use relative parameterization, simply set metac_absolute=FALSE call function.","code":""},{"path":"https://metacoglab.github.io/mRatio/articles/parameterization.html","id":"model-parameterization","dir":"Articles","previous_headings":"","what":"Model parameterization","title":"Parameterization of the meta-d' model","text":"increase efficiency model fitting help convergence, mRatio parameterizes meta-d’ model parameters unconstrained variables (.e., fall range (-\\infty, \\infty)). parameters type 1 responses (d' c) already unconstrained, estimated normally. However, parameters type 2 parameters bounded. First, instead fitting \\textrm{meta-}d' directly, mRatio package models M-ratio M = \\frac{\\textrm{meta-}d'}{d'}. parameterization helps regularize strong differences \\textrm{meta-}d' d', M-ratio still bounded zero. , mRatio package models M-ratio logarithmic scale, .e., \\textrm{log }M = \\textrm{log}\\frac{\\textrm{meta-}d'}{d'}. parameterization, one can compute \\textrm{meta-}d' \\textrm{meta-}d' = e^{\\textrm{log }M}d'. Second, confidence criteria \\textrm{meta-}c_{2,1:K}^0 \\textrm{meta-}c_{2,1:K}^1 two constraints. Namely, \\textrm{meta-}c_{2,1:K}^0 must strictly decreasing less \\textrm{meta-}c, whereas \\textrm{meta-}c_{2,1:K}^1 must strictly increasing greater \\textrm{meta-}c. deal constraints, mRatio package estimates differences successive confidence criteria: \\textrm{dmeta-}c_{2,k}^0 = \\begin{cases}   \\textrm{meta-}c - \\textrm{meta-}c_{2,1}^0 & \\textrm{} k = 1 \\\\   \\textrm{meta-}c_{2,k-1}^0  - \\textrm{meta-}c_{2,k}^0 & \\textrm{} 2 \\le k \\le K \\end{cases}   \\textrm{dmeta-}c_{2,k}^1 = \\begin{cases}   \\textrm{meta-}c_{2,1}^0 - \\textrm{meta-}c & \\textrm{} k = 1 \\\\   \\textrm{meta-}c_{2,k}^1  - \\textrm{meta-}c_{2,k-1}^1 & \\textrm{} 2 \\le k \\le K \\end{cases} Like M-ratio, differences successive confidence criteria also modeled logarithmic scale (parameters named metac2zero<k>diff metac2one<k>diff). parameterization, confidence criteria can computed follows: \\begin{align*} \\textrm{meta-}c_2^0 &= \\textrm{meta-}c - \\textrm{cumulative}\\_\\textrm{sum}\\left(e^{\\textrm{dmeta-}c_2^0}\\right) \\\\ \\textrm{meta-}c_2^1 &= \\textrm{meta-}c + \\textrm{cumulative}\\_\\textrm{sum}\\left(e^{\\textrm{dmeta-}c_2^1}\\right) \\end{align*}","code":""},{"path":[]},{"path":"https://metacoglab.github.io/mRatio/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kevin O'Neill. Author, maintainer.","code":""},{"path":"https://metacoglab.github.io/mRatio/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"O'Neill K (2026). mRatio: Fit meta-d' model confidence ratings using 'brms'. R package version 0.0.1, https://metacoglab.github.io/mRatio/.","code":"@Manual{,   title = {mRatio: Fit the meta-d' model of confidence ratings using `brms`},   author = {Kevin O'Neill},   year = {2026},   note = {R package version 0.0.1},   url = {https://metacoglab.github.io/mRatio/}, }"},{"path":"https://metacoglab.github.io/mRatio/index.html","id":"mratio","dir":"","previous_headings":"","what":"Fit the meta-d' model of confidence ratings using `brms`","title":"Fit the meta-d' model of confidence ratings using `brms`","text":"mRatio package designed fit meta-d’ model confidence ratings (Maniscalco Lau 2012, 2014). Like Hmeta-d toolbox (Fleming 2017), mRatio package uses Bayesian modeling approach. mRatio package builds Hmeta-d toolbox implementation custom family brms package, provides friendly interface probabilistic programming language Stan. provides major benefits: Model designs can specified simple R formulas Support complex model designs (e.g., multilevel models, distributional models) Interfaces packages surrounding brms (e.g., tidybayes, ggdist, bayesplot, loo, posterior, bridgesampling, bayestestR) Computation model-implied quantities (e.g., mean confidence, type 1 type 2 receiver operating characteristic curves, metacognitive bias) Increased sampling efficiency better convergence diagnostics","code":""},{"path":"https://metacoglab.github.io/mRatio/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fit the meta-d' model of confidence ratings using `brms`","text":"can install development version mRatio GitHub :","code":"# install.packages(\"pak\") pak::pak(\"metacoglab/mRatio\")"},{"path":"https://metacoglab.github.io/mRatio/index.html","id":"quick-setup","dir":"","previous_headings":"","what":"Quick setup","title":"Fit the meta-d' model of confidence ratings using `brms`","text":"Let’s say data binary decision task ordinal confidence ratings: can fit intercepts-meta-d’ model using fit_metad: Now let’s say complicated design, within-participants manipulation: account repeated measures design, can simply adjust formula include participant-level effects:","code":"#> # A tibble: 1,000 × 5 #>    trial stimulus response correct confidence #>    <int>    <int>    <int>   <int>      <int> #>  1     1        0        0       1          2 #>  2     2        1        1       1          4 #>  3     3        0        0       1          1 #>  4     4        1        1       1          2 #>  5     5        0        0       1          2 #>  6     6        0        0       1          3 #>  7     7        0        0       1          1 #>  8     8        0        1       0          1 #>  9     9        0        0       1          1 #> 10    10        1        0       0          4 #> # ℹ 990 more rows library(mRatio)  m <- fit_metad(N ~ 1, data = d, file = \"vignettes/models/readme1.rds\") #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept     0.03      0.14    -0.27     0.29 1.00     3539     2895 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              1.04      0.08     0.88     1.20 1.00     4271     2982 #> c                   0.05      0.04    -0.04     0.12 1.00     3808     3275 #> metac2zero1diff     0.54      0.04     0.47     0.61 1.00     4535     3460 #> metac2zero2diff     0.53      0.04     0.46     0.61 1.00     5245     3345 #> metac2zero3diff     0.49      0.05     0.40     0.58 1.00     5219     3298 #> metac2one1diff      0.44      0.03     0.38     0.51 1.00     4889     3351 #> metac2one2diff      0.51      0.04     0.44     0.60 1.00     5030     2835 #> metac2one3diff      0.51      0.05     0.42     0.61 1.00     5413     3109 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1). #> # A tibble: 5,000 × 7 #> # Groups:   participant, condition [50] #>    participant condition trial stimulus response correct confidence #>          <int>     <int> <int>    <int>    <int>   <int>      <int> #>  1           1         1     1        1        1       1          4 #>  2           1         1     2        0        1       0          1 #>  3           1         1     3        1        0       0          1 #>  4           1         1     4        1        1       1          3 #>  5           1         1     5        1        1       1          4 #>  6           1         1     6        0        1       0          2 #>  7           1         1     7        0        0       1          4 #>  8           1         1     8        1        0       0          2 #>  9           1         1     9        1        1       1          3 #> 10           1         1    10        0        0       1          4 #> # ℹ 4,990 more rows m <- fit_metad(   bf(     N ~ condition + (condition | participant),     dprime + c +       metac2zero1diff + metac2zero2diff + metac2zero3diff +       metac2one1diff + metac2one2diff + metac2one3diff ~       condition + (condition | participant)   ),   data = d, init = \"0\", file = \"vignettes/models/readme2.rds\",   prior = prior(normal(0, 1)) +     prior(normal(0, 1), dpar = dprime) +     prior(normal(0, 1), dpar = c) +     prior(normal(0, 1), dpar = metac2zero1diff) +     prior(normal(0, 1), dpar = metac2zero2diff) +     prior(normal(0, 1), dpar = metac2zero3diff) +     prior(normal(0, 1), dpar = metac2one1diff) +     prior(normal(0, 1), dpar = metac2one2diff) +     prior(normal(0, 1), dpar = metac2one3diff) ) #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log; dprime = identity; c = identity; metac2zero1diff = log; metac2zero2diff = log; metac2zero3diff = log; metac2one1diff = log; metac2one2diff = log; metac2one3diff = log  #> Formula: N ~ condition + (condition | participant)  #>          dprime ~ condition + (condition | participant) #>          c ~ condition + (condition | participant) #>          metac2zero1diff ~ condition + (condition | participant) #>          metac2zero2diff ~ condition + (condition | participant) #>          metac2zero3diff ~ condition + (condition | participant) #>          metac2one1diff ~ condition + (condition | participant) #>          metac2one2diff ~ condition + (condition | participant) #>          metac2one3diff ~ condition + (condition | participant) #>    Data: data.aggregated (Number of observations: 50)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Multilevel Hyperparameters: #> ~participant (Number of levels: 25)  #>                                                           Estimate Est.Error #> sd(Intercept)                                                 0.38      0.16 #> sd(condition2)                                                0.61      0.22 #> sd(dprime_Intercept)                                          0.57      0.10 #> sd(dprime_condition2)                                         0.81      0.15 #> sd(c_Intercept)                                               0.58      0.09 #> sd(c_condition2)                                              0.59      0.10 #> sd(metac2zero1diff_Intercept)                                 0.06      0.05 #> sd(metac2zero1diff_condition2)                                0.10      0.07 #> sd(metac2zero2diff_Intercept)                                 0.06      0.04 #> sd(metac2zero2diff_condition2)                                0.11      0.08 #> sd(metac2zero3diff_Intercept)                                 0.06      0.05 #> sd(metac2zero3diff_condition2)                                0.09      0.07 #> sd(metac2one1diff_Intercept)                                  0.08      0.06 #> sd(metac2one1diff_condition2)                                 0.14      0.09 #> sd(metac2one2diff_Intercept)                                  0.12      0.07 #> sd(metac2one2diff_condition2)                                 0.12      0.09 #> sd(metac2one3diff_Intercept)                                  0.13      0.09 #> sd(metac2one3diff_condition2)                                 0.20      0.12 #> cor(Intercept,condition2)                                    -0.29      0.41 #> cor(dprime_Intercept,dprime_condition2)                      -0.65      0.14 #> cor(c_Intercept,c_condition2)                                -0.63      0.13 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)    -0.09      0.58 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)    -0.09      0.58 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)    -0.19      0.57 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)      -0.11      0.57 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)      -0.13      0.58 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)      -0.18      0.56 #>                                                           l-95% CI u-95% CI #> sd(Intercept)                                                 0.09     0.73 #> sd(condition2)                                                0.21     1.09 #> sd(dprime_Intercept)                                          0.41     0.82 #> sd(dprime_condition2)                                         0.57     1.14 #> sd(c_Intercept)                                               0.43     0.79 #> sd(c_condition2)                                              0.42     0.81 #> sd(metac2zero1diff_Intercept)                                 0.00     0.18 #> sd(metac2zero1diff_condition2)                                0.00     0.27 #> sd(metac2zero2diff_Intercept)                                 0.00     0.16 #> sd(metac2zero2diff_condition2)                                0.00     0.30 #> sd(metac2zero3diff_Intercept)                                 0.00     0.17 #> sd(metac2zero3diff_condition2)                                0.00     0.28 #> sd(metac2one1diff_Intercept)                                  0.00     0.22 #> sd(metac2one1diff_condition2)                                 0.01     0.34 #> sd(metac2one2diff_Intercept)                                  0.01     0.27 #> sd(metac2one2diff_condition2)                                 0.01     0.33 #> sd(metac2one3diff_Intercept)                                  0.01     0.33 #> sd(metac2one3diff_condition2)                                 0.01     0.46 #> cor(Intercept,condition2)                                    -0.85     0.71 #> cor(dprime_Intercept,dprime_condition2)                      -0.86    -0.32 #> cor(c_Intercept,c_condition2)                                -0.83    -0.31 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)    -0.96     0.94 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)    -0.97     0.93 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)    -0.97     0.92 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)      -0.96     0.93 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)      -0.96     0.94 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)      -0.96     0.90 #>                                                           Rhat Bulk_ESS #> sd(Intercept)                                             1.00     1167 #> sd(condition2)                                            1.00     1254 #> sd(dprime_Intercept)                                      1.00     2015 #> sd(dprime_condition2)                                     1.00     1728 #> sd(c_Intercept)                                           1.00     1493 #> sd(c_condition2)                                          1.00     1307 #> sd(metac2zero1diff_Intercept)                             1.00     2852 #> sd(metac2zero1diff_condition2)                            1.00     2155 #> sd(metac2zero2diff_Intercept)                             1.00     3360 #> sd(metac2zero2diff_condition2)                            1.00     2344 #> sd(metac2zero3diff_Intercept)                             1.00     2901 #> sd(metac2zero3diff_condition2)                            1.00     2720 #> sd(metac2one1diff_Intercept)                              1.00     2195 #> sd(metac2one1diff_condition2)                             1.00     1534 #> sd(metac2one2diff_Intercept)                              1.00     1600 #> sd(metac2one2diff_condition2)                             1.00     2027 #> sd(metac2one3diff_Intercept)                              1.00     1928 #> sd(metac2one3diff_condition2)                             1.00     1251 #> cor(Intercept,condition2)                                 1.00     1119 #> cor(dprime_Intercept,dprime_condition2)                   1.00     1615 #> cor(c_Intercept,c_condition2)                             1.00     1754 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2) 1.00     3431 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2) 1.00     3622 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2) 1.00     4661 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)   1.00     2572 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)   1.00     3701 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)   1.00     1899 #>                                                           Tail_ESS #> sd(Intercept)                                                 1009 #> sd(condition2)                                                1956 #> sd(dprime_Intercept)                                          2108 #> sd(dprime_condition2)                                         2256 #> sd(c_Intercept)                                               2290 #> sd(c_condition2)                                              2149 #> sd(metac2zero1diff_Intercept)                                 2489 #> sd(metac2zero1diff_condition2)                                2263 #> sd(metac2zero2diff_Intercept)                                 2837 #> sd(metac2zero2diff_condition2)                                2553 #> sd(metac2zero3diff_Intercept)                                 2288 #> sd(metac2zero3diff_condition2)                                2587 #> sd(metac2one1diff_Intercept)                                  2350 #> sd(metac2one1diff_condition2)                                 2261 #> sd(metac2one2diff_Intercept)                                  1509 #> sd(metac2one2diff_condition2)                                 2491 #> sd(metac2one3diff_Intercept)                                  2517 #> sd(metac2one3diff_condition2)                                 2267 #> cor(Intercept,condition2)                                     1252 #> cor(dprime_Intercept,dprime_condition2)                       2213 #> cor(c_Intercept,c_condition2)                                 2620 #> cor(metac2zero1diff_Intercept,metac2zero1diff_condition2)     2981 #> cor(metac2zero2diff_Intercept,metac2zero2diff_condition2)     2824 #> cor(metac2zero3diff_Intercept,metac2zero3diff_condition2)     3424 #> cor(metac2one1diff_Intercept,metac2one1diff_condition2)       2647 #> cor(metac2one2diff_Intercept,metac2one2diff_condition2)       2952 #> cor(metac2one3diff_Intercept,metac2one3diff_condition2)       1864 #>  #> Regression Coefficients: #>                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS #> Intercept                      0.17      0.14    -0.13     0.41 1.00     3333 #> dprime_Intercept               0.85      0.13     0.61     1.11 1.00     1769 #> c_Intercept                    0.01      0.12    -0.23     0.25 1.00      704 #> metac2zero1diff_Intercept     -1.16      0.06    -1.29    -1.04 1.00     7401 #> metac2zero2diff_Intercept     -1.01      0.06    -1.13    -0.90 1.00     7512 #> metac2zero3diff_Intercept     -1.02      0.07    -1.15    -0.89 1.00     7054 #> metac2one1diff_Intercept      -1.09      0.06    -1.22    -0.97 1.00     7644 #> metac2one2diff_Intercept      -0.95      0.07    -1.08    -0.82 1.00     6026 #> metac2one3diff_Intercept      -1.08      0.08    -1.23    -0.94 1.00     6309 #> condition2                    -0.03      0.19    -0.41     0.33 1.00     3741 #> dprime_condition2              0.09      0.18    -0.27     0.44 1.00     2065 #> c_condition2                  -0.12      0.13    -0.37     0.12 1.00     1082 #> metac2zero1diff_condition2     0.11      0.09    -0.06     0.28 1.00     8006 #> metac2zero2diff_condition2    -0.02      0.09    -0.19     0.15 1.00     7413 #> metac2zero3diff_condition2    -0.04      0.10    -0.23     0.15 1.00     7442 #> metac2one1diff_condition2      0.08      0.09    -0.09     0.25 1.00     6713 #> metac2one2diff_condition2     -0.11      0.09    -0.29     0.06 1.00     8351 #> metac2one3diff_condition2      0.11      0.11    -0.10     0.31 1.00     5899 #>                            Tail_ESS #> Intercept                      2811 #> dprime_Intercept               2187 #> c_Intercept                    1185 #> metac2zero1diff_Intercept      2942 #> metac2zero2diff_Intercept      2788 #> metac2zero3diff_Intercept      3110 #> metac2one1diff_Intercept       3152 #> metac2one2diff_Intercept       2892 #> metac2one3diff_Intercept       2977 #> condition2                     2759 #> dprime_condition2              2332 #> c_condition2                   1477 #> metac2zero1diff_condition2     3010 #> metac2zero2diff_condition2     3354 #> metac2zero3diff_condition2     3043 #> metac2one1diff_condition2      3073 #> metac2one2diff_condition2      3099 #> metac2one3diff_condition2      2844 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":[]},{"path":"https://metacoglab.github.io/mRatio/reference/aggregate_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate data by response, confidence, and other columns — aggregate_metad","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"Counts number rows data unique combinations values columns response, confidence, columns ....","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/aggregate_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"","code":"aggregate_metad(   data,   ...,   .stimulus = \"stimulus\",   .response = \"response\",   .confidence = \"confidence\",   .joint_response = \"joint_response\",   .name = \"N\",   K = NULL )"},{"path":"https://metacoglab.github.io/mRatio/reference/aggregate_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"data data frame aggregate ... Grouping columns data. columns converted factors. .stimulus name \"stimulus\" column .response name \"response\" column .confidence name \"confidence\" column .joint_response name \"joint_response\" column .name name resulting column containing trial counts K number confidence levels data. NULL, estimated data.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/aggregate_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"tibble one row per combination variables ..., another column named value .response containing trial counts. \\(K\\) confidence levels, \\(N \\times K*4\\) matrix, columns represent (stimulus \\(S\\), type 1 response \\(R\\), type 2 response \\(C\\)): $$  [N_{S=0, R=0, C=K}, \\ldots, N_{S=0, R=0, C=1}, \\\\  N_{S=0, R=1, C=1}, \\ldots, N_{S=0, R=1, C=K}, \\\\  N_{S=1, R=0, C=K}, \\ldots, N_{S=1, R=0, C=1}, \\\\  N_{S=1, R=1, C=1}, \\ldots, N_{S=1, R=1, C=K}] \\\\ $$","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/aggregate_metad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"data frame data must one column name given .stimulus. Additionally, must either: Two columns names given .response .confidence One column name given .joint_response Finally, must also columns additional variables ....","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/aggregate_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate data by response, confidence, and other columns — aggregate_metad","text":"","code":"# aggregate a dataset without grouping factors d <- sim_metad() aggregate_metad(d) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1    50    50           8          5          4         12         10          7 #> # ℹ 1 more variable: N[7:16] <int>  # aggregate a dataset with grouping factors d2 <- sim_metad_condition() aggregate_metad(d2, condition) #> # A tibble: 2 × 4 #>   condition   N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] #>   <fct>     <int> <int>       <int>      <int>      <int>      <int>      <int> #> 1 1            50    50           7          4         10         16          5 #> 2 2            50    50           3          6         10         13          9 #> # ℹ 1 more variable: N[6:16] <int>  # can also aggregate ignoring grouping factors aggregate_metad(d2) #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1   100   100          10         10         20         29         14          9 #> # ℹ 1 more variable: N[7:16] <int>  # aggregate data with only `joint_response` column library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union d |>   ungroup() |>   mutate(joint_response = joint_response(     response, confidence,     n_distinct(confidence)   )) |>   select(-response, -confidence) |>   aggregate_metad() #> # A tibble: 1 × 3 #>     N_0   N_1 N[,\"N_0_1\"] [,\"N_0_2\"] [,\"N_0_3\"] [,\"N_0_4\"] [,\"N_0_5\"] [,\"N_0_6\"] #>   <int> <int>       <int>      <int>      <int>      <int>      <int>      <int> #> 1    50    50           8          5          4         12         10          7 #> # ℹ 1 more variable: N[7:16] <int>"},{"path":"https://metacoglab.github.io/mRatio/reference/bias_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"Computes \\(\\textrm{meta-}\\Delta\\), index metacognitive bias. \\(\\textrm{meta-}\\Delta\\) distance meta_c average confidence criteria meta_c2_0 meta_c2_1. metacognitive_bias_draws add_metacognitive_bias_draws, parameters returned tidy tibble one row per posterior draw per response. metacognitive_bias_rvars add_metacognitive_bias_rvars, parameters returned posterior::rvars, one row per row newdata per response.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/bias_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"","code":"metacognitive_bias_draws(object, newdata, ..., by_response = TRUE)  add_metacognitive_bias_draws(newdata, object, ...)  metacognitive_bias_rvars(object, newdata, ..., by_response = TRUE)  add_metacognitive_bias_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/mRatio/reference/bias_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws tidybayes::epred_rvars by_response TRUE, compute metacognitive bias separately two type 1 responses. FALSE, compute un-weighted average two measures.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/bias_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"tibble containing posterior draws \\(\\textrm{meta-}\\Delta\\) following columns: .row: row newdata .chain, .iteration, .draw: metacognitive_bias_draws add_metacognitive_bias_draws, identifiers posterior sample response: type 1 response perceived stimulus presence metacognitive_bias: distance meta_c average confidence criteria meta_c2_{response}.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/bias_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of an index of metacognitive bias — metacognitive_bias_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.031 seconds (Warm-up) #> Chain 1:                0.025 seconds (Sampling) #> Chain 1:                0.056 seconds (Total) #> Chain 1:  newdata <- tidyr::tibble(.row = 1)  # compute metacognitive bias metacognitive_bias_draws(m, newdata) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row response .chain .iteration .draw metacognitive_bias #>    <int>    <int>  <int>      <int> <int>              <dbl> #>  1     1        0     NA         NA     1              0.981 #>  2     1        0     NA         NA     2              1.18  #>  3     1        0     NA         NA     3              1.10  #>  4     1        0     NA         NA     4              1.00  #>  5     1        0     NA         NA     5              0.875 #>  6     1        0     NA         NA     6              1.04  #>  7     1        0     NA         NA     7              1.01  #>  8     1        0     NA         NA     8              1.14  #>  9     1        0     NA         NA     9              1.04  #> 10     1        0     NA         NA    10              1.06  #> # ℹ 490 more rows add_metacognitive_bias_draws(newdata, m) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row response .chain .iteration .draw metacognitive_bias #>    <int>    <int>  <int>      <int> <int>              <dbl> #>  1     1        0     NA         NA     1              0.981 #>  2     1        0     NA         NA     2              1.18  #>  3     1        0     NA         NA     3              1.10  #>  4     1        0     NA         NA     4              1.00  #>  5     1        0     NA         NA     5              0.875 #>  6     1        0     NA         NA     6              1.04  #>  7     1        0     NA         NA     7              1.01  #>  8     1        0     NA         NA     8              1.14  #>  9     1        0     NA         NA     9              1.04  #> 10     1        0     NA         NA    10              1.06  #> # ℹ 490 more rows  # use posterior::rvar for increased efficiency metacognitive_bias_rvars(m, newdata) #> # A tibble: 2 × 3 #> # Groups:   .row, response [2] #>    .row response metacognitive_bias #>   <dbl>    <int>         <rvar[1d]> #> 1     1        0        1.02 ± 0.13 #> 2     1        1        0.97 ± 0.14 add_metacognitive_bias_rvars(newdata, m) #> # A tibble: 2 × 3 #> # Groups:   .row, response [2] #>    .row response metacognitive_bias #>   <dbl>    <int>         <rvar[1d]> #> 1     1        0        1.02 ± 0.13 #> 2     1        1        0.97 ± 0.14  # average over the two type 1 responses metacognitive_bias_draws(m, newdata, by_response = FALSE) #> # A tibble: 250 × 5 #> # Groups:   .row [1] #>     .row .chain .iteration .draw metacognitive_bias #>    <int>  <int>      <int> <int>              <dbl> #>  1     1     NA         NA     1              1.00  #>  2     1     NA         NA     2              1.04  #>  3     1     NA         NA     3              0.983 #>  4     1     NA         NA     4              0.927 #>  5     1     NA         NA     5              1.01  #>  6     1     NA         NA     6              1.07  #>  7     1     NA         NA     7              0.882 #>  8     1     NA         NA     8              1.00  #>  9     1     NA         NA     9              1.03  #> 10     1     NA         NA    10              1.14  #> # ℹ 240 more rows metacognitive_bias_rvars(m, newdata, by_response = FALSE) #> # A tibble: 1 × 2 #> # Groups:   .row [1] #>    .row metacognitive_bias #>   <dbl>         <rvar[1d]> #> 1     1       0.99 ± 0.098"},{"path":"https://metacoglab.github.io/mRatio/reference/cor_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"Generate correlation matrix -diagonal values equal r","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/cor_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"","code":"cor_matrix(r, nrow = 2)"},{"path":"https://metacoglab.github.io/mRatio/reference/cor_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"r correlation fill matrix -diagonals nrow number rows (columns) resulting matrix","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/cor_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"[nrow x nrow] matrix values along diagonal equal 1 values diagonal equal r","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/cor_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a correlation matrix with all off-diagonal values equal to r — cor_matrix","text":"","code":"cor_matrix(0, nrow = 3) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1  cor_matrix(-.5, nrow = 4) #>      [,1] [,2] [,3] [,4] #> [1,]  1.0 -0.5 -0.5 -0.5 #> [2,] -0.5  1.0 -0.5 -0.5 #> [3,] -0.5 -0.5  1.0 -0.5 #> [4,] -0.5 -0.5 -0.5  1.0"},{"path":"https://metacoglab.github.io/mRatio/reference/cov_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a covariance matrix. — cov_matrix","title":"Generate a covariance matrix. — cov_matrix","text":"Generate covariance matrix.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/cov_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a covariance matrix. — cov_matrix","text":"","code":"cov_matrix(S, OMEGA)"},{"path":"https://metacoglab.github.io/mRatio/reference/cov_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a covariance matrix. — cov_matrix","text":"S vector standard deviations OMEGA correlation matrix","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/cov_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a covariance matrix. — cov_matrix","text":"\\(N \\times N\\) covariance matrix, N = length(S).","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/cov_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a covariance matrix. — cov_matrix","text":"","code":"sds <- c(1, 2) corrs <- matrix(c(1, .5, .5, 1), nrow = 2) cov_matrix(sds, corrs) #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    4"},{"path":"https://metacoglab.github.io/mRatio/reference/epred_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of joint response probabilities — epred_draws_metad","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"Given data frame meta-d' model, adds estimates joint type 1 type 2 response probabilities. epred_draws_metad add_epred_draws_metad, estimates returned tidy tibble one row per posterior draw. epred_rvars_metad add_epred_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/epred_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"","code":"epred_draws_metad(object, newdata, ...)  add_epred_draws_metad(newdata, object, ...)  epred_rvars_metad(object, newdata, ...)  add_epred_rvars_metad(newdata, object, ...)"},{"path":"https://metacoglab.github.io/mRatio/reference/epred_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_epred_draws tidybayes::add_epred_rvars","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/epred_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: epred_draws_metad, identifiers posterior sample stimulus, joint_response, response, confidence: identifiers response type .epred: probability type 1 type 2 response given stimulus, \\(P(R, C \\;\\vert\\; S)\\)","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/epred_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of joint response probabilities — epred_draws_metad","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1: Rejecting initial value: #> Chain 1:   Gradient evaluated at the initial value is not finite. #> Chain 1:   Stan can't start sampling from this initial value. #> Chain 1:  #> Chain 1: Gradient evaluation took 1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.028 seconds (Warm-up) #> Chain 1:                0.024 seconds (Sampling) #> Chain 1:                0.052 seconds (Total) #> Chain 1:  #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # obtain model predictions epred_draws_metad(m, newdata) #> # A tibble: 4,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>  <dbl>  <int>      <int> #>  1     1        0              1        0          4 0.0863     NA         NA #>  2     1        0              1        0          4 0.173      NA         NA #>  3     1        0              1        0          4 0.103      NA         NA #>  4     1        0              1        0          4 0.148      NA         NA #>  5     1        0              1        0          4 0.127      NA         NA #>  6     1        0              1        0          4 0.198      NA         NA #>  7     1        0              1        0          4 0.143      NA         NA #>  8     1        0              1        0          4 0.151      NA         NA #>  9     1        0              1        0          4 0.122      NA         NA #> 10     1        0              1        0          4 0.0978     NA         NA #> # ℹ 3,990 more rows #> # ℹ 1 more variable: .draw <int> add_epred_draws_metad(newdata, m) #> # A tibble: 4,000 × 9 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence .epred .chain .iteration #>    <int>    <int>          <int>    <int>      <dbl>  <dbl>  <int>      <int> #>  1     1        0              1        0          4 0.0863     NA         NA #>  2     1        0              1        0          4 0.173      NA         NA #>  3     1        0              1        0          4 0.103      NA         NA #>  4     1        0              1        0          4 0.148      NA         NA #>  5     1        0              1        0          4 0.127      NA         NA #>  6     1        0              1        0          4 0.198      NA         NA #>  7     1        0              1        0          4 0.143      NA         NA #>  8     1        0              1        0          4 0.151      NA         NA #>  9     1        0              1        0          4 0.122      NA         NA #> 10     1        0              1        0          4 0.0978     NA         NA #> # ℹ 3,990 more rows #> # ℹ 1 more variable: .draw <int>  # obtain model predictions (posterior::rvar) epred_rvars_metad(m, newdata) #> # A tibble: 16 × 6 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence         .epred #>    <int>    <int>          <int>    <int>      <dbl>     <rvar[1d]> #>  1     1        0              1        0          4  0.140 ± 0.045 #>  2     1        0              2        0          3  0.186 ± 0.048 #>  3     1        0              3        0          2  0.278 ± 0.049 #>  4     1        0              4        0          1  0.169 ± 0.046 #>  5     1        0              5        1          1  0.118 ± 0.047 #>  6     1        0              6        1          2  0.067 ± 0.023 #>  7     1        0              7        1          3  0.021 ± 0.011 #>  8     1        0              8        1          4  0.022 ± 0.015 #>  9     1        1              1        0          4  0.020 ± 0.013 #> 10     1        1              2        0          3  0.050 ± 0.020 #> 11     1        1              3        0          2  0.133 ± 0.035 #> 12     1        1              4        0          1  0.134 ± 0.041 #> 13     1        1              5        1          1  0.213 ± 0.048 #> 14     1        1              6        1          2  0.202 ± 0.048 #> 15     1        1              7        1          3  0.093 ± 0.035 #> 16     1        1              8        1          4  0.155 ± 0.046 add_epred_rvars_metad(newdata, m) #> # A tibble: 16 × 6 #> # Groups:   .row, stimulus, joint_response, response, confidence [16] #>     .row stimulus joint_response response confidence         .epred #>    <int>    <int>          <int>    <int>      <dbl>     <rvar[1d]> #>  1     1        0              1        0          4  0.140 ± 0.045 #>  2     1        0              2        0          3  0.186 ± 0.048 #>  3     1        0              3        0          2  0.278 ± 0.049 #>  4     1        0              4        0          1  0.169 ± 0.046 #>  5     1        0              5        1          1  0.118 ± 0.047 #>  6     1        0              6        1          2  0.067 ± 0.023 #>  7     1        0              7        1          3  0.021 ± 0.011 #>  8     1        0              8        1          4  0.022 ± 0.015 #>  9     1        1              1        0          4  0.020 ± 0.013 #> 10     1        1              2        0          3  0.050 ± 0.020 #> 11     1        1              3        0          2  0.133 ± 0.035 #> 12     1        1              4        0          1  0.134 ± 0.041 #> 13     1        1              5        1          1  0.213 ± 0.048 #> 14     1        1              6        1          2  0.202 ± 0.048 #> 15     1        1              7        1          3  0.093 ± 0.035 #> 16     1        1              8        1          4  0.155 ± 0.046"},{"path":"https://metacoglab.github.io/mRatio/reference/fit_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit the meta-d' model using brms package — fit_metad","title":"Fit the meta-d' model using brms package — fit_metad","text":"function wrapper around brms::brm() using custom family meta-d' model.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/fit_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit the meta-d' model using brms package — fit_metad","text":"","code":"fit_metad(   formula,   data,   ...,   aggregate = TRUE,   .stimulus = \"stimulus\",   .response = \"response\",   .confidence = \"confidence\",   .joint_response = \"joint_response\",   K = NULL,   distribution = \"normal\",   metac_absolute = TRUE,   stanvars = NULL,   categorical = FALSE )"},{"path":"https://metacoglab.github.io/mRatio/reference/fit_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit the meta-d' model using brms package — fit_metad","text":"formula model formula parameters metad brms family. display parameter names model K confidence levels, use metad(K). data tibble containing data fit model. aggregate==TRUE, data one row per observation columns stimulus, response, confidence, variables formula aggregate==FALSE, aggregated one row per cell design matrix, joint type 1/type 2 response counts matrix column (see aggregate_metad()). ... Additional parameters passed brm function. aggregate TRUE, automatically aggregate data variables included formula using aggregate_metad(). Otherwise, data already aggregated. .stimulus name \"stimulus\" column .response name \"response\" column .confidence name \"confidence\" column .joint_response name \"joint_response\" column K number confidence levels. default, estimated data. distribution noise distribution use signal detection model. default, uses normal distribution mean parameterized dprime. metac_absolute TRUE, fix type 2 criterion equal type 1 criterion. Otherwise, equate criteria relatively metac/metadprime = c/dprime. stanvars Additional stanvars pass model code, example define alternative distribution custom model prior (see brms::stanvar()). categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/fit_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit the meta-d' model using brms package — fit_metad","text":"","code":"# fit a basic model on simulated data # running few iterations so example runs quickly, use more in practice fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.8e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.029 seconds (Warm-up) #> Chain 1:                0.031 seconds (Sampling) #> Chain 1:                0.06 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  Family: metad__4__normal__absolute__multinomial  #>   Links: mu = log  #> Formula: N ~ 1  #>    Data: data.aggregated (Number of observations: 1)  #>   Draws: 1 chains, each with iter = 500; warmup = 250; thin = 1; #>          total post-warmup draws = 250 #>  #> Regression Coefficients: #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept    -1.97      2.08    -7.37     0.52 1.00      123       96 #>  #> Further Distributional Parameters: #>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> dprime              0.76      0.26     0.27     1.24 1.02      309      104 #> c                  -0.03      0.13    -0.26     0.22 1.02      190      153 #> metac2zero1diff     0.47      0.08     0.33     0.65 1.00      206      154 #> metac2zero2diff     0.23      0.08     0.11     0.39 1.00      327      206 #> metac2zero3diff     0.69      0.16     0.44     1.05 1.01      433      208 #> metac2one1diff      0.58      0.10     0.42     0.80 1.02      133      186 #> metac2one2diff      0.58      0.13     0.37     0.89 1.00      437      230 #> metac2one3diff      0.52      0.17     0.21     0.89 1.00      286      153 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://metacoglab.github.io/mRatio/reference/get_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the R function for the model's underlying distribution functions — get_dist","title":"Get the R function for the model's underlying distribution functions — get_dist","text":"Get R function model's underlying distribution functions","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the R function for the model's underlying distribution functions — get_dist","text":"","code":"get_dist(model, fun = \"lcdf\")"},{"path":"https://metacoglab.github.io/mRatio/reference/get_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the R function for the model's underlying distribution functions — get_dist","text":"model brms model get distribution functions fun distribution function return.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the R function for the model's underlying distribution functions — get_dist","text":"R function name distribution_{fun}.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_dist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the R function for the model's underlying distribution functions — get_dist","text":"throw error function exist","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_ll.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the likelihood parameterization in model — get_ll","title":"Get the likelihood parameterization in model — get_ll","text":"Get likelihood parameterization model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_ll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the likelihood parameterization in model — get_ll","text":"","code":"get_ll(model)"},{"path":"https://metacoglab.github.io/mRatio/reference/get_ll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the likelihood parameterization in model — get_ll","text":"model brms model get parameterization ","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_ll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the likelihood parameterization in model — get_ll","text":"character vector, either \"multinomial\" \"categorical\".","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_metac.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the parameterization of meta_c in model — get_metac","title":"Get the parameterization of meta_c in model — get_metac","text":"Get parameterization meta_c model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_metac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the parameterization of meta_c in model — get_metac","text":"","code":"get_metac(model)"},{"path":"https://metacoglab.github.io/mRatio/reference/get_metac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the parameterization of meta_c in model — get_metac","text":"model brms model get parameterization ","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_metac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the parameterization of meta_c in model — get_metac","text":"character vector, either \"absolute\" \"relative\".","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_stimulus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the stimulus variable in model — get_stimulus","title":"Get the stimulus variable in model — get_stimulus","text":"Get stimulus variable model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_stimulus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the stimulus variable in model — get_stimulus","text":"","code":"get_stimulus(model)"},{"path":"https://metacoglab.github.io/mRatio/reference/get_stimulus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the stimulus variable in model — get_stimulus","text":"model brms model get variable ","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/get_stimulus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the stimulus variable in model — get_stimulus","text":"character vector.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/linpred_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"Given data frame meta-d' model, adds estimates model parameters. linpred_draws_metad add_linpred_draws_metad, parameters returned tidy tibble one row per posterior draw. linpred_rvars_metad add_linpred_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/linpred_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"","code":"linpred_draws_metad(object, newdata, ..., pivot_longer = FALSE)  add_linpred_draws_metad(newdata, object, ..., pivot_longer = FALSE)  linpred_rvars_metad(object, newdata, ..., pivot_longer = FALSE)  add_linpred_rvars_metad(newdata, object, pivot_longer = FALSE)"},{"path":"https://metacoglab.github.io/mRatio/reference/linpred_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_linpred_draws tidybayes::add_linpred_rvars pivot_longer Return draws long format? TRUE, resulting data frame one row per posterior draw per model parameter FALSE (default), resulting data frame one row per posterior draw","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/linpred_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: linpred_draws_metad, identifiers posterior sample .variable, .value: pivot_longer=TRUE, .variable identifies different meta-d' model parameters .value stores posterior samples M, dprime, c, meta_dprime, meta_c, meta_c2_0_<k>, meta_c2_1_<k>: pivot_longer=FALSE, posterior samples meta-d' model parameters","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/linpred_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of meta-d' model parameters — linpred_draws_metad","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.8e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.032 seconds (Warm-up) #> Chain 1:                0.021 seconds (Sampling) #> Chain 1:                0.053 seconds (Total) #> Chain 1:  newdata <- tidyr::tibble(.row = 1)  # obtain model parameters (wide format) linpred_draws_metad(m, newdata) #> # A tibble: 250 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime      c meta_dprime meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>  <dbl>       <dbl>  <dbl> #>  1     1     NA         NA     1 0.777  1.18  -0.109       0.914 -0.109 #>  2     1     NA         NA     2 0.305  1.27  -0.172       0.387 -0.109 #>  3     1     NA         NA     3 0.741  1.19  -0.230       0.883 -0.109 #>  4     1     NA         NA     4 0.337  1.25  -0.413       0.420 -0.109 #>  5     1     NA         NA     5 0.362  1.31  -0.439       0.475 -0.109 #>  6     1     NA         NA     6 0.258  1.57  -0.449       0.406 -0.109 #>  7     1     NA         NA     7 0.274  1.61  -0.250       0.440 -0.109 #>  8     1     NA         NA     8 1.09   0.721 -0.167       0.783 -0.109 #>  9     1     NA         NA     9 1.30   0.623 -0.266       0.809 -0.109 #> 10     1     NA         NA    10 0.438  1.16  -0.182       0.508 -0.109 #> # ℹ 240 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl> add_linpred_draws_metad(newdata, m) #> # A tibble: 250 × 15 #> # Groups:   .row [1] #>     .row .chain .iteration .draw     M dprime      c meta_dprime meta_c #>    <int>  <int>      <int> <int> <dbl>  <dbl>  <dbl>       <dbl>  <dbl> #>  1     1     NA         NA     1 0.777  1.18  -0.109       0.914 -0.109 #>  2     1     NA         NA     2 0.305  1.27  -0.172       0.387 -0.109 #>  3     1     NA         NA     3 0.741  1.19  -0.230       0.883 -0.109 #>  4     1     NA         NA     4 0.337  1.25  -0.413       0.420 -0.109 #>  5     1     NA         NA     5 0.362  1.31  -0.439       0.475 -0.109 #>  6     1     NA         NA     6 0.258  1.57  -0.449       0.406 -0.109 #>  7     1     NA         NA     7 0.274  1.61  -0.250       0.440 -0.109 #>  8     1     NA         NA     8 1.09   0.721 -0.167       0.783 -0.109 #>  9     1     NA         NA     9 1.30   0.623 -0.266       0.809 -0.109 #> 10     1     NA         NA    10 0.438  1.16  -0.182       0.508 -0.109 #> # ℹ 240 more rows #> # ℹ 6 more variables: meta_c2_0_1 <dbl>, meta_c2_0_2 <dbl>, meta_c2_0_3 <dbl>, #> #   meta_c2_1_1 <dbl>, meta_c2_1_2 <dbl>, meta_c2_1_3 <dbl>  # obtain model parameters (long format) linpred_draws_metad(m, newdata, pivot_longer = TRUE) #> # A tibble: 2,750 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable   .value #>    <int>  <int>      <int> <int> <chr>        <dbl> #>  1     1     NA         NA     1 M            0.777 #>  2     1     NA         NA     1 dprime       1.18  #>  3     1     NA         NA     1 c           -0.109 #>  4     1     NA         NA     1 meta_dprime  0.914 #>  5     1     NA         NA     1 meta_c      -0.109 #>  6     1     NA         NA     1 meta_c2_0_1 -0.342 #>  7     1     NA         NA     1 meta_c2_0_2 -1.01  #>  8     1     NA         NA     1 meta_c2_0_3 -1.54  #>  9     1     NA         NA     1 meta_c2_1_1  0.382 #> 10     1     NA         NA     1 meta_c2_1_2  1.03  #> # ℹ 2,740 more rows add_linpred_draws_metad(newdata, m, pivot_longer = TRUE) #> # A tibble: 2,750 × 6 #> # Groups:   .row, .variable [11] #>     .row .chain .iteration .draw .variable   .value #>    <int>  <int>      <int> <int> <chr>        <dbl> #>  1     1     NA         NA     1 M            0.777 #>  2     1     NA         NA     1 dprime       1.18  #>  3     1     NA         NA     1 c           -0.109 #>  4     1     NA         NA     1 meta_dprime  0.914 #>  5     1     NA         NA     1 meta_c      -0.109 #>  6     1     NA         NA     1 meta_c2_0_1 -0.342 #>  7     1     NA         NA     1 meta_c2_0_2 -1.01  #>  8     1     NA         NA     1 meta_c2_0_3 -1.54  #>  9     1     NA         NA     1 meta_c2_1_1  0.382 #> 10     1     NA         NA     1 meta_c2_1_2  1.03  #> # ℹ 2,740 more rows  # obtain model parameters (wide format, posterior::rvar) linpred_rvars_metad(m, newdata) #> # A tibble: 1 × 12 #> # Groups:   .row [1] #>    .row            M      dprime             c  meta_dprime        meta_c #>   <dbl>   <rvar[1d]>  <rvar[1d]>    <rvar[1d]>   <rvar[1d]>    <rvar[1d]> #> 1     1  0.52 ± 0.39  1.1 ± 0.24  -0.13 ± 0.13  0.52 ± 0.36  -0.13 ± 0.13 #> # ℹ 6 more variables: meta_c2_0_1 <rvar[1d]>, meta_c2_0_2 <rvar[1d]>, #> #   meta_c2_0_3 <rvar[1d]>, meta_c2_1_1 <rvar[1d]>, meta_c2_1_2 <rvar[1d]>, #> #   meta_c2_1_3 <rvar[1d]> add_linpred_rvars_metad(newdata, m) #> # A tibble: 1 × 12 #> # Groups:   .row [1] #>    .row            M      dprime             c  meta_dprime        meta_c #>   <dbl>   <rvar[1d]>  <rvar[1d]>    <rvar[1d]>   <rvar[1d]>    <rvar[1d]> #> 1     1  0.52 ± 0.39  1.1 ± 0.24  -0.13 ± 0.13  0.52 ± 0.36  -0.13 ± 0.13 #> # ℹ 6 more variables: meta_c2_0_1 <rvar[1d]>, meta_c2_0_2 <rvar[1d]>, #> #   meta_c2_0_3 <rvar[1d]>, meta_c2_1_1 <rvar[1d]>, meta_c2_1_2 <rvar[1d]>, #> #   meta_c2_1_3 <rvar[1d]>  # obtain model parameters (long format, posterior::rvar) linpred_rvars_metad(m, newdata, pivot_longer = TRUE) #> # A tibble: 11 × 3 #> # Groups:   .row, .variable [11] #>     .row .variable          .value #>    <dbl> <chr>          <rvar[1d]> #>  1     1 M             0.52 ± 0.39 #>  2     1 dprime        1.05 ± 0.24 #>  3     1 c            -0.13 ± 0.13 #>  4     1 meta_dprime   0.52 ± 0.36 #>  5     1 meta_c       -0.13 ± 0.13 #>  6     1 meta_c2_0_1  -0.43 ± 0.13 #>  7     1 meta_c2_0_2  -1.04 ± 0.15 #>  8     1 meta_c2_0_3  -1.61 ± 0.17 #>  9     1 meta_c2_1_1   0.32 ± 0.13 #> 10     1 meta_c2_1_2   0.79 ± 0.15 #> 11     1 meta_c2_1_3   1.40 ± 0.18 add_linpred_rvars_metad(newdata, m, pivot_longer = TRUE) #> # A tibble: 11 × 3 #> # Groups:   .row, .variable [11] #>     .row .variable          .value #>    <dbl> <chr>          <rvar[1d]> #>  1     1 M             0.52 ± 0.39 #>  2     1 dprime        1.05 ± 0.24 #>  3     1 c            -0.13 ± 0.13 #>  4     1 meta_dprime   0.52 ± 0.36 #>  5     1 meta_c       -0.13 ± 0.13 #>  6     1 meta_c2_0_1  -0.43 ± 0.13 #>  7     1 meta_c2_0_2  -1.04 ± 0.15 #>  8     1 meta_c2_0_3  -1.61 ± 0.17 #>  9     1 meta_c2_1_1   0.32 ± 0.13 #> 10     1 meta_c2_1_2   0.79 ± 0.15 #> 11     1 meta_c2_1_3   1.40 ± 0.18"},{"path":"https://metacoglab.github.io/mRatio/reference/log_lik_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a function to calculate the log likelihood of the metad' model — log_lik_metad","title":"Generate a function to calculate the log likelihood of the metad' model — log_lik_metad","text":"Generate function calculate log likelihood metad' model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/log_lik_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a function to calculate the log likelihood of the metad' model — log_lik_metad","text":"","code":"log_lik_metad(i, prep)"},{"path":"https://metacoglab.github.io/mRatio/reference/log_lik_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a function to calculate the log likelihood of the metad' model — log_lik_metad","text":"observation index prep object containing data model draws","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/log_lik_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a function to calculate the log likelihood of the metad' model — log_lik_metad","text":"[D x K*4] array containing posterior samples joint probability type 1/type 2 response, D number posterior draws, N number rows data, K number confidence levels.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/lp_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the log probability simplex of the metad' model — lp_metad","title":"Calculate the log probability simplex of the metad' model — lp_metad","text":"Calculate log probability simplex metad' model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/lp_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the log probability simplex of the metad' model — lp_metad","text":"","code":"lp_metad(i, prep)"},{"path":"https://metacoglab.github.io/mRatio/reference/lp_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the log probability simplex of the metad' model — lp_metad","text":"observation index prep object containing data model draws","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/lp_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the log probability simplex of the metad' model — lp_metad","text":"vector joint type 1/type 2 response probabilties observation prep","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/mRatio-package.html","id":null,"dir":"Reference","previous_headings":"","what":"mRatio: Fit the meta-d' model of confidence ratings using `brms` — mRatio-package","title":"mRatio: Fit the meta-d' model of confidence ratings using `brms` — mRatio-package","text":"Implementation `brms` custom family meta-d\\' model (Maniscalco & Lau, 2012).","code":""},{"path":[]},{"path":"https://metacoglab.github.io/mRatio/reference/mRatio-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"mRatio: Fit the meta-d' model of confidence ratings using `brms` — mRatio-package","text":"Maintainer: Kevin O'Neill kevin.o'neill@ucl.ac.uk","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/mean_conf_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of mean confidence — mean_confidence_draws","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"Computes posterior mean confidence conditional stimulus response (\\(\\mathbb{E}[C \\;\\vert\\; S=s,R=r]\\)), stimulus (averaging responses, \\(\\mathbb{E}[C \\;\\vert\\; S=s]\\)), response (averaging stimuli, \\(\\mathbb{E}[C \\;\\vert\\; R=r]\\)), neither (averaging stimuli responses, \\(\\mathbb{E}[C]\\)). mean_confidence_draws add_mean_confidence_draws, estimates returned tidy tibble one row per posterior draw, stimulus, response. mean_confidence_rvars add_mean_confidence_rvars, estimates returned posterior::rvars, one row per row newdata. add_mean_confidence_draws alias mean_confidence_draws argument order swapped.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/mean_conf_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"","code":"mean_confidence_draws(   object,   newdata,   ...,   by_stimulus = TRUE,   by_response = TRUE )  add_mean_confidence_draws(newdata, object, ...)  mean_confidence_rvars(   object,   newdata,   ...,   by_stimulus = TRUE,   by_response = TRUE )  add_mean_confidence_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/mRatio/reference/mean_conf_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments tidybayes::epred_draws tidybayes::epred_rvars by_stimulus TRUE, predict mean confidence separately stimulus. Otherwise, predict mean confidence averaging stimuli. by_response TRUE, predict mean confidence separately response Otherwise, predict mean confidence averaging responses.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/mean_conf_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"tibble containing posterior draws mean confidence following columns: .row: row newdata .chain, .iteration, .draw: mean_confidence_draws add_mean_confidence_draws, identifiers posterior sample stimulus: indicator stimulus presence (by_stimulus==TRUE) response: indicator type 1 response (by_response==TRUE) .epred: predicted mean confidence","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/mean_conf_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of mean confidence — mean_confidence_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.032 seconds (Warm-up) #> Chain 1:                0.028 seconds (Sampling) #> Chain 1:                0.06 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # compute mean confidence by stimulus and response mean_confidence_draws(m, newdata) #> # A tibble: 1,000 × 7 #> # Groups:   .row, stimulus, response [4] #>     .row .chain .iteration .draw stimulus response .epred #>    <int>  <int>      <int> <int>    <int>    <int>  <dbl> #>  1     1     NA         NA     1        0        0   2.21 #>  2     1     NA         NA     1        0        1   1.98 #>  3     1     NA         NA     1        1        0   1.78 #>  4     1     NA         NA     1        1        1   2.42 #>  5     1     NA         NA     2        0        0   2.23 #>  6     1     NA         NA     2        0        1   1.76 #>  7     1     NA         NA     2        1        0   1.43 #>  8     1     NA         NA     2        1        1   2.48 #>  9     1     NA         NA     3        0        0   2.26 #> 10     1     NA         NA     3        0        1   2.01 #> # ℹ 990 more rows add_mean_confidence_draws(newdata, m) #> # A tibble: 1,000 × 7 #> # Groups:   .row, stimulus, response [4] #>     .row .chain .iteration .draw stimulus response .epred #>    <int>  <int>      <int> <int>    <int>    <int>  <dbl> #>  1     1     NA         NA     1        0        0   2.21 #>  2     1     NA         NA     1        0        1   1.98 #>  3     1     NA         NA     1        1        0   1.78 #>  4     1     NA         NA     1        1        1   2.42 #>  5     1     NA         NA     2        0        0   2.23 #>  6     1     NA         NA     2        0        1   1.76 #>  7     1     NA         NA     2        1        0   1.43 #>  8     1     NA         NA     2        1        1   2.48 #>  9     1     NA         NA     3        0        0   2.26 #> 10     1     NA         NA     3        0        1   2.01 #> # ℹ 990 more rows  # compute mean confidence by stimulus mean_confidence_draws(m, newdata, by_response = FALSE) #> # A tibble: 500 × 6 #> # Groups:   .row, stimulus [2] #>     .row .chain .iteration .draw stimulus .epred #>    <int>  <int>      <int> <int>    <int>  <dbl> #>  1     1     NA         NA     1        0   2.14 #>  2     1     NA         NA     1        1   2.25 #>  3     1     NA         NA     2        0   2.14 #>  4     1     NA         NA     2        1   2.06 #>  5     1     NA         NA     3        0   2.20 #>  6     1     NA         NA     3        1   2.13 #>  7     1     NA         NA     4        0   2.15 #>  8     1     NA         NA     4        1   2.06 #>  9     1     NA         NA     5        0   2.09 #> 10     1     NA         NA     5        1   2.08 #> # ℹ 490 more rows  # compute mean confidence by response mean_confidence_draws(m, newdata, by_stimulus = FALSE) #> # A tibble: 500 × 6 #> # Groups:   .row, response [2] #>     .row .chain .iteration .draw response .epred #>    <int>  <int>      <int> <int>    <int>  <dbl> #>  1     1     NA         NA     1        0   2.09 #>  2     1     NA         NA     1        1   2.29 #>  3     1     NA         NA     2        0   1.96 #>  4     1     NA         NA     2        1   2.31 #>  5     1     NA         NA     3        0   2.14 #>  6     1     NA         NA     3        1   2.20 #>  7     1     NA         NA     4        0   2.11 #>  8     1     NA         NA     4        1   2.09 #>  9     1     NA         NA     5        0   1.94 #> 10     1     NA         NA     5        1   2.30 #> # ℹ 490 more rows  # compute mean confidence averaging over stimuli and responses mean_confidence_draws(m, newdata, by_stimulus = FALSE, by_response = FALSE) #> # A tibble: 250 × 5 #> # Groups:   .row [1] #>     .row .chain .iteration .draw .epred #>    <int>  <int>      <int> <int>  <dbl> #>  1     1     NA         NA     1   2.20 #>  2     1     NA         NA     2   2.10 #>  3     1     NA         NA     3   2.16 #>  4     1     NA         NA     4   2.10 #>  5     1     NA         NA     5   2.08 #>  6     1     NA         NA     6   2.12 #>  7     1     NA         NA     7   2.28 #>  8     1     NA         NA     8   2.21 #>  9     1     NA         NA     9   2.14 #> 10     1     NA         NA    10   2.21 #> # ℹ 240 more rows"},{"path":"https://metacoglab.github.io/mRatio/reference/metacognitive_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Given the distances between successive confidence thresholds, calculate the average of the cumulative distances to 0. — metacognitive_bias","title":"Given the distances between successive confidence thresholds, calculate the average of the cumulative distances to 0. — metacognitive_bias","text":"Given distances successive confidence thresholds, calculate average cumulative distances 0.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metacognitive_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given the distances between successive confidence thresholds, calculate the average of the cumulative distances to 0. — metacognitive_bias","text":"","code":"metacognitive_bias(..., rvar = FALSE)"},{"path":"https://metacoglab.github.io/mRatio/reference/metacognitive_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given the distances between successive confidence thresholds, calculate the average of the cumulative distances to 0. — metacognitive_bias","text":"... series distances confidence thresholds rvar TRUE, use posterior::rvar_sum place sum","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metad.html","id":null,"dir":"Reference","previous_headings":"","what":"brms family for the metad' model — metad","title":"brms family for the metad' model — metad","text":"brms family metad' model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"brms family for the metad' model — metad","text":"","code":"metad(K, distribution = \"normal\", metac_absolute = TRUE, categorical = FALSE)"},{"path":"https://metacoglab.github.io/mRatio/reference/metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"brms family for the metad' model — metad","text":"K number confidence levels distribution noise distribution use signal detection model metac_absolute TRUE, fix type 2 criterion equal type 1 criterion. Otherwise, equate criteria relatively $$\\frac{\\textrm{meta-}c}{\\textrm{meta-}d'} = \\frac{c}{d'}$$ categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"brms family for the metad' model — metad","text":"brms family metad' model \\(K\\) confidence levels","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"brms family for the metad' model — metad","text":"","code":"# create a family using the normal distribution and 3 levels of confidence metad(3) #>  #> Custom family: metad__3__normal__absolute__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2one1diff, metac2one2diff  #>   # create a family with meta_c = M * c metad(3, metac_absolute = FALSE) #>  #> Custom family: metad__3__normal__relative__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2one1diff, metac2one2diff  #>   # create a family with an alternative distribution # note: cumulative distribution functions must be defined # in R and in Stan using [brms::stanvar()] metad(4, distribution = \"gumbel_min\") #>  #> Custom family: metad__4__gumbel_min__absolute__multinomial  #> Link function: log  #> Parameters: mu, dprime, c, metac2zero1diff, metac2zero2diff, metac2zero3diff, metac2one1diff, metac2one2diff, metac2one3diff  #>"},{"path":"https://metacoglab.github.io/mRatio/reference/metad_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"Generate (log) probability simplex joint type 1/type 2 responses","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metad_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"","code":"metad_pmf(   stimulus,   dprime,   c,   meta_dprime,   meta_c,   meta_c2_0,   meta_c2_1,   lcdf = normal_lcdf,   lccdf = normal_lccdf,   log = FALSE )"},{"path":"https://metacoglab.github.io/mRatio/reference/metad_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"stimulus stimulus (0 1) dprime type 1 sensitivity c type 1 response criterion meta_dprime type 2 sensitivity meta_c type 1 criteriom generating confidence ratings meta_c2_0 type 2 response criteria \"0\" responses, indexed increasing confidence levels meta_c2_1 type 2 response criteria \"1\" responses, indexed increasing confidence levels lcdf log cumulative distribution function underlying distribution metad' model. default, uses normal distribution standard deviation 1. lccdf log complement cumulative distribution function underlying distribution metad' model. default, uses normal distribution standard deviation 1. log TRUE, return log probabilities instead probabilities","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metad_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"probability simplex $$\\begin{bmatrix} P(R=0, C=K \\vert S=0), \\ldots, P(R=0, C=1 \\vert S=0), P(R=0, C=1 \\vert S=1), \\ldots, P(R=1, C=1 \\vert S=1)\\end{bmatrix}$$ response \\(R\\) confidence \\(C\\) given stimulus \\(S\\), defined meta-d' model.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/metad_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate (log) probability simplex over the joint type 1/type 2 responses — metad_pmf","text":"","code":"metad_pmf(   stimulus = 0, dprime = 2, c = .5, meta_dprime = 1, meta_c = .5,   meta_c2_0 = c(0, -.5), meta_c2_1 = c(1, 1.5) ) #> [1] 0.554584077 0.212364065 0.166244657 0.038675753 0.018551730 0.009579718"},{"path":"https://metacoglab.github.io/mRatio/reference/normal_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal cumulative distribution functions — normal_lcdf","title":"Normal cumulative distribution functions — normal_lcdf","text":"Normal cumulative distribution functions","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/normal_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal cumulative distribution functions — normal_lcdf","text":"","code":"normal_lcdf(x, mu)  normal_lccdf(x, mu)"},{"path":"https://metacoglab.github.io/mRatio/reference/normal_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal cumulative distribution functions — normal_lcdf","text":"x quantile evaluate l(c)cdf mu mean normal distribution","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/normal_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal cumulative distribution functions — normal_lcdf","text":"\\(log(P(X < x))\\) (normal_lcdf) \\(log(P(X > x))\\) (normal_lccdf) \\(X\\) sampled normal distribution mean mu standard deviation \\(1\\)","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/normal_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal cumulative distribution functions — normal_lcdf","text":"","code":"normal_lcdf(0, mu = 1) #> [1] -1.841022 normal_lccdf(0, mu = 1) #> [1] -0.1727538"},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_epred_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate posterior predictions for the metad' model — posterior_epred_metad","title":"Generate posterior predictions for the metad' model — posterior_epred_metad","text":"Generate posterior predictions metad' model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_epred_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate posterior predictions for the metad' model — posterior_epred_metad","text":"","code":"posterior_epred_metad(prep)"},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_epred_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate posterior predictions for the metad' model — posterior_epred_metad","text":"prep object containing data model draws","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_epred_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate posterior predictions for the metad' model — posterior_epred_metad","text":"[D x N x K*4] array containing posterior samples joint probability type 1/type 2 response, D number posterior draws, N number rows data, K number confidence levels.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_predict_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate posterior predictions from the metad' model — posterior_predict_metad","title":"Simulate posterior predictions from the metad' model — posterior_predict_metad","text":"Simulate posterior predictions metad' model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_predict_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate posterior predictions from the metad' model — posterior_predict_metad","text":"","code":"posterior_predict_metad(i, prep, ...)"},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_predict_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate posterior predictions from the metad' model — posterior_predict_metad","text":"observation index prep object containing data model draws ... Additional arguments. currently used.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/posterior_predict_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate posterior predictions from the metad' model — posterior_predict_metad","text":"[D x K*4] array containing posterior samples counts joint type 1/type 2 responses, D number posterior draws, N number rows data, K number confidence levels.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/predicted_draws_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior predictions of joint responses — predicted_draws_metad","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"Given data frame meta-d' model, adds predictions joint type 1 type 2 responses predicted_draws_metad add_predicted_draws_metad, predictions returned tidy tibble one row per posterior draw. predicted_rvars_metad add_predicted_rvars_metad, parameters returned posterior::rvars, one row per row newdata.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/predicted_draws_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"","code":"predicted_draws_metad(object, newdata, ...)  add_predicted_draws_metad(newdata, object, ...)  predicted_rvars_metad(object, newdata, ...)  add_predicted_rvars_metad(newdata, object, ...)"},{"path":"https://metacoglab.github.io/mRatio/reference/predicted_draws_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional arguments passed tidybayes::add_predicted_draws tidybayes::add_predicted_rvars","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/predicted_draws_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"tibble containing posterior draws model parameters following columns: .row: row newdata .chain, .iteration, .draw: predicted_draws_metad, identifiers posterior sample stimulus, joint_response, response, confidence: identifiers response type .prediction: predicted type 1 type 2 responses given stimulus","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/predicted_draws_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior predictions of joint responses — predicted_draws_metad","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1: Rejecting initial value: #> Chain 1:   Gradient evaluated at the initial value is not finite. #> Chain 1:   Stan can't start sampling from this initial value. #> Chain 1:  #> Chain 1: Gradient evaluation took 9e-06 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.039 seconds (Warm-up) #> Chain 1:                0.054 seconds (Sampling) #> Chain 1:                0.093 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess  # obtain model predictions predicted_draws_metad(m, m$data) add_predicted_draws_metad(m$data, m)  # obtain model predictions (posterior::rvar) predicted_rvars_metad(m, m$data) #> # A tibble: 16 × 7 #> # Groups:   .row, N, stimulus, joint_response, response, confidence [16] #>     .row N[,\"N_0_1\"] stimulus joint_response response confidence  .prediction #>    <int>       <int>    <int>          <int>    <int>      <dbl>   <rvar[1d]> #>  1     1           9        0              1        0          4   8.13 ± 3.6 #>  2     1           9        0              2        0          3   8.07 ± 3.6 #>  3     1           9        0              3        0          2  11.45 ± 3.6 #>  4     1           9        0              4        0          1  10.01 ± 4.0 #>  5     1           9        0              5        1          1   5.65 ± 3.2 #>  6     1           9        0              6        1          2   4.04 ± 2.3 #>  7     1           9        0              7        1          3   1.87 ± 1.5 #>  8     1           9        0              8        1          4   0.78 ± 1.0 #>  9     1           9        1              1        0          4   1.30 ± 1.3 #> 10     1           9        1              2        0          3   2.83 ± 2.0 #> 11     1           9        1              3        0          2   6.61 ± 3.0 #> 12     1           9        1              4        0          1  11.02 ± 3.9 #> 13     1           9        1              5        1          1   7.78 ± 3.4 #> 14     1           9        1              6        1          2   8.44 ± 3.5 #> 15     1           9        1              7        1          3   6.06 ± 2.9 #> 16     1           9        1              8        1          4   5.95 ± 3.0 #> # ℹ 1 more variable: N[2:16] <int> add_predicted_rvars_metad(m$data, m) #> # A tibble: 16 × 7 #> # Groups:   .row, N, stimulus, joint_response, response, confidence [16] #>     .row N[,\"N_0_1\"] stimulus joint_response response confidence  .prediction #>    <int>       <int>    <int>          <int>    <int>      <dbl>   <rvar[1d]> #>  1     1           9        0              1        0          4   8.31 ± 3.3 #>  2     1           9        0              2        0          3   8.28 ± 3.4 #>  3     1           9        0              3        0          2  10.99 ± 3.8 #>  4     1           9        0              4        0          1  10.02 ± 3.7 #>  5     1           9        0              5        1          1   5.87 ± 3.0 #>  6     1           9        0              6        1          2   3.82 ± 2.4 #>  7     1           9        0              7        1          3   1.83 ± 1.5 #>  8     1           9        0              8        1          4   0.88 ± 1.0 #>  9     1           9        1              1        0          4   1.41 ± 1.4 #> 10     1           9        1              2        0          3   2.80 ± 2.1 #> 11     1           9        1              3        0          2   6.56 ± 3.1 #> 12     1           9        1              4        0          1  10.75 ± 4.2 #> 13     1           9        1              5        1          1   7.82 ± 3.2 #> 14     1           9        1              6        1          2   8.51 ± 3.4 #> 15     1           9        1              7        1          3   6.26 ± 2.7 #> 16     1           9        1              8        1          4   5.88 ± 3.0 #> # ℹ 1 more variable: N[2:16] <int>"},{"path":"https://metacoglab.github.io/mRatio/reference/response_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute joint response probabilities from aggregated counts — response_probabilities","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"Compute joint response probabilities aggregated counts","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/response_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"","code":"response_probabilities(counts)"},{"path":"https://metacoglab.github.io/mRatio/reference/response_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"counts vector (matrix) counts joint type 1/type 2 responses provided aggregate_metad","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/response_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"vector (matrix) response probabilities \\(P(R, C \\;\\vert\\; S)\\)","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/response_probabilities.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"response \\(R\\), confidence \\(C\\), stimulus \\(S\\), number confidence levels \\(K\\), counts vector (matrix rows) form: $$  [N_{S=0, R=0, C=K}, \\ldots, N_{S=0, R=0, C=1}, \\\\  N_{S=0, R=1, C=1}, \\ldots, N_{S=0, R=1, C=K}, \\\\  N_{S=1, R=0, C=K}, \\ldots, N_{S=1, R=0, C=1}, \\\\  N_{S=1, R=1, C=1}, \\ldots, N_{S=1, R=1, C=K}] \\\\ $$ Returns vector (matrix rows) form: $$ [P(R=0, C=K \\;\\vert\\; S=0), ..., P(R=0, C=1 \\;\\vert\\; S=0), \\\\  P(R=1, C=1 \\;\\vert\\; S=0), ..., P(R=1, C=K \\;\\vert\\; S=0), \\\\  P(R=0, C=K \\;\\vert\\; S=1), ..., P(R=0, C=1 \\;\\vert\\; S=1), \\\\  P(R=1, C=1 \\;\\vert\\; S=1), ..., P(R=1, C=K \\;\\vert\\; S=1)] $$","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/response_probabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute joint response probabilities from aggregated counts — response_probabilities","text":"","code":"# Aggregate responses from simulated data d <- sim_metad() |> aggregate_metad()  # Compute conditional response probabilities response_probabilities(d$N) #>      N_0_1 N_0_2 N_0_3 N_0_4 N_0_5 N_0_6 N_0_7 N_0_8 N_1_1 N_1_2 N_1_3 N_1_4 #> [1,]  0.12  0.12   0.1   0.2  0.24  0.16  0.06     0  0.02  0.02   0.1  0.26 #>      N_1_5 N_1_6 N_1_7 N_1_8 #> [1,]  0.12  0.18  0.16  0.14  # Also works on matrices matrix(rep(1, 16), nrow = 2) |> response_probabilities() #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #> [1,] 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 #> [2,] 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25"},{"path":"https://metacoglab.github.io/mRatio/reference/responses.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between separate and joint type 1/type 2 responses — joint_response","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"Confidence ratings decisions collected one two ways. separate ratings, type 1 response (\\(R \\\\{0, 1\\}\\)) type 2 response (\\(C \\[1, K]\\)). joint ratings, instead combined type 1/type 2 response (\\(J \\[1, 2K]\\)), values \\([1, K]\\) indicating type 1 response \\(0\\) values \\([K+1, 2K]\\) indicating type 1 response \\(1\\), confident responses ends scale. joint_response converts separate type 1 type 2 responses joint format type1_response type2_response convert joint response separate responses.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/responses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"","code":"joint_response(response, confidence, K)  type1_response(joint_response, K)  type2_response(joint_response, K)"},{"path":"https://metacoglab.github.io/mRatio/reference/responses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"response type 1 response (0 1) confidence type 2 response/confidence rating (1:K) K number confidence levels joint_response joint type 1/type 2 response","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/responses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert between separate and joint type 1/type 2 responses — joint_response","text":"","code":"# convert joint_response to separate responses joint <- 1:8 K <- 4 type1_response(joint, K) #> [1] 0 0 0 0 1 1 1 1 type2_response(joint, K) #> [1] 4 3 2 1 1 2 3 4  # convert separate responses to a joint response t1 <- rep(c(0, 1), each = 4) t2 <- c(4:1, 1:4) joint_response(t1, t2, K) #> [1] 1 2 3 4 5 6 7 8"},{"path":"https://metacoglab.github.io/mRatio/reference/rmatrixnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a matrix-normal distribution — rmatrixnorm","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"Sample matrix-normal distribution","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/rmatrixnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"","code":"rmatrixnorm(mu, L_sigma_rows, L_sigma_cols)"},{"path":"https://metacoglab.github.io/mRatio/reference/rmatrixnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"mu matrix means L_sigma_rows Cholesky-decomposed covariance matrix rows L_sigma_cols Cholesky-decomposed covariance matrix columns","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/rmatrixnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"single sample matrix-normal distribution mean mu (matrix), row-wise covariances sigma_rows, column-wise covariances sigma_cols, L_sigma_rows L_sigma_cols Cholesky-decomposed covariance matrices","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/rmatrixnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a matrix-normal distribution — rmatrixnorm","text":"","code":"mu <- matrix(rep(0, 8), nrow = 4) sd_rows <- rep(1, 4) sd_cols <- rep(1, 2) r_rows <- cor_matrix(.25, 4) r_cols <- cor_matrix(.75, 2) L_sigma_rows <- chol(cov_matrix(sd_rows, r_rows)) L_sigma_cols <- chol(cov_matrix(sd_cols, r_cols)) rmatrixnorm(mu, L_sigma_rows, L_sigma_cols) #>            [,1]       [,2] #> [1,]  2.8136991  2.0018524 #> [2,]  0.9433234  1.7617484 #> [3,]  0.7674802  0.3909412 #> [4,] -0.1663155 -0.7883861"},{"path":"https://metacoglab.github.io/mRatio/reference/roc1_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"Given data frame meta-d' model, adds estimates cumulative probability joint_responses. roc1_draws add_roc1_draws, estimates returned tidy tibble one row per posterior draw per joint response. roc1_rvars add_roc1_rvars, parameters returned posterior::rvars, one row per row newdata per joint response.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/roc1_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"","code":"roc1_draws(object, newdata, ..., bounds = FALSE)  add_roc1_draws(newdata, object, ...)  roc1_rvars(object, newdata, ..., bounds = FALSE)  add_roc1_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/mRatio/reference/roc1_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws tidybayes::epred_rvars bounds TRUE, include endpoints ROC \\((0, 0)\\) \\((1, 1)\\). Otherwise, endpoints excluded.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/roc1_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"tibble containing posterior draws pseudo type 1 ROC following columns: .row: row newdata .chain, .iteration, .draw: roc1_draws add_roc1_draws, identifiers posterior sample joint_response: combined type 1 / type 2 response (\\(J \\[1, 2K]\\)) \\(K\\) confidence levels) response: type 1 response perceived stimulus presence (\\(R \\\\{0, 1\\}\\)) confidence: type 2 confidence response (\\(C \\[1, K]\\)) p_fa: cumulative probability 'present'/'old' response stimulus==0 (\\(P(J \\ge j \\;\\vert\\; S=0)\\)) p_hit: cumulative probability 'present'/'old' response stimulus==1 (\\(P(J \\ge j \\;\\vert\\; S=1)\\))","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/roc1_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of the pseudo type 1 receiver operating characteristic (ROC) curve. — roc1_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.04 seconds (Warm-up) #> Chain 1:                0.04 seconds (Sampling) #> Chain 1:                0.08 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.07, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # compute pseudo-type 1 ROC curve roc1_draws(m, newdata) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.784 0.976 #>  2     1              1        0          4     NA         NA     2 0.767 0.956 #>  3     1              1        0          4     NA         NA     3 0.765 0.957 #>  4     1              1        0          4     NA         NA     4 0.865 0.985 #>  5     1              1        0          4     NA         NA     5 0.770 0.915 #>  6     1              1        0          4     NA         NA     6 0.798 0.964 #>  7     1              1        0          4     NA         NA     7 0.888 0.971 #>  8     1              1        0          4     NA         NA     8 0.730 0.947 #>  9     1              1        0          4     NA         NA     9 0.851 0.962 #> 10     1              1        0          4     NA         NA    10 0.728 0.981 #> # ℹ 1,740 more rows add_roc1_draws(newdata, m) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.784 0.976 #>  2     1              1        0          4     NA         NA     2 0.767 0.956 #>  3     1              1        0          4     NA         NA     3 0.765 0.957 #>  4     1              1        0          4     NA         NA     4 0.865 0.985 #>  5     1              1        0          4     NA         NA     5 0.770 0.915 #>  6     1              1        0          4     NA         NA     6 0.798 0.964 #>  7     1              1        0          4     NA         NA     7 0.888 0.971 #>  8     1              1        0          4     NA         NA     8 0.730 0.947 #>  9     1              1        0          4     NA         NA     9 0.851 0.962 #> 10     1              1        0          4     NA         NA    10 0.728 0.981 #> # ℹ 1,740 more rows  # use posterior::rvar for additional efficiency roc1_rvars(m, newdata) #> # A tibble: 7 × 6 #> # Groups:   .row, joint_response, response, confidence [7] #>    .row joint_response response confidence           p_fa         p_hit #>   <int>          <int>    <int>      <dbl>     <rvar[1d]>    <rvar[1d]> #> 1     1              1        0          4  0.804 ± 0.051  0.96 ± 0.016 #> 2     1              2        0          3  0.657 ± 0.064  0.93 ± 0.025 #> 3     1              3        0          2  0.447 ± 0.059  0.87 ± 0.042 #> 4     1              4        0          1  0.237 ± 0.056  0.81 ± 0.057 #> 5     1              5        1          1  0.135 ± 0.037  0.52 ± 0.067 #> 6     1              6        1          2  0.066 ± 0.026  0.29 ± 0.063 #> 7     1              7        1          3  0.025 ± 0.013  0.12 ± 0.041 add_roc1_draws(newdata, m) #> # A tibble: 1,750 × 9 #> # Groups:   .row, joint_response, response, confidence [7] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <int>    <int>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              1        0          4     NA         NA     1 0.784 0.976 #>  2     1              1        0          4     NA         NA     2 0.767 0.956 #>  3     1              1        0          4     NA         NA     3 0.765 0.957 #>  4     1              1        0          4     NA         NA     4 0.865 0.985 #>  5     1              1        0          4     NA         NA     5 0.770 0.915 #>  6     1              1        0          4     NA         NA     6 0.798 0.964 #>  7     1              1        0          4     NA         NA     7 0.888 0.971 #>  8     1              1        0          4     NA         NA     8 0.730 0.947 #>  9     1              1        0          4     NA         NA     9 0.851 0.962 #> 10     1              1        0          4     NA         NA    10 0.728 0.981 #> # ℹ 1,740 more rows  # include the ROC bounds roc1_draws(m, newdata, bounds = TRUE) #> # A tibble: 2,250 × 9 #> # Groups:   .row, joint_response, response, confidence [9] #>     .row joint_response response confidence .chain .iteration .draw  p_fa p_hit #>    <int>          <dbl>    <dbl>      <dbl>  <int>      <int> <int> <dbl> <dbl> #>  1     1              0        0          5     NA         NA     1     1     1 #>  2     1              0        0          5     NA         NA     2     1     1 #>  3     1              0        0          5     NA         NA     3     1     1 #>  4     1              0        0          5     NA         NA     4     1     1 #>  5     1              0        0          5     NA         NA     5     1     1 #>  6     1              0        0          5     NA         NA     6     1     1 #>  7     1              0        0          5     NA         NA     7     1     1 #>  8     1              0        0          5     NA         NA     8     1     1 #>  9     1              0        0          5     NA         NA     9     1     1 #> 10     1              0        0          5     NA         NA    10     1     1 #> # ℹ 2,240 more rows"},{"path":"https://metacoglab.github.io/mRatio/reference/roc2_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"Given data frame meta-d' model, adds estimates cumulative probability confidence type 1 response. roc2_draws add_roc2_draws, estimates returned tidy tibble one row per posterior draw per joint response. roc2_rvars add_roc2_rvars, parameters returned posterior::rvars, one row per row newdata per joint response.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/roc2_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"","code":"roc2_draws(object, newdata, ..., bounds = FALSE)  add_roc2_draws(newdata, object, ...)  roc2_rvars(object, newdata, ..., bounds = FALSE)  add_roc2_rvars(newdata, object, ...)"},{"path":"https://metacoglab.github.io/mRatio/reference/roc2_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"object brms model metad family newdata data frame generate posterior predictions ... Additional parameters passed tidybayes::epred_draws bounds TRUE, include endpoints ROC \\((0, 0)\\) \\((1, 1)\\). Otherwise, endpoints excluded.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/roc2_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"tibble containing posterior draws pseudo type 1 ROC following columns: .row: row newdata .chain, .iteration, .draw: roc2_draws add_roc2_draws, identifiers posterior sample response: type 1 response perceived stimulus presence (\\(R \\\\{0, 1\\}\\)) confidence: type 2 confidence response (\\(C \\[1, K]\\)) p_fa2: cumulative probability incorrect response (\\(P(C\\ge c \\;\\vert\\; R\\ne S)\\)) p_hit2: cumulative probability correct response (\\(P(C\\ge c \\;\\vert\\; R = S)\\))","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/roc2_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior draws of the response-specific type 2 receiver operating characteristic (ROC) curves. — roc2_draws","text":"","code":"# running few iterations so example runs quickly, use more in practice m <- fit_metad(N ~ 1, sim_metad(), chains = 1, iter = 500) #> Compiling Stan program... #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.7e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.033 seconds (Warm-up) #> Chain 1:                0.024 seconds (Sampling) #> Chain 1:                0.057 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.06, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess newdata <- tidyr::tibble(.row = 1)  # compute type 2 ROC curve roc2_draws(m, newdata) #> # A tibble: 1,500 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.120 0.0304 #>  2     1        0          4     NA         NA     2  0.183 0.0186 #>  3     1        0          4     NA         NA     3  0.191 0.0911 #>  4     1        0          4     NA         NA     4  0.151 0.0597 #>  5     1        0          4     NA         NA     5  0.132 0.0363 #>  6     1        0          4     NA         NA     6  0.163 0.0860 #>  7     1        0          4     NA         NA     7  0.369 0.199  #>  8     1        0          4     NA         NA     8  0.282 0.0504 #>  9     1        0          4     NA         NA     9  0.209 0.0710 #> 10     1        0          4     NA         NA    10  0.223 0.0773 #> # ℹ 1,490 more rows add_roc2_draws(newdata, m) #> # A tibble: 1,500 × 8 #> # Groups:   .row, response, confidence [6] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <int>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.120 0.0304 #>  2     1        0          4     NA         NA     2  0.183 0.0186 #>  3     1        0          4     NA         NA     3  0.191 0.0911 #>  4     1        0          4     NA         NA     4  0.151 0.0597 #>  5     1        0          4     NA         NA     5  0.132 0.0363 #>  6     1        0          4     NA         NA     6  0.163 0.0860 #>  7     1        0          4     NA         NA     7  0.369 0.199  #>  8     1        0          4     NA         NA     8  0.282 0.0504 #>  9     1        0          4     NA         NA     9  0.209 0.0710 #> 10     1        0          4     NA         NA    10  0.223 0.0773 #> # ℹ 1,490 more rows  # use posterior::rvar for additional efficiency roc2_rvars(m, newdata) #> # A tibble: 6 × 5 #> # Groups:   .row, response, confidence [6] #>    .row response confidence        p_hit2          p_fa2 #>   <int>    <int>      <dbl>    <rvar[1d]>     <rvar[1d]> #> 1     1        0          2  0.74 ± 0.064  0.525 ± 0.096 #> 2     1        0          3  0.48 ± 0.078  0.243 ± 0.089 #> 3     1        0          4  0.21 ± 0.067  0.068 ± 0.045 #> 4     1        1          1  0.71 ± 0.065  0.488 ± 0.100 #> 5     1        1          2  0.42 ± 0.075  0.190 ± 0.075 #> 6     1        1          3  0.19 ± 0.063  0.055 ± 0.036 add_roc2_rvars(newdata, m) #> # A tibble: 6 × 5 #> # Groups:   .row, response, confidence [6] #>    .row response confidence        p_hit2          p_fa2 #>   <int>    <int>      <dbl>    <rvar[1d]>     <rvar[1d]> #> 1     1        0          2  0.74 ± 0.064  0.525 ± 0.096 #> 2     1        0          3  0.48 ± 0.078  0.243 ± 0.089 #> 3     1        0          4  0.21 ± 0.067  0.068 ± 0.045 #> 4     1        1          1  0.71 ± 0.065  0.488 ± 0.100 #> 5     1        1          2  0.42 ± 0.075  0.190 ± 0.075 #> 6     1        1          3  0.19 ± 0.063  0.055 ± 0.036  # include the ROC bounds roc2_draws(m, newdata, bounds = TRUE) #> # A tibble: 2,500 × 8 #> # Groups:   .row, response, confidence [10] #>     .row response confidence .chain .iteration .draw p_hit2  p_fa2 #>    <int>    <dbl>      <dbl>  <int>      <int> <int>  <dbl>  <dbl> #>  1     1        0          4     NA         NA     1  0.120 0.0304 #>  2     1        0          4     NA         NA     2  0.183 0.0186 #>  3     1        0          4     NA         NA     3  0.191 0.0911 #>  4     1        0          4     NA         NA     4  0.151 0.0597 #>  5     1        0          4     NA         NA     5  0.132 0.0363 #>  6     1        0          4     NA         NA     6  0.163 0.0860 #>  7     1        0          4     NA         NA     7  0.369 0.199  #>  8     1        0          4     NA         NA     8  0.282 0.0504 #>  9     1        0          4     NA         NA     9  0.209 0.0710 #> 10     1        0          4     NA         NA    10  0.223 0.0773 #> # ℹ 2,490 more rows"},{"path":"https://metacoglab.github.io/mRatio/reference/signed.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"to_signed(x) converts \\(x \\\\{0, 1\\}\\) \\(x' \\\\{-1, 1\\}\\) to_unsigned(x) converts \\(x \\\\{-1, 1\\}\\) \\(x' \\\\{0, 1\\}\\)","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/signed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"","code":"to_signed(x)  to_unsigned(x)"},{"path":"https://metacoglab.github.io/mRatio/reference/signed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"x binary variable","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/signed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"signed (to_signed) unsigned (to_unsigned) version x","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/signed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert binary variable \\(x\\) between \\(\\{0, 1\\}\\) and \\(\\{-1, 1\\}\\) — to_signed","text":"","code":"# should return `1` to_signed(0) #> [1] -1  # should return `1` to_signed(1) #> [1] 1  # should return `0` to_unsigned(-1) #> [1] 0  # should return `1` to_unsigned(1) #> [1] 1  # `to_signed` also works with objects `R` interprets as `0` or `1` to_signed(10) #> [1] 1  # `to_unsigned` also works with any signed integer to_unsigned(-10) #> [1] 0  # neither function works with factors to_unsigned(factor(1)) #> Warning: ‘>’ not meaningful for factors #> [1] NA"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the meta-d' model — sim_metad","title":"Simulate from the meta-d' model — sim_metad","text":"Generate simulated dataset meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the meta-d' model — sim_metad","text":"","code":"sim_metad(   N_trials = 100,   dprime = 1,   c = 0,   log_M = 0,   c2_0_diff = rep(0.5, 3),   c2_1_diff = rep(0.5, 3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the meta-d' model — sim_metad","text":"N_trials Total number trials simulate. Half trials stimulus=0 half stimulus=1. dprime sensitivity signal detection agent simulate c response bias signal detection agent simulate log_M metacognitive efficiency agent logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. c2_0_diff, c2_1_diff Distances confidence thresholds \"0\" \"1\" responses, meta_c2_0 = meta_c - cumsum(c2_0_diff) meta_c2_1 = meta_c + cumsum(c2_1_diff). metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf, lccdf log (complement) cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the meta-d' model — sim_metad","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the meta-d' model — sim_metad","text":"","code":"sim_metad(N_trials = 10) #> # A tibble: 10 × 14 #> # Groups:   stimulus, response, confidence [8] #>    trial stimulus response correct confidence dprime     c meta_dprime     M #>    <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> <dbl> #>  1     1        0        0       1          1      1     0           1     1 #>  2     2        0        0       1          2      1     0           1     1 #>  3     3        0        0       1          2      1     0           1     1 #>  4     4        0        0       1          4      1     0           1     1 #>  5     5        0        1       0          1      1     0           1     1 #>  6     1        1        1       1          1      1     0           1     1 #>  7     2        1        1       1          2      1     0           1     1 #>  8     3        1        1       1          2      1     0           1     1 #>  9     4        1        1       1          3      1     0           1     1 #> 10     5        1        1       1          4      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad(N_trials = 10000, summarize = TRUE) #> # A tibble: 16 × 14 #> # Groups:   stimulus [2] #>    stimulus response correct confidence     n dprime     c meta_dprime     M #>       <int>    <int>   <int>      <int> <int>  <dbl> <dbl>       <dbl> <dbl> #>  1        0        0       1          1   954      1     0           1     1 #>  2        0        0       1          2   983      1     0           1     1 #>  3        0        0       1          3   725      1     0           1     1 #>  4        0        0       1          4   809      1     0           1     1 #>  5        0        1       0          1   757      1     0           1     1 #>  6        0        1       0          2   439      1     0           1     1 #>  7        0        1       0          3   231      1     0           1     1 #>  8        0        1       0          4   102      1     0           1     1 #>  9        1        0       0          1   741      1     0           1     1 #> 10        1        0       0          2   445      1     0           1     1 #> 11        1        0       0          3   211      1     0           1     1 #> 12        1        0       0          4   125      1     0           1     1 #> 13        1        1       1          1   952      1     0           1     1 #> 14        1        1       1          2   948      1     0           1     1 #> 15        1        1       1          3   736      1     0           1     1 #> 16        1        1       1          4   842      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad(N_trials = 10, c2_0_diff = 1, c2_1_diff = 1) #> # A tibble: 10 × 14 #> # Groups:   stimulus, response, confidence [6] #>    trial stimulus response correct confidence dprime     c meta_dprime     M #>    <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> <dbl> #>  1     1        0        0       1          1      1     0           1     1 #>  2     2        0        0       1          2      1     0           1     1 #>  3     3        0        0       1          2      1     0           1     1 #>  4     4        0        1       0          1      1     0           1     1 #>  5     5        0        1       0          1      1     0           1     1 #>  6     1        1        0       0          1      1     0           1     1 #>  7     2        1        0       0          1      1     0           1     1 #>  8     3        1        1       1          1      1     0           1     1 #>  9     4        1        1       1          2      1     0           1     1 #> 10     5        1        1       1          2      1     0           1     1 #> # ℹ 5 more variables: meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"Generate simulated dataset across separate conditions meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"","code":"sim_metad_condition(   N_trials = 100,   dprime = rep(1, 2),   c = rep(0, 2),   log_M = rep(0, 2),   c2_0_diff = list(rep(0.5, 3), rep(0.5, 3)),   c2_1_diff = list(rep(0.5, 3), rep(0.5, 3)),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"N_trials Total number trials simulate. Half trials stimulus=0 half stimulus=1. dprime sensitivity signal detection agent simulate c response bias signal detection agent simulate log_M metacognitive efficiency agent logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. c2_0_diff, c2_1_diff Distances confidence thresholds \"0\" \"1\" responses, meta_c2_0 = meta_c - cumsum(c2_0_diff) meta_c2_1 = meta_c + cumsum(c2_1_diff). metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf, lccdf log (complement) cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number condition: simulated condition number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the meta-d' model across separate conditions — sim_metad_condition","text":"","code":"sim_metad_condition(N_trials = 10) #> # A tibble: 20 × 15 #>    condition trial stimulus response correct confidence dprime     c meta_dprime #>        <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> #>  1         1     1        0        0       1          1      1     0           1 #>  2         1     2        0        0       1          2      1     0           1 #>  3         1     3        0        0       1          4      1     0           1 #>  4         1     4        0        1       0          1      1     0           1 #>  5         1     5        0        1       0          1      1     0           1 #>  6         1     1        1        0       0          3      1     0           1 #>  7         1     2        1        1       1          1      1     0           1 #>  8         1     3        1        1       1          2      1     0           1 #>  9         1     4        1        1       1          3      1     0           1 #> 10         1     5        1        1       1          4      1     0           1 #> 11         2     1        0        0       1          2      1     0           1 #> 12         2     2        0        0       1          2      1     0           1 #> 13         2     3        0        0       1          3      1     0           1 #> 14         2     4        0        1       0          1      1     0           1 #> 15         2     5        0        1       0          2      1     0           1 #> 16         2     1        1        1       1          2      1     0           1 #> 17         2     2        1        1       1          2      1     0           1 #> 18         2     3        1        1       1          3      1     0           1 #> 19         2     4        1        1       1          3      1     0           1 #> 20         2     5        1        1       1          4      1     0           1 #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad_condition(N_trials = 10000, summarize = TRUE) #> # A tibble: 32 × 15 #>    condition stimulus response correct confidence     n dprime     c meta_dprime #>        <int>    <int>    <int>   <int>      <int> <int>  <dbl> <dbl>       <dbl> #>  1         1        0        0       1          1  1008      1     0           1 #>  2         1        0        0       1          2   927      1     0           1 #>  3         1        0        0       1          3   740      1     0           1 #>  4         1        0        0       1          4   826      1     0           1 #>  5         1        0        1       0          1   750      1     0           1 #>  6         1        0        1       0          2   420      1     0           1 #>  7         1        0        1       0          3   215      1     0           1 #>  8         1        0        1       0          4   114      1     0           1 #>  9         1        1        0       0          1   779      1     0           1 #> 10         1        1        0       0          2   468      1     0           1 #> # ℹ 22 more rows #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl> sim_metad_condition(N_trials = 10, c2_0_diff = list(1, .5), c2_1_diff = list(1, .5)) #> # A tibble: 20 × 15 #>    condition trial stimulus response correct confidence dprime     c meta_dprime #>        <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl>       <dbl> #>  1         1     1        0        0       1          1      1     0           1 #>  2         1     2        0        0       1          1      1     0           1 #>  3         1     3        0        0       1          1      1     0           1 #>  4         1     4        0        0       1          2      1     0           1 #>  5         1     5        0        0       1          2      1     0           1 #>  6         1     1        1        0       0          1      1     0           1 #>  7         1     2        1        1       1          1      1     0           1 #>  8         1     3        1        1       1          1      1     0           1 #>  9         1     4        1        1       1          1      1     0           1 #> 10         1     5        1        1       1          2      1     0           1 #> 11         2     1        0        0       1          2      1     0           1 #> 12         2     2        0        0       1          2      1     0           1 #> 13         2     3        0        0       1          2      1     0           1 #> 14         2     4        0        0       1          2      1     0           1 #> 15         2     5        0        1       0          1      1     0           1 #> 16         2     1        1        0       0          1      1     0           1 #> 17         2     2        1        0       0          1      1     0           1 #> 18         2     3        1        0       0          2      1     0           1 #> 19         2     4        1        0       0          2      1     0           1 #> 20         2     5        1        1       1          2      1     0           1 #> # ℹ 6 more variables: M <dbl>, meta_c2_0 <list>, meta_c2_1 <list>, theta <dbl>, #> #   theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the hierarchical meta-d' model — sim_metad_participant","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"Generate simulated dataset across participants meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"","code":"sim_metad_participant(   N_participants = 100,   N_trials = 100,   mu_dprime = 1,   sd_dprime = 0.5,   mu_c = 0,   sd_c = 0.5,   mu_log_M = 0,   sd_log_M = 0.5,   mu_z_c2_0 = rep(-1, 3),   sd_z_c2_0 = rep(0.1, 3),   r_z_c2_0 = diag(3),   mu_z_c2_1 = rep(-1, 3),   sd_z_c2_1 = rep(0.1, 3),   r_z_c2_1 = diag(3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"N_trials, N_participants Total number participants trials simulate per participant. Half trials stimulus=0 half stimulus=1. mu_dprime, sd_dprime mean standard deviation sensitivities signal detection agents simulate mu_c, sd_c mean standard deviation response bias signal detection agents simulate mu_log_M, sd_log_M mean standard deviation metacognitive efficiency agents logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. mu_z_c2_0, mu_z_c2_1 Mean distance confidence thresholds \"0\" \"1\" responses log_scale, meta_c2_0 = meta_c - cumulative_sum(exp(z_c2_0)) meta_c2_1 = meta_c + cumulative_sum(exp(z_c2_1)). sd_z_c2_0, sd_z_c2_1 SD log distances confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0, r_z_c2_1 Correlation log distances confidence thresholds \"0\" \"1\" responses log_scale. metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf log cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution. lccdf log complement cumulative distribution function underlying signal distribution. default, uses normal(+/-dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number participant: simulated participant number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the hierarchical meta-d' model — sim_metad_participant","text":"","code":"sim_metad_participant(N_participants = 10, N_trials = 10) #> # A tibble: 100 × 15 #>    participant trial stimulus response correct confidence dprime     c #>          <int> <int>    <int>    <int>   <int>      <int>  <dbl> <dbl> #>  1           1     1        0        0       1          4   1.02 0.579 #>  2           1     2        0        0       1          4   1.02 0.579 #>  3           1     3        0        0       1          4   1.02 0.579 #>  4           1     4        0        0       1          4   1.02 0.579 #>  5           1     5        0        0       1          4   1.02 0.579 #>  6           1     1        1        0       0          1   1.02 0.579 #>  7           1     2        1        1       1          1   1.02 0.579 #>  8           1     3        1        1       1          1   1.02 0.579 #>  9           1     4        1        1       1          3   1.02 0.579 #> 10           1     5        1        1       1          3   1.02 0.579 #> # ℹ 90 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl> sim_metad_participant(mu_dprime = 2, mu_log_M = -1) #> # A tibble: 10,000 × 15 #>    participant trial stimulus response correct confidence dprime      c #>          <int> <int>    <int>    <int>   <int>      <int>  <dbl>  <dbl> #>  1           1     1        0        0       1          1   1.61 -0.324 #>  2           1     2        0        0       1          1   1.61 -0.324 #>  3           1     3        0        0       1          1   1.61 -0.324 #>  4           1     4        0        0       1          1   1.61 -0.324 #>  5           1     5        0        0       1          1   1.61 -0.324 #>  6           1     6        0        0       1          1   1.61 -0.324 #>  7           1     7        0        0       1          1   1.61 -0.324 #>  8           1     8        0        0       1          1   1.61 -0.324 #>  9           1     9        0        0       1          2   1.61 -0.324 #> 10           1    10        0        0       1          2   1.61 -0.324 #> # ℹ 9,990 more rows #> # ℹ 7 more variables: meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"Generate simulated dataset across participants conditions meta-d' model sensitivity dprime, response bias c, metacognitive efficiency log_M, distances confidence thresholds c2_0_diff c2_1_diff (two responses).","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"","code":"sim_metad_participant_condition(   N_participants = 100,   N_trials = 100,   mu_dprime = rep(1, 2),   sd_dprime = rep(0.5, 2),   r_dprime = diag(2),   mu_c = rep(0, 2),   sd_c = rep(0.5, 2),   r_c = diag(2),   mu_log_M = rep(0, 2),   sd_log_M = rep(0.5, 2),   r_log_M = diag(2),   mu_z_c2_0 = matrix(rep(-1, 6), nrow = 3, ncol = 2),   sd_z_c2_0_condition = rep(0.1, 2),   r_z_c2_0_condition = diag(2),   sd_z_c2_0_confidence = rep(0.1, 3),   r_z_c2_0_confidence = diag(3),   mu_z_c2_1 = matrix(rep(-1, 6), nrow = 3, ncol = 2),   sd_z_c2_1_condition = rep(0.1, 2),   r_z_c2_1_condition = diag(2),   sd_z_c2_1_confidence = rep(0.1, 3),   r_z_c2_1_confidence = diag(3),   metac_absolute = TRUE,   summarize = FALSE,   lcdf = normal_lcdf,   lccdf = normal_lccdf )"},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"N_trials, N_participants Total number participants trials simulate per participant. Half trials stimulus=0 half stimulus=1. mu_dprime, sd_dprime, r_dprime mean, standard deviation, within-participant correlations sensitivities signal detection agents simulate mu_c, sd_c, r_c mean, standard deviation, within-participant correlations response bias signal detection agents simulate mu_log_M, sd_log_M, r_log_M mean, standard deviation, within-participant correlations metacognitive efficiency agents logarithmic scale, 0 indicates optimal metacognitive sensitivity, negative numbers indicate metacognitive inefficiency, positive numbers indicate metacognitive hyper-efficiency. mu_z_c2_0, mu_z_c2_1 Mean distance confidence thresholds \"0\" \"1\" responses log_scale, meta_c2_0 = meta_c - cumulative_sum(exp(z_c2_0)) meta_c2_1 = meta_c + cumulative_sum(exp(z_c2_1)). sd_z_c2_0_condition, sd_z_c2_1_condition SD log distances across conditions confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0_condition, r_z_c2_1_condition Correlation across conditions log distances confidence thresholds \"0\" \"1\" responses log_scale. sd_z_c2_0_confidence, sd_z_c2_1_confidence SD log distances across confidence levels confidence thresholds \"0\" \"1\" responses log_scale. r_z_c2_0_confidence, r_z_c2_1_confidence Correlation across confidence levels log distances confidence thresholds \"0\" \"1\" responses log_scale. metac_absolute Determines fix type 1 threshold modeling confidence ratings. metac_absolute=TRUE, meta_c = c. Otherwise, meta_c = M * c. summarize Aggregate data? summarize=FALSE, returns dataset one row per observation. summarize=TRUE, returns aggregated dataset n number observations per response, accuracy, confidence level. lcdf log cumulative distribution function underlying signal distribution. default, uses normal(+/- dprime/2, 1) distribution. lccdf log complement cumulative distribution function underlying signal distribution. default, uses normal(+/- dprime/2, 1) distribution.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"simulated dataset type 1 responses confidence ratings, columns: trial: simulated trial number stimulus: value stimulus trial (either 0 1) response: simulated type 1 response (either 0 1) correct: whether stimulus==response (either 0 1) confidence: simulated type 2 response (1 length(c2_0_diff)+1) dprime:theta_2: simulated agent's parameter values summarize=TRUE, trial column replaced n column indicating number simulated type 1/type 2 responses possible value.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/sim_metad_participant_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the hierarchical meta-d' model across within-participant conditions — sim_metad_participant_condition","text":"","code":"sim_metad_participant_condition(10, 10) #> # A tibble: 200 × 16 #>    participant condition trial stimulus response correct confidence dprime #>          <int>     <int> <int>    <int>    <int>   <int>      <int>  <dbl> #>  1           1         1     1        0        0       1          1  0.675 #>  2           1         1     2        0        0       1          1  0.675 #>  3           1         1     3        0        1       0          3  0.675 #>  4           1         1     4        0        1       0          3  0.675 #>  5           1         1     5        0        1       0          4  0.675 #>  6           1         1     1        1        0       0          1  0.675 #>  7           1         1     2        1        0       0          4  0.675 #>  8           1         1     3        1        1       1          1  0.675 #>  9           1         1     4        1        1       1          3  0.675 #> 10           1         1     5        1        1       1          4  0.675 #> # ℹ 190 more rows #> # ℹ 8 more variables: c <dbl>, meta_dprime <dbl>, M <dbl>, meta_c2_0 <list>, #> #   meta_c2_1 <list>, theta <dbl>, theta_1 <dbl>, theta_2 <dbl>"},{"path":"https://metacoglab.github.io/mRatio/reference/stancode_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Stan code for the meta-d' model — stancode_metad","title":"Generate Stan code for the meta-d' model — stancode_metad","text":"Generate Stan code meta-d' model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/stancode_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Stan code for the meta-d' model — stancode_metad","text":"","code":"stancode_metad(   K,   distribution = \"normal\",   metac_absolute = TRUE,   categorical = FALSE )"},{"path":"https://metacoglab.github.io/mRatio/reference/stancode_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Stan code for the meta-d' model — stancode_metad","text":"K number confidence levels distribution noise distribution use. parameter-free distribution, .e., one mean-centered without additional variance/shape parameters. distribution already available stan, must additionally provide two functions Stan (one <distribution>_lcdf one <distribution>_lccdf). metac_absolute type 2 criterion (metac) fixed absolute type 1 criterion (c)? TRUE, model set metac = c. Otherwise, set metac = M * c, type 2 criterion relatively equal type 1 criterion (.e., meta_c/meta_dprime = c/dprime) categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/stancode_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Stan code for the meta-d' model — stancode_metad","text":"string containing Stan code defining likelihood metad' model K confidence levels, signal distributed according distribution distribution, metac = c metac_absolute==TRUE, metac = M*c otherwise.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/stanvars_metad.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Stan code for the meta-d' model — stanvars_metad","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"Generate Stan code meta-d' model","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/stanvars_metad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"","code":"stanvars_metad(   K,   distribution = \"normal\",   metac_absolute = TRUE,   categorical = FALSE )"},{"path":"https://metacoglab.github.io/mRatio/reference/stanvars_metad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"K number confidence levels distribution noise distribution use. parameter-free distribution, .e., one mean-centered without additional variance/shape parameters. distribution already available stan, must additionally provide two functions Stan (one <distribution>_lcdf one <distribution>_lccdf). metac_absolute type 2 criterion (metac) fixed absolute type 1 criterion (c)? TRUE, model set metac = c. Otherwise, set metac = M * c, type 2 criterion relatively equal type 1 criterion (.e., meta_c/meta_dprime = c/dprime) categorical FALSE (default), use multinomial likelihood aggregated data. TRUE, use categorical likelihood individual trials.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/stanvars_metad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"brms::stanvar object containing Stan code defining likelihood metad' model K confidence levels, signal distributed according distribution distribution, metac = c metac_absolute==TRUE, metac = M*c otherwise.","code":""},{"path":"https://metacoglab.github.io/mRatio/reference/stanvars_metad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Stan code for the meta-d' model — stanvars_metad","text":"","code":"# create stancode for the meta-d' model # using the normal distribution and 3 levels of confidence stanvars_metad(3) #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_normal_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = std_normal_lccdf(c - to_signed(stimulus)*dprime/2);\\n    real lp_0 = std_normal_lcdf(c - to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = std_normal_lccdf(meta_c - meta_mu);\\n    lp2_0[1] = std_normal_lcdf(meta_c - meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = std_normal_lccdf(meta_c2_1[k-1] - meta_mu);\\n      lp2_0[k] = std_normal_lcdf(meta_c2_0[k-1] - meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__3__normal__absolute__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_1_1, real z_meta_c2_1_2) {\\n  int K = 3; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_normal_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_normal_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\"  # create stancode for the meta-d' model with meta_c = M * c stanvars_metad(3, metac_absolute = FALSE) #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_normal_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = std_normal_lccdf(c - to_signed(stimulus)*dprime/2);\\n    real lp_0 = std_normal_lcdf(c - to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = std_normal_lccdf(meta_c - meta_mu);\\n    lp2_0[1] = std_normal_lcdf(meta_c - meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = std_normal_lccdf(meta_c2_1[k-1] - meta_mu);\\n      lp2_0[k] = std_normal_lcdf(meta_c2_0[k-1] - meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__3__normal__relative__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_1_1, real z_meta_c2_1_2) {\\n  int K = 3; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = M * c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_normal_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_normal_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\"  # create stancode for the meta-d' model with # an alternative distribution # note: cumulative distribution functions must be defined # in R and in Stan using [brms::stanvar()] stanvars_metad(4, distribution = \"gumbel_min\") #> [[1]] #> [[1]]$name #> [1] \"\" #>  #> [[1]]$sdata #> NULL #>  #> [[1]]$scode #> [1] \"\\n  // Convert a binary int x from {0, 1} to {-1, 1}\\n  int to_signed(int x) {\\n    return 2*x - 1;\\n  }\\n\\n  // P(response, confidence | stimulus) given as simplex\\n  // [P(resp=0, conf=K), .... P(resp=0, conf=1), P(resp=1, conf=1), ... P(resp=1, conf=K)]\\n  vector metad_gumbel_min_pmf(int stimulus, real dprime, real c, real meta_dprime, real meta_c, vector meta_c2_0, vector meta_c2_1) {\\n    // number of confidence levels\\n    int K = size(meta_c2_0) + 1;\\n\\n    // type-1 response probabilities\\n    real lp_1 = gumbel_min_lccdf(c | to_signed(stimulus)*dprime/2);\\n    real lp_0 = gumbel_min_lcdf(c | to_signed(stimulus)*dprime/2);\\n\\n    // means of type-2 distributions\\n    real meta_mu = to_signed(stimulus) * meta_dprime/2;\\n\\n    vector[K] lp2_1;         // CDFs (response == 1)\\n    vector[K] lp2_0;         // CDFs (response == 0)\\n    vector[2*K] log_theta;   // joint (type-1 x type-2) response probabilities\\n\\n    lp2_1[1] = gumbel_min_lccdf(meta_c | meta_mu);\\n    lp2_0[1] = gumbel_min_lcdf(meta_c | meta_mu);\\n    for (k in 2:K) {\\n      lp2_1[k] = gumbel_min_lccdf(meta_c2_1[k-1] | meta_mu);\\n      lp2_0[k] = gumbel_min_lcdf(meta_c2_0[k-1] | meta_mu);\\n\\n      log_theta[K-k+2] = log_diff_exp(lp2_0[k-1], lp2_0[k]);\\n      log_theta[K+k-1] = log_diff_exp(lp2_1[k-1], lp2_1[k]);\\n    }\\n    log_theta[1] = lp2_0[K];\\n    log_theta[2*K] = lp2_1[K];\\n\\n    // weight by P(response|stimulus) and normalize\\n    log_theta[1:K] += lp_0 - lp2_0[1];\\n    log_theta[(K+1):(2*K)] += lp_1 - lp2_1[1];\\n\\n    return exp(log_theta);\\n  }\\n\\n  real metad__4__gumbel_min__absolute__multinomial_lpmf(array[] int Y, real M, real dprime, real c, real z_meta_c2_0_1, real z_meta_c2_0_2, real z_meta_c2_0_3, real z_meta_c2_1_1, real z_meta_c2_1_2, real z_meta_c2_1_3) {\\n  int K = 4; // number of confidence levels\\n\\n  real meta_dprime = M * dprime;\\n  real meta_c = c;\\n  vector[K-1] meta_c2_0 = meta_c - cumulative_sum([z_meta_c2_0_1, z_meta_c2_0_2, z_meta_c2_0_3]');\\n  vector[K-1] meta_c2_1 = meta_c + cumulative_sum([z_meta_c2_1_1, z_meta_c2_1_2, z_meta_c2_1_3]');\\n\\n  // use multinomial likelihood\\n  return multinomial_lpmf(Y[1:(2*K)] | metad_gumbel_min_pmf(0, dprime, c,\\n                          meta_dprime, meta_c, meta_c2_0, meta_c2_1)) +\\n    multinomial_lpmf(Y[(2*K+1):(4*K)] |  metad_gumbel_min_pmf(1, dprime, c,\\n                      meta_dprime, meta_c, meta_c2_0, meta_c2_1));\\n}\" #>  #> [[1]]$block #> [1] \"functions\" #>  #> [[1]]$position #> [1] \"start\" #>  #> [[1]]$pll_args #> character(0) #>  #>  #> attr(,\"class\") #> [1] \"stanvars\""}]
